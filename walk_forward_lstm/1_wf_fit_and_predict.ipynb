{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23cf19b8-53cf-43e8-b2b6-ea2a69bce4b6",
   "metadata": {},
   "source": [
    "## Walk-Forward Forecast with Univariate Stateful LSTM\n",
    "In this notebook a walkforward forecasting approach is taken with the univariate LSTM architecture [demonstrated here](https://github.com/anasashb/brent_price_forecasting/tree/main/univariate_lstm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43ccce9-7156-412d-b14c-d173acbcb0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 13:23:37.711012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import stataments, including unused imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "# Seeds\n",
    "tf.random.set_seed(66)\n",
    "np.random.seed(66)\n",
    "\n",
    "# Plot configurations\n",
    "plt.rcParams['figure.figsize'] = (12, 6.75)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "# Error metrics\n",
    "def rmse(true, predicted):\n",
    "    return np.sqrt(np.mean(np.square(predicted - true)))\n",
    "def mape(true, predicted):\n",
    "    true, predicted = np.array(true), np.array(predicted)\n",
    "    return np.mean(np.abs((true - predicted) / true)) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7622c8b",
   "metadata": {},
   "source": [
    "### **Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e12c62f-f9a7-4870-a839-fc7361a1b030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brentpath = '/home/RDC/anasashb/Dokumente/ECXLOC/BRENTDATA.csv'\n",
    "\n",
    "# Import data set\n",
    "BRENT = pd.read_csv(brentpath,\n",
    "                   index_col = 'Date',\n",
    "                   parse_dates = True)\n",
    "BRENT = pd.Series(BRENT['EUR Future 1 Month'])\n",
    "\n",
    "# Plot\n",
    "BRENT.plot()\n",
    "plt.title('BRENT EUR FUTURE 1 MONTH')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf791e7-ca2f-4701-ad9f-50f0eca0eaed",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Pre-processing as well as model architecture is identical with the univariate LSTM [demonstrated here](https://github.com/anasashb/brent_price_forecasting/tree/main/univariate_lstm).\n",
    "\n",
    "Since in this case we'll be using the lag order of 1 and batch size of 1, input dimensions will not be a problem in terms of divisibility with the batch size. \n",
    "\n",
    "The set lengths are generated same as in the tuning notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afc6147-a011-43bb-b71f-211201ca6b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store Date\n",
    "dates = BRENT.index\n",
    "# Get values for the series\n",
    "series = BRENT.values.astype('float32').reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dfd007-00a8-4ca2-b0cb-2b6cca2a275f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify batch_size\n",
    "batch_size = 10\n",
    "# Specify lag order\n",
    "timesteps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd768b49-37db-44e9-a4ab-7bb86950934e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "# Define test, validation and train sizes\n",
    "test_size = 81\n",
    "val_size = 51\n",
    "train_size = 271\n",
    "print(test_size+val_size+train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbcbff9-5901-458e-8dc4-cff9ad233757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-val-test split\n",
    "train = series[:train_size]\n",
    "val = series[train_size:train_size+val_size]\n",
    "test = series[train_size+val_size:]\n",
    "\n",
    "# Important to obtain the retrain set at this stage\n",
    "# because we will lose observations if we concatenate \n",
    "# the sets after tensors have been generated\n",
    "retrain = np.concatenate((train, val), axis = 0)\n",
    "\n",
    "# Check\n",
    "len(train)+len(val)==len(retrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cb303b-91b7-4651-9774-a23ddfa0cb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale and Generate Tensors\n",
    "\n",
    "# Scaling: Use (-1,1) for better input to hyperbolic tangent\n",
    "# Fit on train set\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1)).fit(train)\n",
    "\n",
    "# Scale everything per train data parameters\n",
    "train = scaler.transform(train)\n",
    "val = scaler.transform(val)\n",
    "test = scaler.transform(test)\n",
    "retrain = scaler.transform(retrain)\n",
    "\n",
    "# Reshape as LSTM inputs:\n",
    "def generate_tensors(series, timesteps):\n",
    "    \n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for i in range(0, len(series) - timesteps):\n",
    "        x = np.reshape(series[i:i + timesteps], (-1,1))\n",
    "        dataX.append(x)\n",
    "        y = series[i +timesteps]\n",
    "        dataY.append(y)\n",
    "    \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "                 \n",
    "\n",
    "X_train, y_train = generate_tensors(train, timesteps)\n",
    "X_val, y_val = generate_tensors(val, timesteps)\n",
    "X_test, y_test = generate_tensors(test, timesteps)\n",
    "X_retrain, y_retrain = generate_tensors(retrain, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae0cc49-e459-4f18-bc20-1027c89c45bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 1, 1)\n",
      "(270, 1)\n",
      "(50, 1, 1)\n",
      "(50, 1)\n",
      "(80, 1, 1)\n",
      "(80, 1)\n",
      "(321, 1, 1)\n",
      "(321, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "tensors = [X_train, y_train, X_val, y_val, X_test, y_test, X_retrain, y_retrain]\n",
    "\n",
    "for i, tensor in enumerate(tensors):\n",
    "    print(f'{tensor.shape}')\n",
    "\n",
    "# Remove unneeded variable\n",
    "del tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4c0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for results\n",
    "path = '/home/RDC/anasashb/Dokumente/ECXLOC/WFTUNEDL1B10 /Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56c2ba",
   "metadata": {},
   "source": [
    "### **Model Architecture, Training, Predicting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe76c1cc-654a-4ea0-98c1-860dc1c0bed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (1, 45)                   8460      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (1, 45)                   0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, 1)                    46        \n",
      "=================================================================\n",
      "Total params: 8,506\n",
      "Trainable params: 8,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(45,\n",
    "                         activation = 'tanh',\n",
    "                         recurrent_activation = 'sigmoid',\n",
    "                         kernel_regularizer = regularizers.L2(1e-3),\n",
    "                         recurrent_regularizer = regularizers.L2(1e-3),\n",
    "                         bias_regularizer = regularizers.L2(1e-3),\n",
    "                         recurrent_dropout=0,\n",
    "                         unroll=False,\n",
    "                         use_bias = True,\n",
    "                         stateful = True,\n",
    "                         return_sequences = False,\n",
    "                         batch_input_shape = (batch_size, timesteps, 1)\n",
    "                         ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mape'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec170ce",
   "metadata": {},
   "source": [
    "For walk-forward validation, first we define a training function that we'll then put in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "454fe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stateful training\n",
    "def train_model(model, X_train, y_train, epochs=100, patience=10, min_delta=0.001):\n",
    "    # Set up variables for early stopping\n",
    "    best_train_loss = np.inf\n",
    "    wait = 0\n",
    "\n",
    "    # Empty containers to store training losses.\n",
    "    train_losses = []\n",
    "\n",
    "    # Training loop for given number of epochs\n",
    "    for i in range(epochs):\n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs = 1,\n",
    "                            batch_size = batch_size,\n",
    "                            verbose = 0,\n",
    "                            shuffle = False)\n",
    "        # Reset cell states after one epoch\n",
    "        model.reset_states()\n",
    "        \n",
    "        # Calculate training losses\n",
    "        train_loss = history.history['loss'][0]\n",
    "        \n",
    "        # Append losses\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if np.abs(train_loss - best_train_loss) > min_delta:\n",
    "            best_train_loss = train_loss\n",
    "            wait = 0\n",
    "            \n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f'early stopping on epoch: {i+1}')\n",
    "                break\n",
    "        \n",
    "        print(f'Epoch {i + 1} - Training Loss: {train_loss}') \n",
    "    \n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3490507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the sets for WF forecasting\n",
    "WFX_train = X_retrain.copy()\n",
    "WFy_train = y_retrain.copy()\n",
    "WFX_test = X_test.copy()\n",
    "WFy_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15031a8f",
   "metadata": {},
   "source": [
    "Below the walk forward forecasting loop is demonstrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "679bc900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 0.10536497086286545\n",
      "Epoch 2 - Training Loss: 0.05646384879946709\n",
      "Epoch 3 - Training Loss: 0.03604467213153839\n",
      "Epoch 4 - Training Loss: 0.026525242254137993\n",
      "Epoch 5 - Training Loss: 0.02245585061609745\n",
      "Epoch 6 - Training Loss: 0.018749283626675606\n",
      "Epoch 7 - Training Loss: 0.01726406253874302\n",
      "Epoch 8 - Training Loss: 0.016442501917481422\n",
      "Epoch 9 - Training Loss: 0.016031956300139427\n",
      "Epoch 10 - Training Loss: 0.016367755830287933\n",
      "Epoch 11 - Training Loss: 0.016054511070251465\n",
      "Epoch 12 - Training Loss: 0.015789028257131577\n",
      "Epoch 13 - Training Loss: 0.014512808993458748\n",
      "Epoch 14 - Training Loss: 0.015823954716324806\n",
      "Epoch 15 - Training Loss: 0.014668414369225502\n",
      "Epoch 16 - Training Loss: 0.015778256580233574\n",
      "Epoch 17 - Training Loss: 0.015295940451323986\n",
      "Epoch 18 - Training Loss: 0.01628367230296135\n",
      "Epoch 19 - Training Loss: 0.015445691533386707\n",
      "Epoch 20 - Training Loss: 0.015685370191931725\n",
      "Epoch 21 - Training Loss: 0.01567172072827816\n",
      "Epoch 22 - Training Loss: 0.014488324522972107\n",
      "Epoch 23 - Training Loss: 0.015036683529615402\n",
      "Epoch 24 - Training Loss: 0.014300975017249584\n",
      "Epoch 25 - Training Loss: 0.014507681131362915\n",
      "Epoch 26 - Training Loss: 0.014455272816121578\n",
      "Epoch 27 - Training Loss: 0.014998695813119411\n",
      "Epoch 28 - Training Loss: 0.015302296727895737\n",
      "Epoch 29 - Training Loss: 0.014855763874948025\n",
      "Epoch 30 - Training Loss: 0.01587931253015995\n",
      "Epoch 31 - Training Loss: 0.015033344738185406\n",
      "Epoch 32 - Training Loss: 0.014363099820911884\n",
      "Epoch 33 - Training Loss: 0.014454894699156284\n",
      "Epoch 34 - Training Loss: 0.015323420986533165\n",
      "Epoch 35 - Training Loss: 0.014395413920283318\n",
      "Epoch 36 - Training Loss: 0.014455954544246197\n",
      "Epoch 37 - Training Loss: 0.014364824630320072\n",
      "Epoch 38 - Training Loss: 0.01501565519720316\n",
      "Epoch 39 - Training Loss: 0.014931653626263142\n",
      "Epoch 40 - Training Loss: 0.014960584230720997\n",
      "Epoch 41 - Training Loss: 0.015182756818830967\n",
      "early stopping on epoch: 42\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f15600c1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1 - Training Loss: 0.014732337556779385\n",
      "Epoch 2 - Training Loss: 0.014171048067510128\n",
      "Epoch 3 - Training Loss: 0.013424722477793694\n",
      "Epoch 4 - Training Loss: 0.01413397490978241\n",
      "Epoch 5 - Training Loss: 0.014380499720573425\n",
      "Epoch 6 - Training Loss: 0.014255588874220848\n",
      "Epoch 7 - Training Loss: 0.014312791638076305\n",
      "Epoch 8 - Training Loss: 0.014397338032722473\n",
      "Epoch 9 - Training Loss: 0.014278813265264034\n",
      "Epoch 10 - Training Loss: 0.014094101265072823\n",
      "Epoch 11 - Training Loss: 0.014399352483451366\n",
      "Epoch 12 - Training Loss: 0.014685582369565964\n",
      "Epoch 13 - Training Loss: 0.014322358183562756\n",
      "Epoch 14 - Training Loss: 0.014106329530477524\n",
      "Epoch 15 - Training Loss: 0.013880325481295586\n",
      "Epoch 16 - Training Loss: 0.013874305412173271\n",
      "Epoch 17 - Training Loss: 0.01434387732297182\n",
      "Epoch 18 - Training Loss: 0.015012465417385101\n",
      "Epoch 19 - Training Loss: 0.01356890331953764\n",
      "Epoch 20 - Training Loss: 0.014555399306118488\n",
      "Epoch 21 - Training Loss: 0.013862173072993755\n",
      "Epoch 22 - Training Loss: 0.013885998167097569\n",
      "Epoch 23 - Training Loss: 0.013808034360408783\n",
      "Epoch 24 - Training Loss: 0.015008818358182907\n",
      "Epoch 25 - Training Loss: 0.014252359047532082\n",
      "Epoch 26 - Training Loss: 0.013541394844651222\n",
      "Epoch 27 - Training Loss: 0.01449461467564106\n",
      "Epoch 28 - Training Loss: 0.013944938778877258\n",
      "Epoch 29 - Training Loss: 0.014149371534585953\n",
      "Epoch 30 - Training Loss: 0.013989701867103577\n",
      "Epoch 31 - Training Loss: 0.014578484930098057\n",
      "Epoch 32 - Training Loss: 0.01448410376906395\n",
      "Epoch 33 - Training Loss: 0.012580913491547108\n",
      "Epoch 34 - Training Loss: 0.01304197870194912\n",
      "Epoch 35 - Training Loss: 0.013599586673080921\n",
      "Epoch 36 - Training Loss: 0.0146509213373065\n",
      "Epoch 37 - Training Loss: 0.013191750273108482\n",
      "Epoch 38 - Training Loss: 0.013439248315989971\n",
      "Epoch 39 - Training Loss: 0.013181452639400959\n",
      "Epoch 40 - Training Loss: 0.014208504930138588\n",
      "Epoch 41 - Training Loss: 0.014807116240262985\n",
      "Epoch 42 - Training Loss: 0.013840040192008018\n",
      "Epoch 43 - Training Loss: 0.014043908566236496\n",
      "Epoch 44 - Training Loss: 0.013232866302132607\n",
      "Epoch 45 - Training Loss: 0.013286334462463856\n",
      "Epoch 46 - Training Loss: 0.014665530994534492\n",
      "Epoch 47 - Training Loss: 0.014211027882993221\n",
      "Epoch 48 - Training Loss: 0.013564200140535831\n",
      "Epoch 49 - Training Loss: 0.013396479189395905\n",
      "early stopping on epoch: 50\n",
      "Epoch 1 - Training Loss: 0.013424510136246681\n",
      "Epoch 2 - Training Loss: 0.013969366438686848\n",
      "Epoch 3 - Training Loss: 0.013462969101965427\n",
      "Epoch 4 - Training Loss: 0.013972366228699684\n",
      "Epoch 5 - Training Loss: 0.013356433250010014\n",
      "Epoch 6 - Training Loss: 0.013933000154793262\n",
      "Epoch 7 - Training Loss: 0.013561706058681011\n",
      "Epoch 8 - Training Loss: 0.013562090694904327\n",
      "Epoch 9 - Training Loss: 0.012797221541404724\n",
      "Epoch 10 - Training Loss: 0.01440463773906231\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.013244083151221275\n",
      "Epoch 2 - Training Loss: 0.013592570088803768\n",
      "Epoch 3 - Training Loss: 0.013371404260396957\n",
      "Epoch 4 - Training Loss: 0.013044621795415878\n",
      "Epoch 5 - Training Loss: 0.012817910872399807\n",
      "Epoch 6 - Training Loss: 0.013009758666157722\n",
      "Epoch 7 - Training Loss: 0.013885259628295898\n",
      "Epoch 8 - Training Loss: 0.012086007744073868\n",
      "Epoch 9 - Training Loss: 0.013856664299964905\n",
      "Epoch 10 - Training Loss: 0.012969420291483402\n",
      "Epoch 11 - Training Loss: 0.012429587543010712\n",
      "Epoch 12 - Training Loss: 0.012588021345436573\n",
      "Epoch 13 - Training Loss: 0.012800832279026508\n",
      "Epoch 14 - Training Loss: 0.014122995547950268\n",
      "Epoch 15 - Training Loss: 0.01315088476985693\n",
      "Epoch 16 - Training Loss: 0.013468739576637745\n",
      "Epoch 17 - Training Loss: 0.01356418151408434\n",
      "Epoch 18 - Training Loss: 0.012867072597146034\n",
      "Epoch 19 - Training Loss: 0.012980692088603973\n",
      "Epoch 20 - Training Loss: 0.013377072289586067\n",
      "Epoch 21 - Training Loss: 0.013486425392329693\n",
      "Epoch 22 - Training Loss: 0.013941014185547829\n",
      "Epoch 23 - Training Loss: 0.013116301968693733\n",
      "Epoch 24 - Training Loss: 0.01361951231956482\n",
      "Epoch 25 - Training Loss: 0.01350434496998787\n",
      "Epoch 26 - Training Loss: 0.01354335155338049\n",
      "Epoch 27 - Training Loss: 0.012597025372087955\n",
      "Epoch 28 - Training Loss: 0.014005128294229507\n",
      "Epoch 29 - Training Loss: 0.013707218691706657\n",
      "Epoch 30 - Training Loss: 0.01284981518983841\n",
      "Epoch 31 - Training Loss: 0.014173179864883423\n",
      "Epoch 32 - Training Loss: 0.012980679050087929\n",
      "Epoch 33 - Training Loss: 0.012601727619767189\n",
      "Epoch 34 - Training Loss: 0.01258692517876625\n",
      "Epoch 35 - Training Loss: 0.01291682105511427\n",
      "Epoch 36 - Training Loss: 0.013396973721683025\n",
      "Epoch 37 - Training Loss: 0.012500072829425335\n",
      "Epoch 38 - Training Loss: 0.013352376408874989\n",
      "Epoch 39 - Training Loss: 0.012619792483747005\n",
      "Epoch 40 - Training Loss: 0.01311210636049509\n",
      "Epoch 41 - Training Loss: 0.013173522427678108\n",
      "early stopping on epoch: 42\n",
      "Epoch 1 - Training Loss: 0.01342447567731142\n",
      "Epoch 2 - Training Loss: 0.01324043981730938\n",
      "Epoch 3 - Training Loss: 0.012759911827743053\n",
      "Epoch 4 - Training Loss: 0.013137503527104855\n",
      "Epoch 5 - Training Loss: 0.012593439780175686\n",
      "Epoch 6 - Training Loss: 0.012915215454995632\n",
      "Epoch 7 - Training Loss: 0.013910382054746151\n",
      "Epoch 8 - Training Loss: 0.013323258608579636\n",
      "Epoch 9 - Training Loss: 0.014408628456294537\n",
      "Epoch 10 - Training Loss: 0.013162360526621342\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.011413389816880226\n",
      "Epoch 2 - Training Loss: 0.013060126453638077\n",
      "Epoch 3 - Training Loss: 0.012860431335866451\n",
      "Epoch 4 - Training Loss: 0.012064479291439056\n",
      "Epoch 5 - Training Loss: 0.01262365560978651\n",
      "Epoch 6 - Training Loss: 0.012940427288413048\n",
      "Epoch 7 - Training Loss: 0.013088795356452465\n",
      "Epoch 8 - Training Loss: 0.012692656368017197\n",
      "Epoch 9 - Training Loss: 0.011927446350455284\n",
      "Epoch 10 - Training Loss: 0.01259197760373354\n",
      "Epoch 11 - Training Loss: 0.012926189228892326\n",
      "Epoch 12 - Training Loss: 0.013025731779634953\n",
      "Epoch 13 - Training Loss: 0.013377340510487556\n",
      "Epoch 14 - Training Loss: 0.013611703179776669\n",
      "Epoch 15 - Training Loss: 0.013040429912507534\n",
      "Epoch 16 - Training Loss: 0.011611300520598888\n",
      "Epoch 17 - Training Loss: 0.012374096550047398\n",
      "Epoch 18 - Training Loss: 0.012790092267096043\n",
      "Epoch 19 - Training Loss: 0.012538863345980644\n",
      "Epoch 20 - Training Loss: 0.013762605376541615\n",
      "Epoch 21 - Training Loss: 0.013727644458413124\n",
      "Epoch 22 - Training Loss: 0.012256819754838943\n",
      "Epoch 23 - Training Loss: 0.011920381337404251\n",
      "Epoch 24 - Training Loss: 0.012724663130939007\n",
      "Epoch 25 - Training Loss: 0.012781728059053421\n",
      "Epoch 26 - Training Loss: 0.012188087217509747\n",
      "Epoch 27 - Training Loss: 0.012392057105898857\n",
      "early stopping on epoch: 28\n",
      "Epoch 1 - Training Loss: 0.012927532196044922\n",
      "Epoch 2 - Training Loss: 0.011845595203340054\n",
      "Epoch 3 - Training Loss: 0.014028508216142654\n",
      "Epoch 4 - Training Loss: 0.012935592792928219\n",
      "Epoch 5 - Training Loss: 0.01277067419141531\n",
      "Epoch 6 - Training Loss: 0.010940708220005035\n",
      "Epoch 7 - Training Loss: 0.011600001715123653\n",
      "Epoch 8 - Training Loss: 0.011458317749202251\n",
      "Epoch 9 - Training Loss: 0.012783626094460487\n",
      "Epoch 10 - Training Loss: 0.011464983224868774\n",
      "Epoch 11 - Training Loss: 0.012798626907169819\n",
      "Epoch 12 - Training Loss: 0.012829220853745937\n",
      "Epoch 13 - Training Loss: 0.011265827342867851\n",
      "Epoch 14 - Training Loss: 0.013227535411715508\n",
      "Epoch 15 - Training Loss: 0.011408845894038677\n",
      "Epoch 16 - Training Loss: 0.013000939972698689\n",
      "Epoch 17 - Training Loss: 0.012914322316646576\n",
      "Epoch 18 - Training Loss: 0.0130495335906744\n",
      "Epoch 19 - Training Loss: 0.012808172963559628\n",
      "Epoch 20 - Training Loss: 0.012394987978041172\n",
      "Epoch 21 - Training Loss: 0.01304403692483902\n",
      "Epoch 22 - Training Loss: 0.01207007933408022\n",
      "Epoch 23 - Training Loss: 0.01094051729887724\n",
      "Epoch 24 - Training Loss: 0.012278268113732338\n",
      "Epoch 25 - Training Loss: 0.012863854877650738\n",
      "Epoch 26 - Training Loss: 0.012280533090233803\n",
      "Epoch 27 - Training Loss: 0.013081063516438007\n",
      "Epoch 28 - Training Loss: 0.012030908837914467\n",
      "Epoch 29 - Training Loss: 0.01320246048271656\n",
      "Epoch 30 - Training Loss: 0.012959041632711887\n",
      "Epoch 31 - Training Loss: 0.013142654672265053\n",
      "Epoch 32 - Training Loss: 0.012461396865546703\n",
      "Epoch 33 - Training Loss: 0.012205655686557293\n",
      "early stopping on epoch: 34\n",
      "Epoch 1 - Training Loss: 0.012966292910277843\n",
      "Epoch 2 - Training Loss: 0.013082687743008137\n",
      "Epoch 3 - Training Loss: 0.012987206690013409\n",
      "Epoch 4 - Training Loss: 0.01329799834638834\n",
      "Epoch 5 - Training Loss: 0.012951837852597237\n",
      "Epoch 6 - Training Loss: 0.012528683058917522\n",
      "Epoch 7 - Training Loss: 0.0131727559491992\n",
      "Epoch 8 - Training Loss: 0.013280645944178104\n",
      "Epoch 9 - Training Loss: 0.01290092058479786\n",
      "Epoch 10 - Training Loss: 0.012180649675428867\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.012598875910043716\n",
      "Epoch 2 - Training Loss: 0.012333442457020283\n",
      "Epoch 3 - Training Loss: 0.011995508335530758\n",
      "Epoch 4 - Training Loss: 0.012651337310671806\n",
      "Epoch 5 - Training Loss: 0.01210754830390215\n",
      "Epoch 6 - Training Loss: 0.013164139352738857\n",
      "Epoch 7 - Training Loss: 0.012019726447761059\n",
      "Epoch 8 - Training Loss: 0.012162730097770691\n",
      "Epoch 9 - Training Loss: 0.012480031698942184\n",
      "Epoch 10 - Training Loss: 0.012911356054246426\n",
      "Epoch 11 - Training Loss: 0.013632602989673615\n",
      "Epoch 12 - Training Loss: 0.01249191164970398\n",
      "Epoch 13 - Training Loss: 0.01289297267794609\n",
      "Epoch 14 - Training Loss: 0.012793142348527908\n",
      "Epoch 15 - Training Loss: 0.012455413118004799\n",
      "Epoch 16 - Training Loss: 0.012788241729140282\n",
      "Epoch 17 - Training Loss: 0.0123903788626194\n",
      "Epoch 18 - Training Loss: 0.012144625186920166\n",
      "Epoch 19 - Training Loss: 0.01345819141715765\n",
      "Epoch 20 - Training Loss: 0.01380203664302826\n",
      "Epoch 21 - Training Loss: 0.011218716390430927\n",
      "Epoch 22 - Training Loss: 0.011813982389867306\n",
      "Epoch 23 - Training Loss: 0.013201518915593624\n",
      "Epoch 24 - Training Loss: 0.01217141468077898\n",
      "Epoch 25 - Training Loss: 0.012407829985022545\n",
      "Epoch 26 - Training Loss: 0.013799529522657394\n",
      "Epoch 27 - Training Loss: 0.011450867168605328\n",
      "Epoch 28 - Training Loss: 0.011618126183748245\n",
      "Epoch 29 - Training Loss: 0.012841769494116306\n",
      "Epoch 30 - Training Loss: 0.012319234199821949\n",
      "Epoch 31 - Training Loss: 0.012833415530622005\n",
      "Epoch 32 - Training Loss: 0.013007323257625103\n",
      "Epoch 33 - Training Loss: 0.012296579778194427\n",
      "Epoch 34 - Training Loss: 0.012323770672082901\n",
      "Epoch 35 - Training Loss: 0.012562134303152561\n",
      "Epoch 36 - Training Loss: 0.012783954851329327\n",
      "Epoch 37 - Training Loss: 0.01177969854325056\n",
      "Epoch 38 - Training Loss: 0.013432877138257027\n",
      "Epoch 39 - Training Loss: 0.011924341320991516\n",
      "Epoch 40 - Training Loss: 0.012530019506812096\n",
      "Epoch 41 - Training Loss: 0.012972704134881496\n",
      "Epoch 42 - Training Loss: 0.011493510566651821\n",
      "Epoch 43 - Training Loss: 0.012575984001159668\n",
      "Epoch 44 - Training Loss: 0.012941136956214905\n",
      "Epoch 45 - Training Loss: 0.011973071843385696\n",
      "Epoch 46 - Training Loss: 0.01415981724858284\n",
      "Epoch 47 - Training Loss: 0.011905775405466557\n",
      "Epoch 48 - Training Loss: 0.012364656664431095\n",
      "Epoch 49 - Training Loss: 0.012478914111852646\n",
      "Epoch 50 - Training Loss: 0.011829035356640816\n",
      "Epoch 51 - Training Loss: 0.012914462946355343\n",
      "Epoch 52 - Training Loss: 0.012498808093369007\n",
      "Epoch 53 - Training Loss: 0.012129208073019981\n",
      "Epoch 54 - Training Loss: 0.013300510123372078\n",
      "Epoch 55 - Training Loss: 0.012525184080004692\n",
      "Epoch 56 - Training Loss: 0.012417949736118317\n",
      "Epoch 57 - Training Loss: 0.013747007586061954\n",
      "Epoch 58 - Training Loss: 0.012833032757043839\n",
      "Epoch 59 - Training Loss: 0.012728657573461533\n",
      "Epoch 60 - Training Loss: 0.013758515939116478\n",
      "early stopping on epoch: 61\n",
      "Epoch 1 - Training Loss: 0.013128581456840038\n",
      "Epoch 2 - Training Loss: 0.012373716570436954\n",
      "Epoch 3 - Training Loss: 0.012426056899130344\n",
      "Epoch 4 - Training Loss: 0.01222963910549879\n",
      "Epoch 5 - Training Loss: 0.011914855800569057\n",
      "Epoch 6 - Training Loss: 0.01178772747516632\n",
      "Epoch 7 - Training Loss: 0.012455600313842297\n",
      "Epoch 8 - Training Loss: 0.012284289114177227\n",
      "Epoch 9 - Training Loss: 0.012222085148096085\n",
      "Epoch 10 - Training Loss: 0.011538064107298851\n",
      "Epoch 11 - Training Loss: 0.012520591728389263\n",
      "Epoch 12 - Training Loss: 0.01188945583999157\n",
      "Epoch 13 - Training Loss: 0.012249773368239403\n",
      "Epoch 14 - Training Loss: 0.01365379523485899\n",
      "Epoch 15 - Training Loss: 0.012416782788932323\n",
      "Epoch 16 - Training Loss: 0.011685756035149097\n",
      "Epoch 17 - Training Loss: 0.011880951933562756\n",
      "Epoch 18 - Training Loss: 0.012800381518900394\n",
      "Epoch 19 - Training Loss: 0.011869468726217747\n",
      "Epoch 20 - Training Loss: 0.012091527692973614\n",
      "Epoch 21 - Training Loss: 0.011245034635066986\n",
      "Epoch 22 - Training Loss: 0.012471457943320274\n",
      "Epoch 23 - Training Loss: 0.013251595199108124\n",
      "Epoch 24 - Training Loss: 0.012486989609897137\n",
      "Epoch 25 - Training Loss: 0.012316573411226273\n",
      "Epoch 26 - Training Loss: 0.013232831843197346\n",
      "Epoch 27 - Training Loss: 0.0128640653565526\n",
      "Epoch 28 - Training Loss: 0.011306647211313248\n",
      "Epoch 29 - Training Loss: 0.013262725435197353\n",
      "Epoch 30 - Training Loss: 0.013077124953269958\n",
      "Epoch 31 - Training Loss: 0.013160171918570995\n",
      "Epoch 32 - Training Loss: 0.012176130898296833\n",
      "Epoch 33 - Training Loss: 0.012010354548692703\n",
      "Epoch 34 - Training Loss: 0.012844947166740894\n",
      "Epoch 35 - Training Loss: 0.0118784224614501\n",
      "Epoch 36 - Training Loss: 0.014450120739638805\n",
      "Epoch 37 - Training Loss: 0.011482414789497852\n",
      "Epoch 38 - Training Loss: 0.011978236958384514\n",
      "Epoch 39 - Training Loss: 0.014551389962434769\n",
      "Epoch 40 - Training Loss: 0.013514156453311443\n",
      "Epoch 41 - Training Loss: 0.013382160104811192\n",
      "Epoch 42 - Training Loss: 0.01233602687716484\n",
      "Epoch 43 - Training Loss: 0.011708270758390427\n",
      "Epoch 44 - Training Loss: 0.012371683493256569\n",
      "Epoch 45 - Training Loss: 0.0131034255027771\n",
      "Epoch 46 - Training Loss: 0.012962432578206062\n",
      "Epoch 47 - Training Loss: 0.012356841936707497\n",
      "Epoch 48 - Training Loss: 0.011798812076449394\n",
      "Epoch 49 - Training Loss: 0.011906566098332405\n",
      "Epoch 50 - Training Loss: 0.012889367528259754\n",
      "Epoch 51 - Training Loss: 0.01272045448422432\n",
      "early stopping on epoch: 52\n",
      "Epoch 1 - Training Loss: 0.014177639037370682\n",
      "Epoch 2 - Training Loss: 0.012548374943435192\n",
      "Epoch 3 - Training Loss: 0.01298007182776928\n",
      "Epoch 4 - Training Loss: 0.01273110881447792\n",
      "Epoch 5 - Training Loss: 0.011862969025969505\n",
      "Epoch 6 - Training Loss: 0.012804410420358181\n",
      "Epoch 7 - Training Loss: 0.011959363706409931\n",
      "Epoch 8 - Training Loss: 0.013019372709095478\n",
      "Epoch 9 - Training Loss: 0.012263597920536995\n",
      "Epoch 10 - Training Loss: 0.012454809620976448\n",
      "Epoch 11 - Training Loss: 0.01407751627266407\n",
      "Epoch 12 - Training Loss: 0.012567033059895039\n",
      "Epoch 13 - Training Loss: 0.01234460063278675\n",
      "Epoch 14 - Training Loss: 0.011711135506629944\n",
      "Epoch 15 - Training Loss: 0.01346596609801054\n",
      "Epoch 16 - Training Loss: 0.011286835186183453\n",
      "Epoch 17 - Training Loss: 0.01131600420922041\n",
      "Epoch 18 - Training Loss: 0.011469913646578789\n",
      "Epoch 19 - Training Loss: 0.013547910377383232\n",
      "Epoch 20 - Training Loss: 0.012148356065154076\n",
      "Epoch 21 - Training Loss: 0.013408084399998188\n",
      "Epoch 22 - Training Loss: 0.014186951331794262\n",
      "Epoch 23 - Training Loss: 0.011901170946657658\n",
      "Epoch 24 - Training Loss: 0.012036309577524662\n",
      "Epoch 25 - Training Loss: 0.014134539291262627\n",
      "Epoch 26 - Training Loss: 0.013145226053893566\n",
      "Epoch 27 - Training Loss: 0.011984380893409252\n",
      "Epoch 28 - Training Loss: 0.012501171790063381\n",
      "Epoch 29 - Training Loss: 0.012242370285093784\n",
      "Epoch 30 - Training Loss: 0.011548680253326893\n",
      "Epoch 31 - Training Loss: 0.01277755293995142\n",
      "Epoch 32 - Training Loss: 0.012931141071021557\n",
      "Epoch 33 - Training Loss: 0.01182765793055296\n",
      "Epoch 34 - Training Loss: 0.012599273584783077\n",
      "Epoch 35 - Training Loss: 0.012190192006528378\n",
      "Epoch 36 - Training Loss: 0.012695425190031528\n",
      "early stopping on epoch: 37\n",
      "Epoch 1 - Training Loss: 0.01397529523819685\n",
      "Epoch 2 - Training Loss: 0.01227974146604538\n",
      "Epoch 3 - Training Loss: 0.011876835487782955\n",
      "Epoch 4 - Training Loss: 0.012725165113806725\n",
      "Epoch 5 - Training Loss: 0.011685785837471485\n",
      "Epoch 6 - Training Loss: 0.012295905500650406\n",
      "Epoch 7 - Training Loss: 0.011992807500064373\n",
      "Epoch 8 - Training Loss: 0.012363946996629238\n",
      "Epoch 9 - Training Loss: 0.01260070875287056\n",
      "Epoch 10 - Training Loss: 0.012349478900432587\n",
      "Epoch 11 - Training Loss: 0.013087882660329342\n",
      "early stopping on epoch: 12\n",
      "Epoch 1 - Training Loss: 0.012646390125155449\n",
      "Epoch 2 - Training Loss: 0.011763572692871094\n",
      "Epoch 3 - Training Loss: 0.012421397492289543\n",
      "Epoch 4 - Training Loss: 0.011662142351269722\n",
      "Epoch 5 - Training Loss: 0.01287365984171629\n",
      "Epoch 6 - Training Loss: 0.0123036103323102\n",
      "Epoch 7 - Training Loss: 0.013088008388876915\n",
      "Epoch 8 - Training Loss: 0.012231806293129921\n",
      "Epoch 9 - Training Loss: 0.013769039884209633\n",
      "Epoch 10 - Training Loss: 0.011867460794746876\n",
      "Epoch 11 - Training Loss: 0.012298554182052612\n",
      "Epoch 12 - Training Loss: 0.011559140868484974\n",
      "Epoch 13 - Training Loss: 0.012590103782713413\n",
      "Epoch 14 - Training Loss: 0.011607016436755657\n",
      "Epoch 15 - Training Loss: 0.012175203301012516\n",
      "Epoch 16 - Training Loss: 0.01299357507377863\n",
      "Epoch 17 - Training Loss: 0.013206226751208305\n",
      "Epoch 18 - Training Loss: 0.012386961840093136\n",
      "Epoch 19 - Training Loss: 0.011364766396582127\n",
      "Epoch 20 - Training Loss: 0.013387207873165607\n",
      "Epoch 21 - Training Loss: 0.012512268498539925\n",
      "Epoch 22 - Training Loss: 0.013315437361598015\n",
      "Epoch 23 - Training Loss: 0.013111707754433155\n",
      "Epoch 24 - Training Loss: 0.011912654154002666\n",
      "Epoch 25 - Training Loss: 0.01256096176803112\n",
      "Epoch 26 - Training Loss: 0.012742828577756882\n",
      "Epoch 27 - Training Loss: 0.013325422070920467\n",
      "Epoch 28 - Training Loss: 0.013134141452610493\n",
      "Epoch 29 - Training Loss: 0.0122055159881711\n",
      "Epoch 30 - Training Loss: 0.013366453349590302\n",
      "Epoch 31 - Training Loss: 0.01287813764065504\n",
      "Epoch 32 - Training Loss: 0.01182563602924347\n",
      "Epoch 33 - Training Loss: 0.011920079588890076\n",
      "Epoch 34 - Training Loss: 0.012877856381237507\n",
      "Epoch 35 - Training Loss: 0.012481668032705784\n",
      "Epoch 36 - Training Loss: 0.011927969753742218\n",
      "Epoch 37 - Training Loss: 0.013998843729496002\n",
      "Epoch 38 - Training Loss: 0.012197267264127731\n",
      "Epoch 39 - Training Loss: 0.010597875341773033\n",
      "Epoch 40 - Training Loss: 0.012279494665563107\n",
      "Epoch 41 - Training Loss: 0.01077775377780199\n",
      "Epoch 42 - Training Loss: 0.011333191767334938\n",
      "Epoch 43 - Training Loss: 0.011961251497268677\n",
      "Epoch 44 - Training Loss: 0.012365533038973808\n",
      "Epoch 45 - Training Loss: 0.012401808053255081\n",
      "Epoch 46 - Training Loss: 0.011666600592434406\n",
      "Epoch 47 - Training Loss: 0.013811556622385979\n",
      "Epoch 48 - Training Loss: 0.013890882022678852\n",
      "Epoch 49 - Training Loss: 0.01196110900491476\n",
      "Epoch 50 - Training Loss: 0.011152290739119053\n",
      "Epoch 51 - Training Loss: 0.011615588329732418\n",
      "Epoch 52 - Training Loss: 0.012143195606768131\n",
      "Epoch 53 - Training Loss: 0.011200396344065666\n",
      "Epoch 54 - Training Loss: 0.011949361301958561\n",
      "Epoch 55 - Training Loss: 0.011521516367793083\n",
      "Epoch 56 - Training Loss: 0.012881680391728878\n",
      "Epoch 57 - Training Loss: 0.011447612196207047\n",
      "Epoch 58 - Training Loss: 0.013485186733305454\n",
      "Epoch 59 - Training Loss: 0.013334372080862522\n",
      "Epoch 60 - Training Loss: 0.01197819784283638\n",
      "Epoch 61 - Training Loss: 0.012136169709265232\n",
      "Epoch 62 - Training Loss: 0.011922219768166542\n",
      "Epoch 63 - Training Loss: 0.012769666500389576\n",
      "Epoch 64 - Training Loss: 0.013359978795051575\n",
      "Epoch 65 - Training Loss: 0.011952665634453297\n",
      "Epoch 66 - Training Loss: 0.011962474323809147\n",
      "Epoch 67 - Training Loss: 0.011664272285997868\n",
      "Epoch 68 - Training Loss: 0.012267845682799816\n",
      "Epoch 69 - Training Loss: 0.01292081456631422\n",
      "Epoch 70 - Training Loss: 0.011338897980749607\n",
      "Epoch 71 - Training Loss: 0.011426292359828949\n",
      "Epoch 72 - Training Loss: 0.013366958126425743\n",
      "Epoch 73 - Training Loss: 0.013977335765957832\n",
      "Epoch 74 - Training Loss: 0.011891378089785576\n",
      "Epoch 75 - Training Loss: 0.012135366909205914\n",
      "Epoch 76 - Training Loss: 0.01300588995218277\n",
      "Epoch 77 - Training Loss: 0.012307686731219292\n",
      "Epoch 78 - Training Loss: 0.01213055569678545\n",
      "Epoch 79 - Training Loss: 0.012656553648412228\n",
      "Epoch 80 - Training Loss: 0.01236414723098278\n",
      "Epoch 81 - Training Loss: 0.01364800613373518\n",
      "Epoch 82 - Training Loss: 0.011953964829444885\n",
      "Epoch 83 - Training Loss: 0.011699741706252098\n",
      "Epoch 84 - Training Loss: 0.012969285249710083\n",
      "Epoch 85 - Training Loss: 0.012652107514441013\n",
      "Epoch 86 - Training Loss: 0.012213775888085365\n",
      "Epoch 87 - Training Loss: 0.012242773547768593\n",
      "Epoch 88 - Training Loss: 0.010980051942169666\n",
      "Epoch 89 - Training Loss: 0.013514683581888676\n",
      "Epoch 90 - Training Loss: 0.011461730115115643\n",
      "Epoch 91 - Training Loss: 0.012314032763242722\n",
      "Epoch 92 - Training Loss: 0.012326338328421116\n",
      "Epoch 93 - Training Loss: 0.012777326628565788\n",
      "Epoch 94 - Training Loss: 0.012768599204719067\n",
      "Epoch 95 - Training Loss: 0.011420969851315022\n",
      "Epoch 96 - Training Loss: 0.012225327081978321\n",
      "Epoch 97 - Training Loss: 0.01126092579215765\n",
      "Epoch 98 - Training Loss: 0.011539979837834835\n",
      "Epoch 99 - Training Loss: 0.01239604502916336\n",
      "Epoch 100 - Training Loss: 0.013731418177485466\n",
      "Epoch 1 - Training Loss: 0.011654283851385117\n",
      "Epoch 2 - Training Loss: 0.01151342410594225\n",
      "Epoch 3 - Training Loss: 0.011399319395422935\n",
      "Epoch 4 - Training Loss: 0.0121600441634655\n",
      "Epoch 5 - Training Loss: 0.011976183392107487\n",
      "Epoch 6 - Training Loss: 0.014778940007090569\n",
      "Epoch 7 - Training Loss: 0.011897648684680462\n",
      "Epoch 8 - Training Loss: 0.011879979632794857\n",
      "Epoch 9 - Training Loss: 0.013189843855798244\n",
      "Epoch 10 - Training Loss: 0.012024027295410633\n",
      "Epoch 11 - Training Loss: 0.01259017176926136\n",
      "Epoch 12 - Training Loss: 0.01247287355363369\n",
      "Epoch 13 - Training Loss: 0.0117781488224864\n",
      "Epoch 14 - Training Loss: 0.012549213133752346\n",
      "Epoch 15 - Training Loss: 0.013011776842176914\n",
      "Epoch 16 - Training Loss: 0.012869209982454777\n",
      "Epoch 17 - Training Loss: 0.013376983813941479\n",
      "Epoch 18 - Training Loss: 0.011888137087225914\n",
      "Epoch 19 - Training Loss: 0.012739443220198154\n",
      "Epoch 20 - Training Loss: 0.012329747900366783\n",
      "Epoch 21 - Training Loss: 0.014414184726774693\n",
      "Epoch 22 - Training Loss: 0.01257279422134161\n",
      "Epoch 23 - Training Loss: 0.013765343464910984\n",
      "Epoch 24 - Training Loss: 0.01267295703291893\n",
      "Epoch 25 - Training Loss: 0.012875311076641083\n",
      "Epoch 26 - Training Loss: 0.012124160304665565\n",
      "Epoch 27 - Training Loss: 0.012190192006528378\n",
      "Epoch 28 - Training Loss: 0.012134868651628494\n",
      "Epoch 29 - Training Loss: 0.012731165625154972\n",
      "Epoch 30 - Training Loss: 0.01370612345635891\n",
      "Epoch 31 - Training Loss: 0.01277140248566866\n",
      "Epoch 32 - Training Loss: 0.013119314797222614\n",
      "Epoch 33 - Training Loss: 0.012281677685678005\n",
      "Epoch 34 - Training Loss: 0.012507886625826359\n",
      "Epoch 35 - Training Loss: 0.011795605532824993\n",
      "Epoch 36 - Training Loss: 0.01188418734818697\n",
      "Epoch 37 - Training Loss: 0.011813469231128693\n",
      "Epoch 38 - Training Loss: 0.012143933214247227\n",
      "Epoch 39 - Training Loss: 0.012407785281538963\n",
      "Epoch 40 - Training Loss: 0.013161330483853817\n",
      "Epoch 41 - Training Loss: 0.011458617635071278\n",
      "Epoch 42 - Training Loss: 0.012739521451294422\n",
      "early stopping on epoch: 43\n",
      "Epoch 1 - Training Loss: 0.012742680497467518\n",
      "Epoch 2 - Training Loss: 0.011557715013623238\n",
      "Epoch 3 - Training Loss: 0.013337960466742516\n",
      "Epoch 4 - Training Loss: 0.0120682492852211\n",
      "Epoch 5 - Training Loss: 0.013859894126653671\n",
      "Epoch 6 - Training Loss: 0.01130366139113903\n",
      "Epoch 7 - Training Loss: 0.013023004867136478\n",
      "Epoch 8 - Training Loss: 0.012888569384813309\n",
      "Epoch 9 - Training Loss: 0.012953313998878002\n",
      "Epoch 10 - Training Loss: 0.012298977933824062\n",
      "Epoch 11 - Training Loss: 0.014052021317183971\n",
      "Epoch 12 - Training Loss: 0.011757565662264824\n",
      "Epoch 13 - Training Loss: 0.015019694343209267\n",
      "Epoch 14 - Training Loss: 0.011760645546019077\n",
      "Epoch 15 - Training Loss: 0.011283842846751213\n",
      "Epoch 16 - Training Loss: 0.013034890405833721\n",
      "Epoch 17 - Training Loss: 0.013248368166387081\n",
      "Epoch 18 - Training Loss: 0.0120585598051548\n",
      "Epoch 19 - Training Loss: 0.012776367366313934\n",
      "Epoch 20 - Training Loss: 0.013743421994149685\n",
      "Epoch 21 - Training Loss: 0.01201531384140253\n",
      "Epoch 22 - Training Loss: 0.01332548912614584\n",
      "Epoch 23 - Training Loss: 0.011600665748119354\n",
      "Epoch 24 - Training Loss: 0.010031755082309246\n",
      "Epoch 25 - Training Loss: 0.013294749893248081\n",
      "Epoch 26 - Training Loss: 0.012739812023937702\n",
      "Epoch 27 - Training Loss: 0.011631567031145096\n",
      "Epoch 28 - Training Loss: 0.012272290885448456\n",
      "Epoch 29 - Training Loss: 0.012117234990000725\n",
      "Epoch 30 - Training Loss: 0.013517007231712341\n",
      "Epoch 31 - Training Loss: 0.011449990794062614\n",
      "Epoch 32 - Training Loss: 0.013039758428931236\n",
      "Epoch 33 - Training Loss: 0.01198109332472086\n",
      "Epoch 34 - Training Loss: 0.01365668885409832\n",
      "Epoch 35 - Training Loss: 0.011235522106289864\n",
      "Epoch 36 - Training Loss: 0.012882833369076252\n",
      "Epoch 37 - Training Loss: 0.012947135604918003\n",
      "Epoch 38 - Training Loss: 0.013149013742804527\n",
      "Epoch 39 - Training Loss: 0.011862952262163162\n",
      "Epoch 40 - Training Loss: 0.012488440610468388\n",
      "Epoch 41 - Training Loss: 0.012967920862138271\n",
      "Epoch 42 - Training Loss: 0.012689957395195961\n",
      "Epoch 43 - Training Loss: 0.013221441768109798\n",
      "Epoch 44 - Training Loss: 0.01204514317214489\n",
      "Epoch 45 - Training Loss: 0.011778583750128746\n",
      "Epoch 46 - Training Loss: 0.01138700358569622\n",
      "Epoch 47 - Training Loss: 0.012682472355663776\n",
      "Epoch 48 - Training Loss: 0.012773316353559494\n",
      "Epoch 49 - Training Loss: 0.01165060419589281\n",
      "Epoch 50 - Training Loss: 0.012104805558919907\n",
      "Epoch 51 - Training Loss: 0.013184983283281326\n",
      "Epoch 52 - Training Loss: 0.011851325631141663\n",
      "Epoch 53 - Training Loss: 0.012201751582324505\n",
      "Epoch 54 - Training Loss: 0.012810752727091312\n",
      "Epoch 55 - Training Loss: 0.014697426930069923\n",
      "Epoch 56 - Training Loss: 0.012072245590388775\n",
      "Epoch 57 - Training Loss: 0.013755666092038155\n",
      "Epoch 58 - Training Loss: 0.01369499508291483\n",
      "Epoch 59 - Training Loss: 0.012068667449057102\n",
      "Epoch 60 - Training Loss: 0.011588217690587044\n",
      "Epoch 61 - Training Loss: 0.012166645377874374\n",
      "Epoch 62 - Training Loss: 0.01241977047175169\n",
      "Epoch 63 - Training Loss: 0.01178913377225399\n",
      "Epoch 64 - Training Loss: 0.01238672062754631\n",
      "Epoch 65 - Training Loss: 0.01307662669569254\n",
      "Epoch 66 - Training Loss: 0.011928178369998932\n",
      "Epoch 67 - Training Loss: 0.012639040127396584\n",
      "Epoch 68 - Training Loss: 0.012567111290991306\n",
      "Epoch 69 - Training Loss: 0.011696795001626015\n",
      "Epoch 70 - Training Loss: 0.012134714052081108\n",
      "Epoch 71 - Training Loss: 0.012791677378118038\n",
      "Epoch 72 - Training Loss: 0.012761560268700123\n",
      "Epoch 73 - Training Loss: 0.013064537197351456\n",
      "Epoch 74 - Training Loss: 0.011791182681918144\n",
      "Epoch 75 - Training Loss: 0.013837507925927639\n",
      "Epoch 76 - Training Loss: 0.012314604595303535\n",
      "Epoch 77 - Training Loss: 0.011003535240888596\n",
      "Epoch 78 - Training Loss: 0.012197702191770077\n",
      "Epoch 79 - Training Loss: 0.014452699571847916\n",
      "Epoch 80 - Training Loss: 0.01147325150668621\n",
      "Epoch 81 - Training Loss: 0.011737905442714691\n",
      "Epoch 82 - Training Loss: 0.01409285981208086\n",
      "Epoch 83 - Training Loss: 0.012421347200870514\n",
      "Epoch 84 - Training Loss: 0.013139702379703522\n",
      "Epoch 85 - Training Loss: 0.012432456947863102\n",
      "Epoch 86 - Training Loss: 0.012005011551082134\n",
      "Epoch 87 - Training Loss: 0.012825319543480873\n",
      "Epoch 88 - Training Loss: 0.013224591501057148\n",
      "Epoch 89 - Training Loss: 0.01135406456887722\n",
      "Epoch 90 - Training Loss: 0.011873563751578331\n",
      "Epoch 91 - Training Loss: 0.013426964171230793\n",
      "Epoch 92 - Training Loss: 0.01164967380464077\n",
      "Epoch 93 - Training Loss: 0.01240437664091587\n",
      "Epoch 94 - Training Loss: 0.012107918970286846\n",
      "Epoch 95 - Training Loss: 0.012552255764603615\n",
      "Epoch 96 - Training Loss: 0.012860400602221489\n",
      "Epoch 97 - Training Loss: 0.01228030864149332\n",
      "Epoch 98 - Training Loss: 0.012884940020740032\n",
      "Epoch 99 - Training Loss: 0.011776885017752647\n",
      "Epoch 100 - Training Loss: 0.013055727817118168\n",
      "Epoch 1 - Training Loss: 0.011835915967822075\n",
      "Epoch 2 - Training Loss: 0.013020694255828857\n",
      "Epoch 3 - Training Loss: 0.012946497648954391\n",
      "Epoch 4 - Training Loss: 0.013228514231741428\n",
      "Epoch 5 - Training Loss: 0.011613461188971996\n",
      "Epoch 6 - Training Loss: 0.012812980450689793\n",
      "Epoch 7 - Training Loss: 0.014569761231541634\n",
      "Epoch 8 - Training Loss: 0.012742259539663792\n",
      "Epoch 9 - Training Loss: 0.013026854954659939\n",
      "Epoch 10 - Training Loss: 0.013052831403911114\n",
      "Epoch 11 - Training Loss: 0.011289196088910103\n",
      "Epoch 12 - Training Loss: 0.012229696847498417\n",
      "Epoch 13 - Training Loss: 0.011065440252423286\n",
      "Epoch 14 - Training Loss: 0.012024510651826859\n",
      "Epoch 15 - Training Loss: 0.011495823971927166\n",
      "Epoch 16 - Training Loss: 0.013149702921509743\n",
      "Epoch 17 - Training Loss: 0.01233450323343277\n",
      "Epoch 18 - Training Loss: 0.012905844487249851\n",
      "Epoch 19 - Training Loss: 0.014159703627228737\n",
      "Epoch 20 - Training Loss: 0.0117406714707613\n",
      "Epoch 21 - Training Loss: 0.01338264625519514\n",
      "Epoch 22 - Training Loss: 0.011810654774308205\n",
      "Epoch 23 - Training Loss: 0.011544089764356613\n",
      "Epoch 24 - Training Loss: 0.012952103279531002\n",
      "Epoch 25 - Training Loss: 0.01270825695246458\n",
      "Epoch 26 - Training Loss: 0.012435661628842354\n",
      "Epoch 27 - Training Loss: 0.01309517864137888\n",
      "Epoch 28 - Training Loss: 0.01230446808040142\n",
      "Epoch 29 - Training Loss: 0.01217039953917265\n",
      "Epoch 30 - Training Loss: 0.012295406311750412\n",
      "Epoch 31 - Training Loss: 0.012511339969933033\n",
      "Epoch 32 - Training Loss: 0.0121046407148242\n",
      "Epoch 33 - Training Loss: 0.012762514874339104\n",
      "Epoch 34 - Training Loss: 0.011938919313251972\n",
      "Epoch 35 - Training Loss: 0.013645708560943604\n",
      "Epoch 36 - Training Loss: 0.012874598614871502\n",
      "Epoch 37 - Training Loss: 0.012320661917328835\n",
      "Epoch 38 - Training Loss: 0.011519500985741615\n",
      "Epoch 39 - Training Loss: 0.012887920252978802\n",
      "Epoch 40 - Training Loss: 0.011403986252844334\n",
      "Epoch 41 - Training Loss: 0.011491946876049042\n",
      "Epoch 42 - Training Loss: 0.012112519703805447\n",
      "Epoch 43 - Training Loss: 0.012946738861501217\n",
      "Epoch 44 - Training Loss: 0.014263974502682686\n",
      "Epoch 45 - Training Loss: 0.0127107547596097\n",
      "Epoch 46 - Training Loss: 0.013270665891468525\n",
      "Epoch 47 - Training Loss: 0.011636639945209026\n",
      "Epoch 48 - Training Loss: 0.012963967397809029\n",
      "Epoch 49 - Training Loss: 0.013498872518539429\n",
      "Epoch 50 - Training Loss: 0.011775513179600239\n",
      "Epoch 51 - Training Loss: 0.012905020266771317\n",
      "Epoch 52 - Training Loss: 0.012325471267104149\n",
      "Epoch 53 - Training Loss: 0.011938357725739479\n",
      "Epoch 54 - Training Loss: 0.013525242917239666\n",
      "Epoch 55 - Training Loss: 0.013216097839176655\n",
      "Epoch 56 - Training Loss: 0.013049431145191193\n",
      "Epoch 57 - Training Loss: 0.01335945725440979\n",
      "Epoch 58 - Training Loss: 0.013399573974311352\n",
      "Epoch 59 - Training Loss: 0.012007124722003937\n",
      "Epoch 60 - Training Loss: 0.013082699850201607\n",
      "early stopping on epoch: 61\n",
      "Epoch 1 - Training Loss: 0.012776837684214115\n",
      "Epoch 2 - Training Loss: 0.012075761333107948\n",
      "Epoch 3 - Training Loss: 0.012168306857347488\n",
      "Epoch 4 - Training Loss: 0.01235850527882576\n",
      "Epoch 5 - Training Loss: 0.012237554416060448\n",
      "Epoch 6 - Training Loss: 0.012964429333806038\n",
      "Epoch 7 - Training Loss: 0.013644321821630001\n",
      "Epoch 8 - Training Loss: 0.011505665257573128\n",
      "Epoch 9 - Training Loss: 0.01215597614645958\n",
      "Epoch 10 - Training Loss: 0.014357280917465687\n",
      "Epoch 11 - Training Loss: 0.012767740525305271\n",
      "Epoch 12 - Training Loss: 0.0128840496763587\n",
      "Epoch 13 - Training Loss: 0.011752222664654255\n",
      "Epoch 14 - Training Loss: 0.012161952443420887\n",
      "Epoch 15 - Training Loss: 0.011782588437199593\n",
      "Epoch 16 - Training Loss: 0.011947409249842167\n",
      "Epoch 17 - Training Loss: 0.012019779533147812\n",
      "Epoch 18 - Training Loss: 0.011253070086240768\n",
      "Epoch 19 - Training Loss: 0.012812132015824318\n",
      "Epoch 20 - Training Loss: 0.012249093502759933\n",
      "Epoch 21 - Training Loss: 0.013190372847020626\n",
      "Epoch 22 - Training Loss: 0.013221978209912777\n",
      "Epoch 23 - Training Loss: 0.011944872327148914\n",
      "Epoch 24 - Training Loss: 0.013532075099647045\n",
      "Epoch 25 - Training Loss: 0.012553549371659756\n",
      "Epoch 26 - Training Loss: 0.012202735058963299\n",
      "Epoch 27 - Training Loss: 0.012362174689769745\n",
      "Epoch 28 - Training Loss: 0.012749173678457737\n",
      "early stopping on epoch: 29\n",
      "Epoch 1 - Training Loss: 0.011075690388679504\n",
      "Epoch 2 - Training Loss: 0.0113199008628726\n",
      "Epoch 3 - Training Loss: 0.012749413959681988\n",
      "Epoch 4 - Training Loss: 0.012092356570065022\n",
      "Epoch 5 - Training Loss: 0.012026713229715824\n",
      "Epoch 6 - Training Loss: 0.01226028986275196\n",
      "Epoch 7 - Training Loss: 0.01217931229621172\n",
      "Epoch 8 - Training Loss: 0.012202093377709389\n",
      "Epoch 9 - Training Loss: 0.012245383113622665\n",
      "Epoch 10 - Training Loss: 0.012993939220905304\n",
      "Epoch 11 - Training Loss: 0.011845385655760765\n",
      "Epoch 12 - Training Loss: 0.012628810480237007\n",
      "early stopping on epoch: 13\n",
      "Epoch 1 - Training Loss: 0.01216151099652052\n",
      "Epoch 2 - Training Loss: 0.012094530276954174\n",
      "Epoch 3 - Training Loss: 0.013136632740497589\n",
      "Epoch 4 - Training Loss: 0.012632974423468113\n",
      "Epoch 5 - Training Loss: 0.013209637254476547\n",
      "Epoch 6 - Training Loss: 0.010829213075339794\n",
      "Epoch 7 - Training Loss: 0.011977375485002995\n",
      "Epoch 8 - Training Loss: 0.012183891609311104\n",
      "Epoch 9 - Training Loss: 0.010950920172035694\n",
      "Epoch 10 - Training Loss: 0.011677442118525505\n",
      "Epoch 11 - Training Loss: 0.011326733976602554\n",
      "Epoch 12 - Training Loss: 0.012088405899703503\n",
      "Epoch 13 - Training Loss: 0.012254848144948483\n",
      "Epoch 14 - Training Loss: 0.011727151460945606\n",
      "Epoch 15 - Training Loss: 0.012332321144640446\n",
      "Epoch 16 - Training Loss: 0.012564201839268208\n",
      "Epoch 17 - Training Loss: 0.012615119107067585\n",
      "Epoch 18 - Training Loss: 0.011455941013991833\n",
      "Epoch 19 - Training Loss: 0.011583639308810234\n",
      "Epoch 20 - Training Loss: 0.011421449482440948\n",
      "Epoch 21 - Training Loss: 0.013210381381213665\n",
      "Epoch 22 - Training Loss: 0.01354488730430603\n",
      "Epoch 23 - Training Loss: 0.012069826945662498\n",
      "Epoch 24 - Training Loss: 0.012114091776311398\n",
      "Epoch 25 - Training Loss: 0.01334074791520834\n",
      "Epoch 26 - Training Loss: 0.012329066172242165\n",
      "Epoch 27 - Training Loss: 0.013689341023564339\n",
      "Epoch 28 - Training Loss: 0.012568592093884945\n",
      "Epoch 29 - Training Loss: 0.012822652235627174\n",
      "Epoch 30 - Training Loss: 0.013242139481008053\n",
      "Epoch 31 - Training Loss: 0.011283250525593758\n",
      "Epoch 32 - Training Loss: 0.012069318443536758\n",
      "Epoch 33 - Training Loss: 0.013199704699218273\n",
      "Epoch 34 - Training Loss: 0.012192405760288239\n",
      "Epoch 35 - Training Loss: 0.01343612652271986\n",
      "Epoch 36 - Training Loss: 0.012621397152543068\n",
      "Epoch 37 - Training Loss: 0.012159681878983974\n",
      "Epoch 38 - Training Loss: 0.011718961410224438\n",
      "Epoch 39 - Training Loss: 0.01291341707110405\n",
      "Epoch 40 - Training Loss: 0.013104104436933994\n",
      "Epoch 41 - Training Loss: 0.011350422166287899\n",
      "Epoch 42 - Training Loss: 0.012406495399773121\n",
      "Epoch 43 - Training Loss: 0.011599195189774036\n",
      "Epoch 44 - Training Loss: 0.012589297257363796\n",
      "Epoch 45 - Training Loss: 0.011626245453953743\n",
      "Epoch 46 - Training Loss: 0.011972064152359962\n",
      "early stopping on epoch: 47\n",
      "Epoch 1 - Training Loss: 0.012609874829649925\n",
      "Epoch 2 - Training Loss: 0.012075237929821014\n",
      "Epoch 3 - Training Loss: 0.01230063196271658\n",
      "Epoch 4 - Training Loss: 0.011845581233501434\n",
      "Epoch 5 - Training Loss: 0.013151714578270912\n",
      "Epoch 6 - Training Loss: 0.012281190603971481\n",
      "Epoch 7 - Training Loss: 0.012762920930981636\n",
      "Epoch 8 - Training Loss: 0.011919165030121803\n",
      "Epoch 9 - Training Loss: 0.013364710845053196\n",
      "Epoch 10 - Training Loss: 0.013206446543335915\n",
      "Epoch 11 - Training Loss: 0.011411433108150959\n",
      "Epoch 12 - Training Loss: 0.011422884650528431\n",
      "Epoch 13 - Training Loss: 0.010711699724197388\n",
      "Epoch 14 - Training Loss: 0.011305355466902256\n",
      "Epoch 15 - Training Loss: 0.011981426738202572\n",
      "Epoch 16 - Training Loss: 0.012328277342021465\n",
      "Epoch 17 - Training Loss: 0.012523592449724674\n",
      "Epoch 18 - Training Loss: 0.012257406488060951\n",
      "Epoch 19 - Training Loss: 0.012829563580453396\n",
      "Epoch 20 - Training Loss: 0.012826504185795784\n",
      "Epoch 21 - Training Loss: 0.011042329482734203\n",
      "Epoch 22 - Training Loss: 0.013276948593556881\n",
      "Epoch 23 - Training Loss: 0.012485734187066555\n",
      "Epoch 24 - Training Loss: 0.011755562387406826\n",
      "Epoch 25 - Training Loss: 0.012029703706502914\n",
      "Epoch 26 - Training Loss: 0.012204986065626144\n",
      "Epoch 27 - Training Loss: 0.011763663031160831\n",
      "Epoch 28 - Training Loss: 0.012975881807506084\n",
      "Epoch 29 - Training Loss: 0.01197767723351717\n",
      "Epoch 30 - Training Loss: 0.011900230310857296\n",
      "Epoch 31 - Training Loss: 0.011364438571035862\n",
      "Epoch 32 - Training Loss: 0.013462194241583347\n",
      "Epoch 33 - Training Loss: 0.0115964999422431\n",
      "Epoch 34 - Training Loss: 0.013540457002818584\n",
      "Epoch 35 - Training Loss: 0.012007467448711395\n",
      "Epoch 36 - Training Loss: 0.012455369345843792\n",
      "Epoch 37 - Training Loss: 0.013026831671595573\n",
      "Epoch 38 - Training Loss: 0.011617952957749367\n",
      "Epoch 39 - Training Loss: 0.012132023461163044\n",
      "Epoch 40 - Training Loss: 0.01230277493596077\n",
      "Epoch 41 - Training Loss: 0.013207562267780304\n",
      "Epoch 42 - Training Loss: 0.012425316497683525\n",
      "Epoch 43 - Training Loss: 0.010683063417673111\n",
      "Epoch 44 - Training Loss: 0.0143178915604949\n",
      "Epoch 45 - Training Loss: 0.012090807780623436\n",
      "Epoch 46 - Training Loss: 0.011734944768249989\n",
      "Epoch 47 - Training Loss: 0.01370153110474348\n",
      "Epoch 48 - Training Loss: 0.013063081540167332\n",
      "Epoch 49 - Training Loss: 0.012194986455142498\n",
      "Epoch 50 - Training Loss: 0.012973173521459103\n",
      "Epoch 51 - Training Loss: 0.011636443436145782\n",
      "Epoch 52 - Training Loss: 0.013060761615633965\n",
      "Epoch 53 - Training Loss: 0.012346797622740269\n",
      "Epoch 54 - Training Loss: 0.011743434704840183\n",
      "Epoch 55 - Training Loss: 0.01256905123591423\n",
      "Epoch 56 - Training Loss: 0.011655349284410477\n",
      "Epoch 57 - Training Loss: 0.01241657417267561\n",
      "Epoch 58 - Training Loss: 0.012795842252671719\n",
      "early stopping on epoch: 59\n",
      "Epoch 1 - Training Loss: 0.011322533711791039\n",
      "Epoch 2 - Training Loss: 0.014216643758118153\n",
      "Epoch 3 - Training Loss: 0.011899348348379135\n",
      "Epoch 4 - Training Loss: 0.01376723125576973\n",
      "Epoch 5 - Training Loss: 0.012606507167220116\n",
      "Epoch 6 - Training Loss: 0.012145625427365303\n",
      "Epoch 7 - Training Loss: 0.012553458102047443\n",
      "Epoch 8 - Training Loss: 0.012631301768124104\n",
      "Epoch 9 - Training Loss: 0.012958914041519165\n",
      "Epoch 10 - Training Loss: 0.012803163379430771\n",
      "Epoch 11 - Training Loss: 0.01318436674773693\n",
      "Epoch 12 - Training Loss: 0.012963331304490566\n",
      "Epoch 13 - Training Loss: 0.013173992745578289\n",
      "Epoch 14 - Training Loss: 0.01329207792878151\n",
      "early stopping on epoch: 15\n",
      "Epoch 1 - Training Loss: 0.013857484795153141\n",
      "Epoch 2 - Training Loss: 0.012250353582203388\n",
      "Epoch 3 - Training Loss: 0.012216865085065365\n",
      "Epoch 4 - Training Loss: 0.011787784285843372\n",
      "Epoch 5 - Training Loss: 0.012662054970860481\n",
      "Epoch 6 - Training Loss: 0.01241234689950943\n",
      "Epoch 7 - Training Loss: 0.013205472379922867\n",
      "Epoch 8 - Training Loss: 0.012516733258962631\n",
      "Epoch 9 - Training Loss: 0.012711984105408192\n",
      "Epoch 10 - Training Loss: 0.013026895932853222\n",
      "Epoch 11 - Training Loss: 0.012125152163207531\n",
      "early stopping on epoch: 12\n",
      "Epoch 1 - Training Loss: 0.011320788413286209\n",
      "Epoch 2 - Training Loss: 0.012894808314740658\n",
      "Epoch 3 - Training Loss: 0.01316797360777855\n",
      "Epoch 4 - Training Loss: 0.01314840279519558\n",
      "Epoch 5 - Training Loss: 0.013234911486506462\n",
      "Epoch 6 - Training Loss: 0.01364862360060215\n",
      "Epoch 7 - Training Loss: 0.013276754878461361\n",
      "Epoch 8 - Training Loss: 0.011475379578769207\n",
      "Epoch 9 - Training Loss: 0.012084952555596828\n",
      "Epoch 10 - Training Loss: 0.013281588442623615\n",
      "Epoch 11 - Training Loss: 0.011909673921763897\n",
      "Epoch 12 - Training Loss: 0.011704035103321075\n",
      "Epoch 13 - Training Loss: 0.011828549206256866\n",
      "Epoch 14 - Training Loss: 0.012464161962270737\n",
      "Epoch 15 - Training Loss: 0.012362200766801834\n",
      "Epoch 16 - Training Loss: 0.012209109961986542\n",
      "Epoch 17 - Training Loss: 0.01204006839543581\n",
      "Epoch 18 - Training Loss: 0.014073808677494526\n",
      "Epoch 19 - Training Loss: 0.01373080164194107\n",
      "Epoch 20 - Training Loss: 0.011696326546370983\n",
      "Epoch 21 - Training Loss: 0.01259289775043726\n",
      "Epoch 22 - Training Loss: 0.011820460669696331\n",
      "Epoch 23 - Training Loss: 0.01248733326792717\n",
      "Epoch 24 - Training Loss: 0.012826231308281422\n",
      "Epoch 25 - Training Loss: 0.013651845045387745\n",
      "Epoch 26 - Training Loss: 0.011516415514051914\n",
      "Epoch 27 - Training Loss: 0.013073557056486607\n",
      "Epoch 28 - Training Loss: 0.011746253818273544\n",
      "Epoch 29 - Training Loss: 0.011618322692811489\n",
      "Epoch 30 - Training Loss: 0.011806439608335495\n",
      "Epoch 31 - Training Loss: 0.012473623268306255\n",
      "Epoch 32 - Training Loss: 0.01350525300949812\n",
      "Epoch 33 - Training Loss: 0.012652983888983727\n",
      "Epoch 34 - Training Loss: 0.012454825453460217\n",
      "Epoch 35 - Training Loss: 0.01165793091058731\n",
      "Epoch 36 - Training Loss: 0.011869887821376324\n",
      "Epoch 37 - Training Loss: 0.01269743125885725\n",
      "Epoch 38 - Training Loss: 0.012592129409313202\n",
      "Epoch 39 - Training Loss: 0.012828500010073185\n",
      "Epoch 40 - Training Loss: 0.01265785750001669\n",
      "Epoch 41 - Training Loss: 0.013115637004375458\n",
      "Epoch 42 - Training Loss: 0.011435420252382755\n",
      "Epoch 43 - Training Loss: 0.01248251274228096\n",
      "Epoch 44 - Training Loss: 0.012832460924983025\n",
      "Epoch 45 - Training Loss: 0.01128788199275732\n",
      "Epoch 46 - Training Loss: 0.013613511808216572\n",
      "Epoch 47 - Training Loss: 0.012183832004666328\n",
      "Epoch 48 - Training Loss: 0.01070101372897625\n",
      "Epoch 49 - Training Loss: 0.012409492395818233\n",
      "Epoch 50 - Training Loss: 0.011635036207735538\n",
      "Epoch 51 - Training Loss: 0.013514972291886806\n",
      "Epoch 52 - Training Loss: 0.011473155580461025\n",
      "Epoch 53 - Training Loss: 0.012189170345664024\n",
      "Epoch 54 - Training Loss: 0.010397014208137989\n",
      "Epoch 55 - Training Loss: 0.012660096399486065\n",
      "Epoch 56 - Training Loss: 0.012144681997597218\n",
      "Epoch 57 - Training Loss: 0.013711124658584595\n",
      "Epoch 58 - Training Loss: 0.011834178119897842\n",
      "Epoch 59 - Training Loss: 0.011210900731384754\n",
      "Epoch 60 - Training Loss: 0.013905677944421768\n",
      "Epoch 61 - Training Loss: 0.012309610843658447\n",
      "Epoch 62 - Training Loss: 0.012332342565059662\n",
      "Epoch 63 - Training Loss: 0.012444577179849148\n",
      "Epoch 64 - Training Loss: 0.01049546804279089\n",
      "Epoch 65 - Training Loss: 0.013770061545073986\n",
      "Epoch 66 - Training Loss: 0.012076256796717644\n",
      "Epoch 67 - Training Loss: 0.011978434398770332\n",
      "Epoch 68 - Training Loss: 0.01420617289841175\n",
      "Epoch 69 - Training Loss: 0.012134049087762833\n",
      "Epoch 70 - Training Loss: 0.011874794960021973\n",
      "Epoch 71 - Training Loss: 0.012800329364836216\n",
      "Epoch 72 - Training Loss: 0.013582183979451656\n",
      "Epoch 73 - Training Loss: 0.012446138076484203\n",
      "Epoch 74 - Training Loss: 0.012948541902005672\n",
      "Epoch 75 - Training Loss: 0.010529845952987671\n",
      "Epoch 76 - Training Loss: 0.01302086841315031\n",
      "Epoch 77 - Training Loss: 0.013052701018750668\n",
      "Epoch 78 - Training Loss: 0.012354723177850246\n",
      "Epoch 79 - Training Loss: 0.011803782545030117\n",
      "Epoch 80 - Training Loss: 0.01216855738312006\n",
      "Epoch 81 - Training Loss: 0.013000603765249252\n",
      "Epoch 82 - Training Loss: 0.012332425452768803\n",
      "Epoch 83 - Training Loss: 0.013168753124773502\n",
      "Epoch 84 - Training Loss: 0.012919248081743717\n",
      "Epoch 85 - Training Loss: 0.01209837943315506\n",
      "Epoch 86 - Training Loss: 0.012868027202785015\n",
      "Epoch 87 - Training Loss: 0.011189969256520271\n",
      "Epoch 88 - Training Loss: 0.01273810863494873\n",
      "Epoch 89 - Training Loss: 0.013526185415685177\n",
      "Epoch 90 - Training Loss: 0.012286212295293808\n",
      "Epoch 91 - Training Loss: 0.012974033132195473\n",
      "Epoch 92 - Training Loss: 0.013235476799309254\n",
      "Epoch 93 - Training Loss: 0.011260390281677246\n",
      "Epoch 94 - Training Loss: 0.012439107522368431\n",
      "Epoch 95 - Training Loss: 0.01188945397734642\n",
      "Epoch 96 - Training Loss: 0.011801088228821754\n",
      "Epoch 97 - Training Loss: 0.012979447841644287\n",
      "Epoch 98 - Training Loss: 0.01224435679614544\n",
      "Epoch 99 - Training Loss: 0.013496825471520424\n",
      "Epoch 100 - Training Loss: 0.013150406070053577\n",
      "Epoch 1 - Training Loss: 0.01265787798911333\n",
      "Epoch 2 - Training Loss: 0.01233548205345869\n",
      "Epoch 3 - Training Loss: 0.011270093731582165\n",
      "Epoch 4 - Training Loss: 0.01253418903797865\n",
      "Epoch 5 - Training Loss: 0.012270527891814709\n",
      "Epoch 6 - Training Loss: 0.012010429985821247\n",
      "Epoch 7 - Training Loss: 0.012244394980370998\n",
      "Epoch 8 - Training Loss: 0.011839387007057667\n",
      "Epoch 9 - Training Loss: 0.012608073651790619\n",
      "Epoch 10 - Training Loss: 0.01061339396983385\n",
      "Epoch 11 - Training Loss: 0.013424107804894447\n",
      "Epoch 12 - Training Loss: 0.01161953154951334\n",
      "Epoch 13 - Training Loss: 0.011747896671295166\n",
      "Epoch 14 - Training Loss: 0.013134581968188286\n",
      "Epoch 15 - Training Loss: 0.011116080917418003\n",
      "Epoch 16 - Training Loss: 0.012486914172768593\n",
      "Epoch 17 - Training Loss: 0.011878774501383305\n",
      "Epoch 18 - Training Loss: 0.010713732801377773\n",
      "Epoch 19 - Training Loss: 0.013087157160043716\n",
      "Epoch 20 - Training Loss: 0.01229204423725605\n",
      "Epoch 21 - Training Loss: 0.012646729126572609\n",
      "Epoch 22 - Training Loss: 0.012163545936346054\n",
      "Epoch 23 - Training Loss: 0.012409455142915249\n",
      "Epoch 24 - Training Loss: 0.013373848050832748\n",
      "Epoch 25 - Training Loss: 0.012674396857619286\n",
      "Epoch 26 - Training Loss: 0.01243335660547018\n",
      "Epoch 27 - Training Loss: 0.01186309289187193\n",
      "Epoch 28 - Training Loss: 0.012279283255338669\n",
      "Epoch 29 - Training Loss: 0.012511089444160461\n",
      "Epoch 30 - Training Loss: 0.012248359620571136\n",
      "Epoch 31 - Training Loss: 0.01265373919159174\n",
      "Epoch 32 - Training Loss: 0.012651831842958927\n",
      "Epoch 33 - Training Loss: 0.011540823616087437\n",
      "Epoch 34 - Training Loss: 0.012477456592023373\n",
      "Epoch 35 - Training Loss: 0.01261216402053833\n",
      "Epoch 36 - Training Loss: 0.01269198302179575\n",
      "early stopping on epoch: 37\n",
      "Epoch 1 - Training Loss: 0.012879214249551296\n",
      "Epoch 2 - Training Loss: 0.012356657534837723\n",
      "Epoch 3 - Training Loss: 0.012023771181702614\n",
      "Epoch 4 - Training Loss: 0.011336089111864567\n",
      "Epoch 5 - Training Loss: 0.011791449971497059\n",
      "Epoch 6 - Training Loss: 0.011969931423664093\n",
      "Epoch 7 - Training Loss: 0.011348198167979717\n",
      "Epoch 8 - Training Loss: 0.012284858152270317\n",
      "Epoch 9 - Training Loss: 0.011869161389768124\n",
      "Epoch 10 - Training Loss: 0.011664199642837048\n",
      "Epoch 11 - Training Loss: 0.012593061663210392\n",
      "Epoch 12 - Training Loss: 0.012683534994721413\n",
      "Epoch 13 - Training Loss: 0.011283342726528645\n",
      "Epoch 14 - Training Loss: 0.012040364556014538\n",
      "Epoch 15 - Training Loss: 0.013028569519519806\n",
      "Epoch 16 - Training Loss: 0.012617521919310093\n",
      "Epoch 17 - Training Loss: 0.013330267742276192\n",
      "Epoch 18 - Training Loss: 0.012760593555867672\n",
      "Epoch 19 - Training Loss: 0.011681443080306053\n",
      "Epoch 20 - Training Loss: 0.012700592167675495\n",
      "Epoch 21 - Training Loss: 0.011928047053515911\n",
      "Epoch 22 - Training Loss: 0.012538870796561241\n",
      "Epoch 23 - Training Loss: 0.014534972608089447\n",
      "Epoch 24 - Training Loss: 0.013185660354793072\n",
      "Epoch 25 - Training Loss: 0.01220643799751997\n",
      "Epoch 26 - Training Loss: 0.011040509678423405\n",
      "Epoch 27 - Training Loss: 0.012642432004213333\n",
      "Epoch 28 - Training Loss: 0.014671972952783108\n",
      "Epoch 29 - Training Loss: 0.012090014293789864\n",
      "Epoch 30 - Training Loss: 0.012457987293601036\n",
      "Epoch 31 - Training Loss: 0.0127224987372756\n",
      "Epoch 32 - Training Loss: 0.012051211670041084\n",
      "Epoch 33 - Training Loss: 0.011919199489057064\n",
      "Epoch 34 - Training Loss: 0.012095768935978413\n",
      "Epoch 35 - Training Loss: 0.012025928124785423\n",
      "Epoch 36 - Training Loss: 0.012839654460549355\n",
      "Epoch 37 - Training Loss: 0.01116595882922411\n",
      "Epoch 38 - Training Loss: 0.012970304116606712\n",
      "Epoch 39 - Training Loss: 0.013601323589682579\n",
      "Epoch 40 - Training Loss: 0.010844266042113304\n",
      "Epoch 41 - Training Loss: 0.012670917436480522\n",
      "Epoch 42 - Training Loss: 0.011694761924445629\n",
      "Epoch 43 - Training Loss: 0.012217016890645027\n",
      "Epoch 44 - Training Loss: 0.011967968195676804\n",
      "Epoch 45 - Training Loss: 0.011567680165171623\n",
      "Epoch 46 - Training Loss: 0.012072618119418621\n",
      "Epoch 47 - Training Loss: 0.011768301017582417\n",
      "Epoch 48 - Training Loss: 0.012504705227911472\n",
      "Epoch 49 - Training Loss: 0.011325345374643803\n",
      "Epoch 50 - Training Loss: 0.013907104730606079\n",
      "Epoch 51 - Training Loss: 0.011423125863075256\n",
      "Epoch 52 - Training Loss: 0.012921142391860485\n",
      "Epoch 53 - Training Loss: 0.011887493543326855\n",
      "Epoch 54 - Training Loss: 0.01283494383096695\n",
      "Epoch 55 - Training Loss: 0.01212202850729227\n",
      "Epoch 56 - Training Loss: 0.011267866007983685\n",
      "Epoch 57 - Training Loss: 0.01206965371966362\n",
      "Epoch 58 - Training Loss: 0.012749149464070797\n",
      "Epoch 59 - Training Loss: 0.012811101973056793\n",
      "Epoch 60 - Training Loss: 0.011972050182521343\n",
      "Epoch 61 - Training Loss: 0.011989687569439411\n",
      "Epoch 62 - Training Loss: 0.01127673964947462\n",
      "early stopping on epoch: 63\n",
      "Epoch 1 - Training Loss: 0.013399967923760414\n",
      "Epoch 2 - Training Loss: 0.012556029483675957\n",
      "Epoch 3 - Training Loss: 0.012546958401799202\n",
      "Epoch 4 - Training Loss: 0.011310772970318794\n",
      "Epoch 5 - Training Loss: 0.012501242570579052\n",
      "Epoch 6 - Training Loss: 0.012759900651872158\n",
      "Epoch 7 - Training Loss: 0.01180278230458498\n",
      "Epoch 8 - Training Loss: 0.012761587277054787\n",
      "Epoch 9 - Training Loss: 0.01190052181482315\n",
      "Epoch 10 - Training Loss: 0.0121805090457201\n",
      "Epoch 11 - Training Loss: 0.012184797786176205\n",
      "Epoch 12 - Training Loss: 0.012121662497520447\n",
      "Epoch 13 - Training Loss: 0.010959751904010773\n",
      "Epoch 14 - Training Loss: 0.011636966839432716\n",
      "Epoch 15 - Training Loss: 0.013197270222008228\n",
      "Epoch 16 - Training Loss: 0.01212964579463005\n",
      "Epoch 17 - Training Loss: 0.012090178206562996\n",
      "Epoch 18 - Training Loss: 0.012380113825201988\n",
      "Epoch 19 - Training Loss: 0.014085175469517708\n",
      "Epoch 20 - Training Loss: 0.010937077924609184\n",
      "Epoch 21 - Training Loss: 0.012227925471961498\n",
      "Epoch 22 - Training Loss: 0.011779465712606907\n",
      "Epoch 23 - Training Loss: 0.011552409268915653\n",
      "Epoch 24 - Training Loss: 0.012227128259837627\n",
      "Epoch 25 - Training Loss: 0.01219321507960558\n",
      "Epoch 26 - Training Loss: 0.011897305026650429\n",
      "Epoch 27 - Training Loss: 0.011656232178211212\n",
      "Epoch 28 - Training Loss: 0.011340280063450336\n",
      "Epoch 29 - Training Loss: 0.012464296072721481\n",
      "Epoch 30 - Training Loss: 0.011349687352776527\n",
      "early stopping on epoch: 31\n",
      "Epoch 1 - Training Loss: 0.011502313427627087\n",
      "Epoch 2 - Training Loss: 0.012770416215062141\n",
      "Epoch 3 - Training Loss: 0.012019082903862\n",
      "Epoch 4 - Training Loss: 0.011830667965114117\n",
      "Epoch 5 - Training Loss: 0.012949625961482525\n",
      "Epoch 6 - Training Loss: 0.011434365063905716\n",
      "Epoch 7 - Training Loss: 0.012332658283412457\n",
      "Epoch 8 - Training Loss: 0.011246182024478912\n",
      "Epoch 9 - Training Loss: 0.012778385542333126\n",
      "Epoch 10 - Training Loss: 0.013709411956369877\n",
      "Epoch 11 - Training Loss: 0.011799449101090431\n",
      "Epoch 12 - Training Loss: 0.013429632410407066\n",
      "Epoch 13 - Training Loss: 0.012059644795954227\n",
      "Epoch 14 - Training Loss: 0.012349083088338375\n",
      "Epoch 15 - Training Loss: 0.01200635451823473\n",
      "Epoch 16 - Training Loss: 0.013749070465564728\n",
      "Epoch 17 - Training Loss: 0.01171945221722126\n",
      "Epoch 18 - Training Loss: 0.01312083937227726\n",
      "Epoch 19 - Training Loss: 0.013407452963292599\n",
      "Epoch 20 - Training Loss: 0.012164777144789696\n",
      "Epoch 21 - Training Loss: 0.012171627022325993\n",
      "Epoch 22 - Training Loss: 0.01238735020160675\n",
      "Epoch 23 - Training Loss: 0.012171097099781036\n",
      "Epoch 24 - Training Loss: 0.012638887390494347\n",
      "Epoch 25 - Training Loss: 0.012579334899783134\n",
      "Epoch 26 - Training Loss: 0.013063514605164528\n",
      "Epoch 27 - Training Loss: 0.012933731079101562\n",
      "early stopping on epoch: 28\n",
      "Epoch 1 - Training Loss: 0.012093029916286469\n",
      "Epoch 2 - Training Loss: 0.01207679882645607\n",
      "Epoch 3 - Training Loss: 0.011213849298655987\n",
      "Epoch 4 - Training Loss: 0.011909144930541515\n",
      "Epoch 5 - Training Loss: 0.012936512939631939\n",
      "Epoch 6 - Training Loss: 0.01237559039145708\n",
      "Epoch 7 - Training Loss: 0.01323397271335125\n",
      "Epoch 8 - Training Loss: 0.013395282439887524\n",
      "Epoch 9 - Training Loss: 0.012374567799270153\n",
      "Epoch 10 - Training Loss: 0.013534226454794407\n",
      "Epoch 11 - Training Loss: 0.012270093895494938\n",
      "Epoch 12 - Training Loss: 0.012886891141533852\n",
      "Epoch 13 - Training Loss: 0.013431531377136707\n",
      "Epoch 14 - Training Loss: 0.013162938877940178\n",
      "Epoch 15 - Training Loss: 0.012600084766745567\n",
      "Epoch 16 - Training Loss: 0.012516428716480732\n",
      "early stopping on epoch: 17\n",
      "Epoch 1 - Training Loss: 0.012978493236005306\n",
      "Epoch 2 - Training Loss: 0.012060694396495819\n",
      "Epoch 3 - Training Loss: 0.013015061616897583\n",
      "Epoch 4 - Training Loss: 0.011215421371161938\n",
      "Epoch 5 - Training Loss: 0.01199725829064846\n",
      "Epoch 6 - Training Loss: 0.01213478296995163\n",
      "Epoch 7 - Training Loss: 0.014384160749614239\n",
      "Epoch 8 - Training Loss: 0.01220021490007639\n",
      "Epoch 9 - Training Loss: 0.013132385909557343\n",
      "Epoch 10 - Training Loss: 0.01194677222520113\n",
      "Epoch 11 - Training Loss: 0.012972615659236908\n",
      "Epoch 12 - Training Loss: 0.013279270380735397\n",
      "Epoch 13 - Training Loss: 0.014085102826356888\n",
      "Epoch 14 - Training Loss: 0.013583434745669365\n",
      "Epoch 15 - Training Loss: 0.012892549857497215\n",
      "Epoch 16 - Training Loss: 0.013351387344300747\n",
      "Epoch 17 - Training Loss: 0.013636818155646324\n",
      "Epoch 18 - Training Loss: 0.013467518612742424\n",
      "Epoch 19 - Training Loss: 0.01290032360702753\n",
      "Epoch 20 - Training Loss: 0.013018657453358173\n",
      "Epoch 21 - Training Loss: 0.012594682164490223\n",
      "early stopping on epoch: 22\n",
      "Epoch 1 - Training Loss: 0.012302286922931671\n",
      "Epoch 2 - Training Loss: 0.011953519657254219\n",
      "Epoch 3 - Training Loss: 0.013348489068448544\n",
      "Epoch 4 - Training Loss: 0.012717590667307377\n",
      "Epoch 5 - Training Loss: 0.01209086924791336\n",
      "Epoch 6 - Training Loss: 0.013099106028676033\n",
      "Epoch 7 - Training Loss: 0.013179629109799862\n",
      "Epoch 8 - Training Loss: 0.012401274405419827\n",
      "Epoch 9 - Training Loss: 0.013030249625444412\n",
      "Epoch 10 - Training Loss: 0.012429553084075451\n",
      "Epoch 11 - Training Loss: 0.014270372688770294\n",
      "Epoch 12 - Training Loss: 0.013247552327811718\n",
      "Epoch 13 - Training Loss: 0.012666169553995132\n",
      "Epoch 14 - Training Loss: 0.0121433911845088\n",
      "Epoch 15 - Training Loss: 0.01203901693224907\n",
      "Epoch 16 - Training Loss: 0.013562243431806564\n",
      "Epoch 17 - Training Loss: 0.012508167885243893\n",
      "Epoch 18 - Training Loss: 0.013787167146801949\n",
      "Epoch 19 - Training Loss: 0.013300059363245964\n",
      "Epoch 20 - Training Loss: 0.011910497210919857\n",
      "Epoch 21 - Training Loss: 0.012652342207729816\n",
      "Epoch 22 - Training Loss: 0.011831354349851608\n",
      "Epoch 23 - Training Loss: 0.01225192192941904\n",
      "Epoch 24 - Training Loss: 0.01259269192814827\n",
      "Epoch 25 - Training Loss: 0.014084209688007832\n",
      "Epoch 26 - Training Loss: 0.012964646331965923\n",
      "Epoch 27 - Training Loss: 0.012835310772061348\n",
      "Epoch 28 - Training Loss: 0.01301304716616869\n",
      "Epoch 29 - Training Loss: 0.012528817169368267\n",
      "Epoch 30 - Training Loss: 0.012549929320812225\n",
      "Epoch 31 - Training Loss: 0.01192666869610548\n",
      "Epoch 32 - Training Loss: 0.012758254073560238\n",
      "Epoch 33 - Training Loss: 0.012408336624503136\n",
      "Epoch 34 - Training Loss: 0.01265906635671854\n",
      "Epoch 35 - Training Loss: 0.015207408927381039\n",
      "Epoch 36 - Training Loss: 0.01354469545185566\n",
      "Epoch 37 - Training Loss: 0.011386114172637463\n",
      "Epoch 38 - Training Loss: 0.012020629830658436\n",
      "Epoch 39 - Training Loss: 0.012456637807190418\n",
      "Epoch 40 - Training Loss: 0.013063490390777588\n",
      "Epoch 41 - Training Loss: 0.012541444040834904\n",
      "Epoch 42 - Training Loss: 0.013460241258144379\n",
      "Epoch 43 - Training Loss: 0.011938059702515602\n",
      "Epoch 44 - Training Loss: 0.013482579030096531\n",
      "Epoch 45 - Training Loss: 0.013376843184232712\n",
      "Epoch 46 - Training Loss: 0.013332955539226532\n",
      "Epoch 47 - Training Loss: 0.012215252965688705\n",
      "Epoch 48 - Training Loss: 0.013482635840773582\n",
      "Epoch 49 - Training Loss: 0.013598330318927765\n",
      "Epoch 50 - Training Loss: 0.012808967381715775\n",
      "Epoch 51 - Training Loss: 0.013194120489060879\n",
      "Epoch 52 - Training Loss: 0.011751771904528141\n",
      "Epoch 53 - Training Loss: 0.012938170693814754\n",
      "Epoch 54 - Training Loss: 0.01312931440770626\n",
      "Epoch 55 - Training Loss: 0.013479220680892467\n",
      "Epoch 56 - Training Loss: 0.013231497257947922\n",
      "Epoch 57 - Training Loss: 0.012556381523609161\n",
      "Epoch 58 - Training Loss: 0.012783863581717014\n",
      "Epoch 59 - Training Loss: 0.012103581801056862\n",
      "Epoch 60 - Training Loss: 0.013122719712555408\n",
      "Epoch 61 - Training Loss: 0.012628491036593914\n",
      "Epoch 62 - Training Loss: 0.011288775131106377\n",
      "Epoch 63 - Training Loss: 0.013127109967172146\n",
      "Epoch 64 - Training Loss: 0.01327585894614458\n",
      "Epoch 65 - Training Loss: 0.013465858064591885\n",
      "Epoch 66 - Training Loss: 0.013735346496105194\n",
      "Epoch 67 - Training Loss: 0.013116504065692425\n",
      "Epoch 68 - Training Loss: 0.013667513616383076\n",
      "Epoch 69 - Training Loss: 0.011920573189854622\n",
      "Epoch 70 - Training Loss: 0.014371908269822598\n",
      "Epoch 71 - Training Loss: 0.013379612006247044\n",
      "Epoch 72 - Training Loss: 0.013237149454653263\n",
      "Epoch 73 - Training Loss: 0.011549935676157475\n",
      "Epoch 74 - Training Loss: 0.013583600521087646\n",
      "Epoch 75 - Training Loss: 0.013697980903089046\n",
      "Epoch 76 - Training Loss: 0.01302408054471016\n",
      "Epoch 77 - Training Loss: 0.012219573371112347\n",
      "Epoch 78 - Training Loss: 0.013325020670890808\n",
      "Epoch 79 - Training Loss: 0.013487216085195541\n",
      "Epoch 80 - Training Loss: 0.012571314349770546\n",
      "Epoch 81 - Training Loss: 0.012420274317264557\n",
      "Epoch 82 - Training Loss: 0.012385318987071514\n",
      "Epoch 83 - Training Loss: 0.012368284165859222\n",
      "Epoch 84 - Training Loss: 0.013331307098269463\n",
      "Epoch 85 - Training Loss: 0.012830027379095554\n",
      "Epoch 86 - Training Loss: 0.01326065044850111\n",
      "Epoch 87 - Training Loss: 0.012156307697296143\n",
      "Epoch 88 - Training Loss: 0.012057042680680752\n",
      "Epoch 89 - Training Loss: 0.012949634343385696\n",
      "Epoch 90 - Training Loss: 0.013195667415857315\n",
      "Epoch 91 - Training Loss: 0.012506846338510513\n",
      "Epoch 92 - Training Loss: 0.013094363734126091\n",
      "Epoch 93 - Training Loss: 0.013744463212788105\n",
      "Epoch 94 - Training Loss: 0.012595289386808872\n",
      "Epoch 95 - Training Loss: 0.01241854764521122\n",
      "Epoch 96 - Training Loss: 0.0119181452319026\n",
      "Epoch 97 - Training Loss: 0.011919124983251095\n",
      "Epoch 98 - Training Loss: 0.014274537563323975\n",
      "Epoch 99 - Training Loss: 0.01331962738186121\n",
      "Epoch 100 - Training Loss: 0.012899034656584263\n",
      "Epoch 1 - Training Loss: 0.012915223836898804\n",
      "Epoch 2 - Training Loss: 0.012312205508351326\n",
      "Epoch 3 - Training Loss: 0.011707346886396408\n",
      "Epoch 4 - Training Loss: 0.011867484077811241\n",
      "Epoch 5 - Training Loss: 0.01328680757433176\n",
      "Epoch 6 - Training Loss: 0.013603045605123043\n",
      "Epoch 7 - Training Loss: 0.01266391295939684\n",
      "Epoch 8 - Training Loss: 0.012797714211046696\n",
      "Epoch 9 - Training Loss: 0.012550920248031616\n",
      "Epoch 10 - Training Loss: 0.011950233019888401\n",
      "Epoch 11 - Training Loss: 0.011913586407899857\n",
      "Epoch 12 - Training Loss: 0.012255650013685226\n",
      "Epoch 13 - Training Loss: 0.013329197652637959\n",
      "Epoch 14 - Training Loss: 0.013385355472564697\n",
      "Epoch 15 - Training Loss: 0.012589975260198116\n",
      "Epoch 16 - Training Loss: 0.014181168749928474\n",
      "Epoch 17 - Training Loss: 0.01172687392681837\n",
      "Epoch 18 - Training Loss: 0.012202094309031963\n",
      "Epoch 19 - Training Loss: 0.012789491564035416\n",
      "Epoch 20 - Training Loss: 0.012695923447608948\n",
      "Epoch 21 - Training Loss: 0.013055001385509968\n",
      "Epoch 22 - Training Loss: 0.012906544841825962\n",
      "Epoch 23 - Training Loss: 0.012335672974586487\n",
      "Epoch 24 - Training Loss: 0.013631538487970829\n",
      "Epoch 25 - Training Loss: 0.013551508076488972\n",
      "Epoch 26 - Training Loss: 0.01310624461621046\n",
      "Epoch 27 - Training Loss: 0.012415221892297268\n",
      "Epoch 28 - Training Loss: 0.012627041898667812\n",
      "early stopping on epoch: 29\n",
      "Epoch 1 - Training Loss: 0.01240745559334755\n",
      "Epoch 2 - Training Loss: 0.012109395116567612\n",
      "Epoch 3 - Training Loss: 0.01328639592975378\n",
      "Epoch 4 - Training Loss: 0.013295024633407593\n",
      "Epoch 5 - Training Loss: 0.012844156473875046\n",
      "Epoch 6 - Training Loss: 0.012981182895600796\n",
      "Epoch 7 - Training Loss: 0.013738807290792465\n",
      "Epoch 8 - Training Loss: 0.012726869434118271\n",
      "Epoch 9 - Training Loss: 0.011744201183319092\n",
      "Epoch 10 - Training Loss: 0.013107921928167343\n",
      "Epoch 11 - Training Loss: 0.012372281402349472\n",
      "Epoch 12 - Training Loss: 0.011999267153441906\n",
      "Epoch 13 - Training Loss: 0.012951839715242386\n",
      "Epoch 14 - Training Loss: 0.012809615582227707\n",
      "Epoch 15 - Training Loss: 0.01231510378420353\n",
      "Epoch 16 - Training Loss: 0.013835431076586246\n",
      "Epoch 17 - Training Loss: 0.012078315019607544\n",
      "Epoch 18 - Training Loss: 0.012265997938811779\n",
      "Epoch 19 - Training Loss: 0.013805358670651913\n",
      "Epoch 20 - Training Loss: 0.01327525731176138\n",
      "Epoch 21 - Training Loss: 0.013098066672682762\n",
      "Epoch 22 - Training Loss: 0.012642658315598965\n",
      "Epoch 23 - Training Loss: 0.013895228505134583\n",
      "Epoch 24 - Training Loss: 0.013198072090744972\n",
      "Epoch 25 - Training Loss: 0.013128024525940418\n",
      "Epoch 26 - Training Loss: 0.014171033166348934\n",
      "Epoch 27 - Training Loss: 0.011982337571680546\n",
      "Epoch 28 - Training Loss: 0.012853548862040043\n",
      "Epoch 29 - Training Loss: 0.01202120166271925\n",
      "Epoch 30 - Training Loss: 0.013849488459527493\n",
      "Epoch 31 - Training Loss: 0.013828284107148647\n",
      "Epoch 32 - Training Loss: 0.012874823063611984\n",
      "Epoch 33 - Training Loss: 0.012869885191321373\n",
      "Epoch 34 - Training Loss: 0.01225326582789421\n",
      "Epoch 35 - Training Loss: 0.012558556161820889\n",
      "Epoch 36 - Training Loss: 0.011766064912080765\n",
      "Epoch 37 - Training Loss: 0.013130730018019676\n",
      "Epoch 38 - Training Loss: 0.013093765825033188\n",
      "Epoch 39 - Training Loss: 0.012512356042861938\n",
      "Epoch 40 - Training Loss: 0.013836156576871872\n",
      "Epoch 41 - Training Loss: 0.01238510012626648\n",
      "Epoch 42 - Training Loss: 0.011493906378746033\n",
      "Epoch 43 - Training Loss: 0.013207224197685719\n",
      "Epoch 44 - Training Loss: 0.012567352503538132\n",
      "Epoch 45 - Training Loss: 0.01470364909619093\n",
      "Epoch 46 - Training Loss: 0.012425556778907776\n",
      "Epoch 47 - Training Loss: 0.01324304286390543\n",
      "Epoch 48 - Training Loss: 0.01308969035744667\n",
      "Epoch 49 - Training Loss: 0.01163220964372158\n",
      "Epoch 50 - Training Loss: 0.013498380780220032\n",
      "Epoch 51 - Training Loss: 0.012687490321695805\n",
      "Epoch 52 - Training Loss: 0.012190447188913822\n",
      "Epoch 53 - Training Loss: 0.012864392250776291\n",
      "Epoch 54 - Training Loss: 0.012649177573621273\n",
      "Epoch 55 - Training Loss: 0.01211399957537651\n",
      "Epoch 56 - Training Loss: 0.012137162499129772\n",
      "Epoch 57 - Training Loss: 0.012338552623987198\n",
      "Epoch 58 - Training Loss: 0.012394520454108715\n",
      "Epoch 59 - Training Loss: 0.011915125884115696\n",
      "Epoch 60 - Training Loss: 0.012063076719641685\n",
      "Epoch 61 - Training Loss: 0.01304447092115879\n",
      "early stopping on epoch: 62\n",
      "Epoch 1 - Training Loss: 0.012579773552715778\n",
      "Epoch 2 - Training Loss: 0.012379912659525871\n",
      "Epoch 3 - Training Loss: 0.014264225959777832\n",
      "Epoch 4 - Training Loss: 0.013621000573039055\n",
      "Epoch 5 - Training Loss: 0.012129544280469418\n",
      "Epoch 6 - Training Loss: 0.012101907283067703\n",
      "Epoch 7 - Training Loss: 0.012247685343027115\n",
      "Epoch 8 - Training Loss: 0.012038243003189564\n",
      "Epoch 9 - Training Loss: 0.013374825939536095\n",
      "Epoch 10 - Training Loss: 0.012462400831282139\n",
      "Epoch 11 - Training Loss: 0.013065307401120663\n",
      "Epoch 12 - Training Loss: 0.013888967223465443\n",
      "Epoch 13 - Training Loss: 0.01200272236019373\n",
      "Epoch 14 - Training Loss: 0.01379234716296196\n",
      "Epoch 15 - Training Loss: 0.012018200010061264\n",
      "Epoch 16 - Training Loss: 0.012571818195283413\n",
      "Epoch 17 - Training Loss: 0.011759158223867416\n",
      "Epoch 18 - Training Loss: 0.012996535748243332\n",
      "Epoch 19 - Training Loss: 0.013837815262377262\n",
      "Epoch 20 - Training Loss: 0.012202886864542961\n",
      "Epoch 21 - Training Loss: 0.01177471037954092\n",
      "Epoch 22 - Training Loss: 0.011966252699494362\n",
      "Epoch 23 - Training Loss: 0.012737867422401905\n",
      "Epoch 24 - Training Loss: 0.012761644087731838\n",
      "Epoch 25 - Training Loss: 0.013340347446501255\n",
      "Epoch 26 - Training Loss: 0.013237769715487957\n",
      "Epoch 27 - Training Loss: 0.013803928159177303\n",
      "Epoch 28 - Training Loss: 0.013025803491473198\n",
      "Epoch 29 - Training Loss: 0.012433459982275963\n",
      "Epoch 30 - Training Loss: 0.011950016021728516\n",
      "Epoch 31 - Training Loss: 0.013123883865773678\n",
      "Epoch 32 - Training Loss: 0.012550555169582367\n",
      "Epoch 33 - Training Loss: 0.013110727071762085\n",
      "Epoch 34 - Training Loss: 0.013126645237207413\n",
      "Epoch 35 - Training Loss: 0.012298548594117165\n",
      "Epoch 36 - Training Loss: 0.012043938972055912\n",
      "Epoch 37 - Training Loss: 0.0122056370601058\n",
      "Epoch 38 - Training Loss: 0.01220683939754963\n",
      "Epoch 39 - Training Loss: 0.012346364557743073\n",
      "Epoch 40 - Training Loss: 0.013467083685100079\n",
      "Epoch 41 - Training Loss: 0.012113370932638645\n",
      "Epoch 42 - Training Loss: 0.012753574177622795\n",
      "Epoch 43 - Training Loss: 0.013300574384629726\n",
      "Epoch 44 - Training Loss: 0.013028355315327644\n",
      "Epoch 45 - Training Loss: 0.012687809765338898\n",
      "Epoch 46 - Training Loss: 0.013562507927417755\n",
      "Epoch 47 - Training Loss: 0.013155072927474976\n",
      "Epoch 48 - Training Loss: 0.01213184092193842\n",
      "Epoch 49 - Training Loss: 0.012616650201380253\n",
      "Epoch 50 - Training Loss: 0.013792844489216805\n",
      "Epoch 51 - Training Loss: 0.013180847279727459\n",
      "Epoch 52 - Training Loss: 0.014062819071114063\n",
      "Epoch 53 - Training Loss: 0.013147777877748013\n",
      "Epoch 54 - Training Loss: 0.012533786706626415\n",
      "Epoch 55 - Training Loss: 0.012077327817678452\n",
      "Epoch 56 - Training Loss: 0.012478903867304325\n",
      "Epoch 57 - Training Loss: 0.011643976904451847\n",
      "Epoch 58 - Training Loss: 0.014014726504683495\n",
      "Epoch 59 - Training Loss: 0.013026171363890171\n",
      "Epoch 60 - Training Loss: 0.012305954471230507\n",
      "Epoch 61 - Training Loss: 0.012747925706207752\n",
      "Epoch 62 - Training Loss: 0.012816788628697395\n",
      "Epoch 63 - Training Loss: 0.012571980245411396\n",
      "Epoch 64 - Training Loss: 0.013195488601922989\n",
      "Epoch 65 - Training Loss: 0.012465774081647396\n",
      "Epoch 66 - Training Loss: 0.012536031194031239\n",
      "Epoch 67 - Training Loss: 0.013560094870626926\n",
      "Epoch 68 - Training Loss: 0.011949240230023861\n",
      "Epoch 69 - Training Loss: 0.01361911091953516\n",
      "Epoch 70 - Training Loss: 0.01248407643288374\n",
      "Epoch 71 - Training Loss: 0.012781972996890545\n",
      "Epoch 72 - Training Loss: 0.012235473841428757\n",
      "Epoch 73 - Training Loss: 0.012317444197833538\n",
      "Epoch 74 - Training Loss: 0.011841624043881893\n",
      "Epoch 75 - Training Loss: 0.013285028748214245\n",
      "Epoch 76 - Training Loss: 0.01250220462679863\n",
      "Epoch 77 - Training Loss: 0.013811943121254444\n",
      "Epoch 78 - Training Loss: 0.01318618468940258\n",
      "Epoch 79 - Training Loss: 0.011559086851775646\n",
      "Epoch 80 - Training Loss: 0.012875715270638466\n",
      "Epoch 81 - Training Loss: 0.0143613675609231\n",
      "Epoch 82 - Training Loss: 0.013173853978514671\n",
      "Epoch 83 - Training Loss: 0.01286342367529869\n",
      "Epoch 84 - Training Loss: 0.013305709697306156\n",
      "Epoch 85 - Training Loss: 0.012323456816375256\n",
      "Epoch 86 - Training Loss: 0.013330771587789059\n",
      "Epoch 87 - Training Loss: 0.012216688133776188\n",
      "Epoch 88 - Training Loss: 0.012333028018474579\n",
      "Epoch 89 - Training Loss: 0.013279500417411327\n",
      "Epoch 90 - Training Loss: 0.013518000021576881\n",
      "Epoch 91 - Training Loss: 0.012146382592618465\n",
      "Epoch 92 - Training Loss: 0.01286869216710329\n",
      "Epoch 93 - Training Loss: 0.01236694771796465\n",
      "Epoch 94 - Training Loss: 0.012977301143109798\n",
      "Epoch 95 - Training Loss: 0.012876478023827076\n",
      "Epoch 96 - Training Loss: 0.013688870705664158\n",
      "Epoch 97 - Training Loss: 0.014408314600586891\n",
      "Epoch 98 - Training Loss: 0.013707400299608707\n",
      "Epoch 99 - Training Loss: 0.012575180269777775\n",
      "Epoch 100 - Training Loss: 0.012130563147366047\n",
      "Epoch 1 - Training Loss: 0.012283832766115665\n",
      "Epoch 2 - Training Loss: 0.012121693231165409\n",
      "Epoch 3 - Training Loss: 0.013227368704974651\n",
      "Epoch 4 - Training Loss: 0.013080955483019352\n",
      "Epoch 5 - Training Loss: 0.0128413001075387\n",
      "Epoch 6 - Training Loss: 0.01224658451974392\n",
      "Epoch 7 - Training Loss: 0.012512068264186382\n",
      "Epoch 8 - Training Loss: 0.01300093438476324\n",
      "Epoch 9 - Training Loss: 0.011871506460011005\n",
      "Epoch 10 - Training Loss: 0.013063330203294754\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.013270976021885872\n",
      "Epoch 2 - Training Loss: 0.012945475988090038\n",
      "Epoch 3 - Training Loss: 0.01309199258685112\n",
      "Epoch 4 - Training Loss: 0.013079315423965454\n",
      "Epoch 5 - Training Loss: 0.011539829894900322\n",
      "Epoch 6 - Training Loss: 0.012316545471549034\n",
      "Epoch 7 - Training Loss: 0.012669176794588566\n",
      "Epoch 8 - Training Loss: 0.012465416453778744\n",
      "Epoch 9 - Training Loss: 0.012306522578001022\n",
      "Epoch 10 - Training Loss: 0.014059820212423801\n",
      "Epoch 11 - Training Loss: 0.012622307986021042\n",
      "Epoch 12 - Training Loss: 0.012583249248564243\n",
      "Epoch 13 - Training Loss: 0.012976178899407387\n",
      "Epoch 14 - Training Loss: 0.013186433352530003\n",
      "Epoch 15 - Training Loss: 0.012046006508171558\n",
      "Epoch 16 - Training Loss: 0.013352970592677593\n",
      "Epoch 17 - Training Loss: 0.012941637076437473\n",
      "Epoch 18 - Training Loss: 0.012099044397473335\n",
      "Epoch 19 - Training Loss: 0.01292954571545124\n",
      "Epoch 20 - Training Loss: 0.013465853407979012\n",
      "early stopping on epoch: 21\n",
      "Epoch 1 - Training Loss: 0.013032390736043453\n",
      "Epoch 2 - Training Loss: 0.012980596162378788\n",
      "Epoch 3 - Training Loss: 0.013021775521337986\n",
      "Epoch 4 - Training Loss: 0.014027129858732224\n",
      "Epoch 5 - Training Loss: 0.013510686345398426\n",
      "Epoch 6 - Training Loss: 0.012835921719670296\n",
      "Epoch 7 - Training Loss: 0.012332219630479813\n",
      "Epoch 8 - Training Loss: 0.0132061205804348\n",
      "Epoch 9 - Training Loss: 0.012381106615066528\n",
      "Epoch 10 - Training Loss: 0.013597603887319565\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.012631693854928017\n",
      "Epoch 2 - Training Loss: 0.01319779735058546\n",
      "Epoch 3 - Training Loss: 0.01214671228080988\n",
      "Epoch 4 - Training Loss: 0.012817798182368279\n",
      "Epoch 5 - Training Loss: 0.012455364689230919\n",
      "Epoch 6 - Training Loss: 0.012684393674135208\n",
      "Epoch 7 - Training Loss: 0.014063121750950813\n",
      "Epoch 8 - Training Loss: 0.013532903976738453\n",
      "Epoch 9 - Training Loss: 0.0126908328384161\n",
      "Epoch 10 - Training Loss: 0.012573092244565487\n",
      "Epoch 11 - Training Loss: 0.013860502280294895\n",
      "Epoch 12 - Training Loss: 0.012327944859862328\n",
      "Epoch 13 - Training Loss: 0.012037325650453568\n",
      "Epoch 14 - Training Loss: 0.012925277464091778\n",
      "Epoch 15 - Training Loss: 0.012501397170126438\n",
      "Epoch 16 - Training Loss: 0.013792629353702068\n",
      "Epoch 17 - Training Loss: 0.01303973700851202\n",
      "Epoch 18 - Training Loss: 0.012646791525185108\n",
      "Epoch 19 - Training Loss: 0.013264729641377926\n",
      "Epoch 20 - Training Loss: 0.013241359032690525\n",
      "Epoch 21 - Training Loss: 0.013443881645798683\n",
      "Epoch 22 - Training Loss: 0.012958385981619358\n",
      "Epoch 23 - Training Loss: 0.01283179223537445\n",
      "Epoch 24 - Training Loss: 0.012325644493103027\n",
      "Epoch 25 - Training Loss: 0.01253458485007286\n",
      "Epoch 26 - Training Loss: 0.011807284317910671\n",
      "Epoch 27 - Training Loss: 0.013153386302292347\n",
      "early stopping on epoch: 28\n",
      "Epoch 1 - Training Loss: 0.012632171623408794\n",
      "Epoch 2 - Training Loss: 0.012254533357918262\n",
      "Epoch 3 - Training Loss: 0.012607772834599018\n",
      "Epoch 4 - Training Loss: 0.012749757617712021\n",
      "Epoch 5 - Training Loss: 0.013094150461256504\n",
      "Epoch 6 - Training Loss: 0.012248764745891094\n",
      "Epoch 7 - Training Loss: 0.01202388759702444\n",
      "Epoch 8 - Training Loss: 0.012246563099324703\n",
      "Epoch 9 - Training Loss: 0.013202599249780178\n",
      "Epoch 10 - Training Loss: 0.012522474862635136\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.012681628577411175\n",
      "Epoch 2 - Training Loss: 0.01365612167865038\n",
      "Epoch 3 - Training Loss: 0.012226893566548824\n",
      "Epoch 4 - Training Loss: 0.013123443350195885\n",
      "Epoch 5 - Training Loss: 0.012914962135255337\n",
      "Epoch 6 - Training Loss: 0.013663167133927345\n",
      "Epoch 7 - Training Loss: 0.012200349941849709\n",
      "Epoch 8 - Training Loss: 0.014055773615837097\n",
      "Epoch 9 - Training Loss: 0.013175854459404945\n",
      "Epoch 10 - Training Loss: 0.013609967194497585\n",
      "Epoch 11 - Training Loss: 0.012897839769721031\n",
      "Epoch 12 - Training Loss: 0.012649635784327984\n",
      "Epoch 13 - Training Loss: 0.012999029830098152\n",
      "Epoch 14 - Training Loss: 0.013005786575376987\n",
      "Epoch 15 - Training Loss: 0.012654142454266548\n",
      "Epoch 16 - Training Loss: 0.012095003388822079\n",
      "Epoch 17 - Training Loss: 0.012175978161394596\n",
      "Epoch 18 - Training Loss: 0.01446689572185278\n",
      "Epoch 19 - Training Loss: 0.012204859405755997\n",
      "Epoch 20 - Training Loss: 0.013299570418894291\n",
      "Epoch 21 - Training Loss: 0.011984528973698616\n",
      "Epoch 22 - Training Loss: 0.012711831368505955\n",
      "Epoch 23 - Training Loss: 0.012036638334393501\n",
      "Epoch 24 - Training Loss: 0.012718789279460907\n",
      "Epoch 25 - Training Loss: 0.011856837198138237\n",
      "Epoch 26 - Training Loss: 0.013519376516342163\n",
      "Epoch 27 - Training Loss: 0.013118114322423935\n",
      "Epoch 28 - Training Loss: 0.013553149066865444\n",
      "Epoch 29 - Training Loss: 0.012964284978806973\n",
      "Epoch 30 - Training Loss: 0.013737856410443783\n",
      "Epoch 31 - Training Loss: 0.012442943640053272\n",
      "Epoch 32 - Training Loss: 0.014128495007753372\n",
      "Epoch 33 - Training Loss: 0.012665919959545135\n",
      "Epoch 34 - Training Loss: 0.012914207763969898\n",
      "Epoch 35 - Training Loss: 0.011627539992332458\n",
      "Epoch 36 - Training Loss: 0.012725424021482468\n",
      "Epoch 37 - Training Loss: 0.01199417095631361\n",
      "Epoch 38 - Training Loss: 0.011646093800663948\n",
      "Epoch 39 - Training Loss: 0.012532954104244709\n",
      "Epoch 40 - Training Loss: 0.01329871080815792\n",
      "Epoch 41 - Training Loss: 0.013537867926061153\n",
      "Epoch 42 - Training Loss: 0.012725627049803734\n",
      "Epoch 43 - Training Loss: 0.012442847713828087\n",
      "Epoch 44 - Training Loss: 0.0122097572311759\n",
      "Epoch 45 - Training Loss: 0.012442544102668762\n",
      "Epoch 46 - Training Loss: 0.012068579904735088\n",
      "Epoch 47 - Training Loss: 0.012145117856562138\n",
      "Epoch 48 - Training Loss: 0.012841376475989819\n",
      "Epoch 49 - Training Loss: 0.015146452002227306\n",
      "Epoch 50 - Training Loss: 0.012059293687343597\n",
      "Epoch 51 - Training Loss: 0.011886116117238998\n",
      "Epoch 52 - Training Loss: 0.012356916442513466\n",
      "Epoch 53 - Training Loss: 0.013515478000044823\n",
      "Epoch 54 - Training Loss: 0.0122865354642272\n",
      "Epoch 55 - Training Loss: 0.013502522371709347\n",
      "Epoch 56 - Training Loss: 0.012660332024097443\n",
      "Epoch 57 - Training Loss: 0.014943338930606842\n",
      "Epoch 58 - Training Loss: 0.012870495207607746\n",
      "Epoch 59 - Training Loss: 0.012607138603925705\n",
      "Epoch 60 - Training Loss: 0.014301840215921402\n",
      "Epoch 61 - Training Loss: 0.012212899513542652\n",
      "Epoch 62 - Training Loss: 0.012153309769928455\n",
      "Epoch 63 - Training Loss: 0.012978749349713326\n",
      "Epoch 64 - Training Loss: 0.013387140817940235\n",
      "Epoch 65 - Training Loss: 0.012898195534944534\n",
      "Epoch 66 - Training Loss: 0.01155174896121025\n",
      "Epoch 67 - Training Loss: 0.013169621117413044\n",
      "Epoch 68 - Training Loss: 0.012873041443526745\n",
      "Epoch 69 - Training Loss: 0.012944156304001808\n",
      "Epoch 70 - Training Loss: 0.01260242611169815\n",
      "Epoch 71 - Training Loss: 0.013286691159009933\n",
      "Epoch 72 - Training Loss: 0.012775701470673084\n",
      "Epoch 73 - Training Loss: 0.011738181114196777\n",
      "Epoch 74 - Training Loss: 0.014155377633869648\n",
      "Epoch 75 - Training Loss: 0.014578954316675663\n",
      "Epoch 76 - Training Loss: 0.013438334688544273\n",
      "Epoch 77 - Training Loss: 0.013803435489535332\n",
      "Epoch 78 - Training Loss: 0.012922043912112713\n",
      "Epoch 79 - Training Loss: 0.011437741108238697\n",
      "Epoch 80 - Training Loss: 0.0126784797757864\n",
      "Epoch 81 - Training Loss: 0.012748988345265388\n",
      "Epoch 82 - Training Loss: 0.013761681504547596\n",
      "Epoch 83 - Training Loss: 0.012403998523950577\n",
      "Epoch 84 - Training Loss: 0.012202620506286621\n",
      "Epoch 85 - Training Loss: 0.013356348499655724\n",
      "Epoch 86 - Training Loss: 0.01175199169665575\n",
      "Epoch 87 - Training Loss: 0.012511100620031357\n",
      "Epoch 88 - Training Loss: 0.013324854895472527\n",
      "Epoch 89 - Training Loss: 0.014671129174530506\n",
      "Epoch 90 - Training Loss: 0.011869188398122787\n",
      "Epoch 91 - Training Loss: 0.012786581180989742\n",
      "Epoch 92 - Training Loss: 0.011882386170327663\n",
      "Epoch 93 - Training Loss: 0.01238966640084982\n",
      "Epoch 94 - Training Loss: 0.011483781039714813\n",
      "Epoch 95 - Training Loss: 0.01320812851190567\n",
      "Epoch 96 - Training Loss: 0.013883761130273342\n",
      "Epoch 97 - Training Loss: 0.012710091657936573\n",
      "Epoch 98 - Training Loss: 0.01293882355093956\n",
      "Epoch 99 - Training Loss: 0.013272061012685299\n",
      "Epoch 100 - Training Loss: 0.01247104350477457\n",
      "Epoch 1 - Training Loss: 0.012870959006249905\n",
      "Epoch 2 - Training Loss: 0.0121255898848176\n",
      "Epoch 3 - Training Loss: 0.012988916598260403\n",
      "Epoch 4 - Training Loss: 0.012865264900028706\n",
      "Epoch 5 - Training Loss: 0.014091539196670055\n",
      "Epoch 6 - Training Loss: 0.012603339739143848\n",
      "Epoch 7 - Training Loss: 0.01247747614979744\n",
      "Epoch 8 - Training Loss: 0.012564065866172314\n",
      "Epoch 9 - Training Loss: 0.012839239090681076\n",
      "Epoch 10 - Training Loss: 0.013933339156210423\n",
      "Epoch 11 - Training Loss: 0.013606652617454529\n",
      "Epoch 12 - Training Loss: 0.013021032325923443\n",
      "Epoch 13 - Training Loss: 0.01334387343376875\n",
      "Epoch 14 - Training Loss: 0.012696227990090847\n",
      "Epoch 15 - Training Loss: 0.012221012264490128\n",
      "Epoch 16 - Training Loss: 0.011450177989900112\n",
      "Epoch 17 - Training Loss: 0.012933493591845036\n",
      "Epoch 18 - Training Loss: 0.012018488720059395\n",
      "Epoch 19 - Training Loss: 0.01299511082470417\n",
      "Epoch 20 - Training Loss: 0.012155774049460888\n",
      "Epoch 21 - Training Loss: 0.012368557043373585\n",
      "Epoch 22 - Training Loss: 0.012203135527670383\n",
      "Epoch 23 - Training Loss: 0.012458506971597672\n",
      "Epoch 24 - Training Loss: 0.012754475697875023\n",
      "Epoch 25 - Training Loss: 0.013060181401669979\n",
      "Epoch 26 - Training Loss: 0.013406333513557911\n",
      "early stopping on epoch: 27\n",
      "Epoch 1 - Training Loss: 0.012834169901907444\n",
      "Epoch 2 - Training Loss: 0.012664991430938244\n",
      "Epoch 3 - Training Loss: 0.01329210214316845\n",
      "Epoch 4 - Training Loss: 0.012809637002646923\n",
      "Epoch 5 - Training Loss: 0.012178830802440643\n",
      "Epoch 6 - Training Loss: 0.012674565427005291\n",
      "Epoch 7 - Training Loss: 0.012485560029745102\n",
      "Epoch 8 - Training Loss: 0.012722180224955082\n",
      "Epoch 9 - Training Loss: 0.013874173164367676\n",
      "Epoch 10 - Training Loss: 0.012323659844696522\n",
      "Epoch 11 - Training Loss: 0.012340535409748554\n",
      "Epoch 12 - Training Loss: 0.01351555809378624\n",
      "Epoch 13 - Training Loss: 0.012819688767194748\n",
      "Epoch 14 - Training Loss: 0.013088454492390156\n",
      "Epoch 15 - Training Loss: 0.011971644125878811\n",
      "Epoch 16 - Training Loss: 0.01230423990637064\n",
      "Epoch 17 - Training Loss: 0.013254609890282154\n",
      "Epoch 18 - Training Loss: 0.01189417950809002\n",
      "Epoch 19 - Training Loss: 0.01237963605672121\n",
      "Epoch 20 - Training Loss: 0.012602230533957481\n",
      "Epoch 21 - Training Loss: 0.013627695851027966\n",
      "Epoch 22 - Training Loss: 0.012587456032633781\n",
      "Epoch 23 - Training Loss: 0.012873691506683826\n",
      "Epoch 24 - Training Loss: 0.012815014459192753\n",
      "Epoch 25 - Training Loss: 0.012617391534149647\n",
      "Epoch 26 - Training Loss: 0.01381517294794321\n",
      "Epoch 27 - Training Loss: 0.012295002117753029\n",
      "Epoch 28 - Training Loss: 0.011660238727927208\n",
      "Epoch 29 - Training Loss: 0.013816401362419128\n",
      "Epoch 30 - Training Loss: 0.012367438524961472\n",
      "Epoch 31 - Training Loss: 0.011693127453327179\n",
      "Epoch 32 - Training Loss: 0.012920177541673183\n",
      "Epoch 33 - Training Loss: 0.013471994549036026\n",
      "Epoch 34 - Training Loss: 0.01283608004450798\n",
      "Epoch 35 - Training Loss: 0.012513499706983566\n",
      "Epoch 36 - Training Loss: 0.01160727720707655\n",
      "Epoch 37 - Training Loss: 0.012782536447048187\n",
      "Epoch 38 - Training Loss: 0.012495811097323895\n",
      "Epoch 39 - Training Loss: 0.01419284287840128\n",
      "Epoch 40 - Training Loss: 0.013142297975718975\n",
      "Epoch 41 - Training Loss: 0.011249952018260956\n",
      "Epoch 42 - Training Loss: 0.014620177447795868\n",
      "Epoch 43 - Training Loss: 0.013046201318502426\n",
      "Epoch 44 - Training Loss: 0.012644689530134201\n",
      "Epoch 45 - Training Loss: 0.013614092022180557\n",
      "Epoch 46 - Training Loss: 0.011830213479697704\n",
      "Epoch 47 - Training Loss: 0.012343593873083591\n",
      "Epoch 48 - Training Loss: 0.012894832529127598\n",
      "Epoch 49 - Training Loss: 0.01319944392889738\n",
      "Epoch 50 - Training Loss: 0.013718334026634693\n",
      "Epoch 51 - Training Loss: 0.012786428444087505\n",
      "Epoch 52 - Training Loss: 0.01181706041097641\n",
      "Epoch 53 - Training Loss: 0.012312551960349083\n",
      "Epoch 54 - Training Loss: 0.012592439539730549\n",
      "Epoch 55 - Training Loss: 0.01212896779179573\n",
      "Epoch 56 - Training Loss: 0.01377386786043644\n",
      "Epoch 57 - Training Loss: 0.012536374852061272\n",
      "Epoch 58 - Training Loss: 0.011829925701022148\n",
      "Epoch 59 - Training Loss: 0.0133435670286417\n",
      "Epoch 60 - Training Loss: 0.012952696532011032\n",
      "Epoch 61 - Training Loss: 0.012529099360108376\n",
      "Epoch 62 - Training Loss: 0.012869657017290592\n",
      "Epoch 63 - Training Loss: 0.01329006440937519\n",
      "Epoch 64 - Training Loss: 0.012745251879096031\n",
      "Epoch 65 - Training Loss: 0.01267252303659916\n",
      "Epoch 66 - Training Loss: 0.013316751457750797\n",
      "early stopping on epoch: 67\n",
      "Epoch 1 - Training Loss: 0.011405108496546745\n",
      "Epoch 2 - Training Loss: 0.01316261850297451\n",
      "Epoch 3 - Training Loss: 0.012764884158968925\n",
      "Epoch 4 - Training Loss: 0.01329951174557209\n",
      "Epoch 5 - Training Loss: 0.012562572956085205\n",
      "Epoch 6 - Training Loss: 0.013647623360157013\n",
      "Epoch 7 - Training Loss: 0.011548927053809166\n",
      "Epoch 8 - Training Loss: 0.012607282027602196\n",
      "Epoch 9 - Training Loss: 0.012871995568275452\n",
      "Epoch 10 - Training Loss: 0.011707079596817493\n",
      "Epoch 11 - Training Loss: 0.013148984871804714\n",
      "Epoch 12 - Training Loss: 0.011971310712397099\n",
      "Epoch 13 - Training Loss: 0.012440865859389305\n",
      "Epoch 14 - Training Loss: 0.012518113479018211\n",
      "Epoch 15 - Training Loss: 0.011721137911081314\n",
      "Epoch 16 - Training Loss: 0.013239317573606968\n",
      "Epoch 17 - Training Loss: 0.013519433327019215\n",
      "early stopping on epoch: 18\n",
      "Epoch 1 - Training Loss: 0.0141063891351223\n",
      "Epoch 2 - Training Loss: 0.0122769083827734\n",
      "Epoch 3 - Training Loss: 0.012617126107215881\n",
      "Epoch 4 - Training Loss: 0.014422687701880932\n",
      "Epoch 5 - Training Loss: 0.011968963779509068\n",
      "Epoch 6 - Training Loss: 0.012264703400433064\n",
      "Epoch 7 - Training Loss: 0.011920628137886524\n",
      "Epoch 8 - Training Loss: 0.012241747230291367\n",
      "Epoch 9 - Training Loss: 0.011480088345706463\n",
      "Epoch 10 - Training Loss: 0.01217556744813919\n",
      "Epoch 11 - Training Loss: 0.013284615240991116\n",
      "Epoch 12 - Training Loss: 0.012890680693089962\n",
      "Epoch 13 - Training Loss: 0.013441354967653751\n",
      "Epoch 14 - Training Loss: 0.01441180519759655\n",
      "Epoch 15 - Training Loss: 0.01274819951504469\n",
      "Epoch 16 - Training Loss: 0.012678011320531368\n",
      "Epoch 17 - Training Loss: 0.013257771730422974\n",
      "Epoch 18 - Training Loss: 0.013493938371539116\n",
      "Epoch 19 - Training Loss: 0.013855584897100925\n",
      "Epoch 20 - Training Loss: 0.012451494112610817\n",
      "Epoch 21 - Training Loss: 0.013698335736989975\n",
      "Epoch 22 - Training Loss: 0.012455896474421024\n",
      "Epoch 23 - Training Loss: 0.012146856635808945\n",
      "Epoch 24 - Training Loss: 0.012282717041671276\n",
      "Epoch 25 - Training Loss: 0.01288623921573162\n",
      "Epoch 26 - Training Loss: 0.014839517883956432\n",
      "Epoch 27 - Training Loss: 0.012503435835242271\n",
      "Epoch 28 - Training Loss: 0.013045824132859707\n",
      "Epoch 29 - Training Loss: 0.01352006383240223\n",
      "Epoch 30 - Training Loss: 0.012669631280004978\n",
      "Epoch 31 - Training Loss: 0.012726636603474617\n",
      "Epoch 32 - Training Loss: 0.012614326551556587\n",
      "Epoch 33 - Training Loss: 0.012450214475393295\n",
      "Epoch 34 - Training Loss: 0.01300373300909996\n",
      "Epoch 35 - Training Loss: 0.013055196963250637\n",
      "Epoch 36 - Training Loss: 0.012955041602253914\n",
      "Epoch 37 - Training Loss: 0.012275938875973225\n",
      "Epoch 38 - Training Loss: 0.012446515262126923\n",
      "Epoch 39 - Training Loss: 0.012494105845689774\n",
      "Epoch 40 - Training Loss: 0.011489864438772202\n",
      "Epoch 41 - Training Loss: 0.01218321267515421\n",
      "Epoch 42 - Training Loss: 0.01343625970184803\n",
      "early stopping on epoch: 43\n",
      "Epoch 1 - Training Loss: 0.014672410674393177\n",
      "Epoch 2 - Training Loss: 0.012922622263431549\n",
      "Epoch 3 - Training Loss: 0.01300144288688898\n",
      "Epoch 4 - Training Loss: 0.013051341287791729\n",
      "Epoch 5 - Training Loss: 0.013351622968912125\n",
      "Epoch 6 - Training Loss: 0.014230305328965187\n",
      "Epoch 7 - Training Loss: 0.01418300624936819\n",
      "Epoch 8 - Training Loss: 0.014423485845327377\n",
      "Epoch 9 - Training Loss: 0.015447237528860569\n",
      "Epoch 10 - Training Loss: 0.013174489140510559\n",
      "Epoch 11 - Training Loss: 0.013072921894490719\n",
      "Epoch 12 - Training Loss: 0.014137010090053082\n",
      "Epoch 13 - Training Loss: 0.014282983727753162\n",
      "Epoch 14 - Training Loss: 0.012986711226403713\n",
      "Epoch 15 - Training Loss: 0.013546334579586983\n",
      "Epoch 16 - Training Loss: 0.0145735964179039\n",
      "Epoch 17 - Training Loss: 0.013478430919349194\n",
      "Epoch 18 - Training Loss: 0.013397426344454288\n",
      "Epoch 19 - Training Loss: 0.013874364085495472\n",
      "Epoch 20 - Training Loss: 0.0133522879332304\n",
      "Epoch 21 - Training Loss: 0.013522060588002205\n",
      "Epoch 22 - Training Loss: 0.01341211423277855\n",
      "Epoch 23 - Training Loss: 0.014445817098021507\n",
      "Epoch 24 - Training Loss: 0.013501823879778385\n",
      "Epoch 25 - Training Loss: 0.013899468816816807\n",
      "Epoch 26 - Training Loss: 0.013234115205705166\n",
      "early stopping on epoch: 27\n",
      "Epoch 1 - Training Loss: 0.014164132997393608\n",
      "Epoch 2 - Training Loss: 0.01520183403044939\n",
      "Epoch 3 - Training Loss: 0.015005386434495449\n",
      "Epoch 4 - Training Loss: 0.01356418151408434\n",
      "Epoch 5 - Training Loss: 0.01335922535508871\n",
      "Epoch 6 - Training Loss: 0.01400731597095728\n",
      "Epoch 7 - Training Loss: 0.014418036676943302\n",
      "Epoch 8 - Training Loss: 0.013189085759222507\n",
      "Epoch 9 - Training Loss: 0.013637272641062737\n",
      "Epoch 10 - Training Loss: 0.014990988187491894\n",
      "Epoch 11 - Training Loss: 0.013652726076543331\n",
      "Epoch 12 - Training Loss: 0.01489946711808443\n",
      "Epoch 13 - Training Loss: 0.014381923712790012\n",
      "Epoch 14 - Training Loss: 0.013787145726382732\n",
      "Epoch 15 - Training Loss: 0.013105008751153946\n",
      "Epoch 16 - Training Loss: 0.013764341361820698\n",
      "Epoch 17 - Training Loss: 0.01428911741822958\n",
      "Epoch 18 - Training Loss: 0.014970611780881882\n",
      "Epoch 19 - Training Loss: 0.012766053900122643\n",
      "Epoch 20 - Training Loss: 0.0144632114097476\n",
      "Epoch 21 - Training Loss: 0.014265520498156548\n",
      "Epoch 22 - Training Loss: 0.014769628643989563\n",
      "Epoch 23 - Training Loss: 0.013668183237314224\n",
      "Epoch 24 - Training Loss: 0.013264389708638191\n",
      "Epoch 25 - Training Loss: 0.013301611877977848\n",
      "Epoch 26 - Training Loss: 0.014920559711754322\n",
      "Epoch 27 - Training Loss: 0.013150201179087162\n",
      "Epoch 28 - Training Loss: 0.01400483027100563\n",
      "Epoch 29 - Training Loss: 0.013435413129627705\n",
      "Epoch 30 - Training Loss: 0.01422862894833088\n",
      "Epoch 31 - Training Loss: 0.012986553832888603\n",
      "Epoch 32 - Training Loss: 0.014313830062747002\n",
      "Epoch 33 - Training Loss: 0.012701631523668766\n",
      "Epoch 34 - Training Loss: 0.014259636402130127\n",
      "Epoch 35 - Training Loss: 0.01591947302222252\n",
      "Epoch 36 - Training Loss: 0.0147501016035676\n",
      "Epoch 37 - Training Loss: 0.014274697750806808\n",
      "Epoch 38 - Training Loss: 0.014066808857023716\n",
      "Epoch 39 - Training Loss: 0.013965914025902748\n",
      "Epoch 40 - Training Loss: 0.0130465067923069\n",
      "Epoch 41 - Training Loss: 0.015759432688355446\n",
      "Epoch 42 - Training Loss: 0.013824881985783577\n",
      "Epoch 43 - Training Loss: 0.012585621327161789\n",
      "Epoch 44 - Training Loss: 0.014344743452966213\n",
      "Epoch 45 - Training Loss: 0.01567213609814644\n",
      "Epoch 46 - Training Loss: 0.013170275837182999\n",
      "Epoch 47 - Training Loss: 0.01326186303049326\n",
      "Epoch 48 - Training Loss: 0.014135201461613178\n",
      "Epoch 49 - Training Loss: 0.012800403870642185\n",
      "Epoch 50 - Training Loss: 0.014916742220520973\n",
      "Epoch 51 - Training Loss: 0.01388218067586422\n",
      "Epoch 52 - Training Loss: 0.014013520441949368\n",
      "Epoch 53 - Training Loss: 0.014640338718891144\n",
      "Epoch 54 - Training Loss: 0.013832277618348598\n",
      "Epoch 55 - Training Loss: 0.013805003836750984\n",
      "Epoch 56 - Training Loss: 0.013766675256192684\n",
      "Epoch 57 - Training Loss: 0.015118598937988281\n",
      "Epoch 58 - Training Loss: 0.014200570993125439\n",
      "Epoch 59 - Training Loss: 0.014859357848763466\n",
      "Epoch 60 - Training Loss: 0.013816294260323048\n",
      "Epoch 61 - Training Loss: 0.014091912657022476\n",
      "Epoch 62 - Training Loss: 0.0140337273478508\n",
      "Epoch 63 - Training Loss: 0.015007213689386845\n",
      "Epoch 64 - Training Loss: 0.013338422402739525\n",
      "Epoch 65 - Training Loss: 0.014547114260494709\n",
      "Epoch 66 - Training Loss: 0.01333714835345745\n",
      "Epoch 67 - Training Loss: 0.012502576224505901\n",
      "Epoch 68 - Training Loss: 0.014207161962985992\n",
      "Epoch 69 - Training Loss: 0.014049154706299305\n",
      "Epoch 70 - Training Loss: 0.013608104549348354\n",
      "Epoch 71 - Training Loss: 0.014429393224418163\n",
      "Epoch 72 - Training Loss: 0.01447462011128664\n",
      "Epoch 73 - Training Loss: 0.013304985128343105\n",
      "Epoch 74 - Training Loss: 0.013173369690775871\n",
      "Epoch 75 - Training Loss: 0.012657904997467995\n",
      "Epoch 76 - Training Loss: 0.015004447661340237\n",
      "Epoch 77 - Training Loss: 0.01319900806993246\n",
      "Epoch 78 - Training Loss: 0.014804054982960224\n",
      "Epoch 79 - Training Loss: 0.015008330345153809\n",
      "Epoch 80 - Training Loss: 0.013604975305497646\n",
      "Epoch 81 - Training Loss: 0.01408734917640686\n",
      "Epoch 82 - Training Loss: 0.014991958625614643\n",
      "Epoch 83 - Training Loss: 0.013465465046465397\n",
      "Epoch 84 - Training Loss: 0.013057907111942768\n",
      "Epoch 85 - Training Loss: 0.013939808122813702\n",
      "Epoch 86 - Training Loss: 0.013468572869896889\n",
      "Epoch 87 - Training Loss: 0.014372462406754494\n",
      "Epoch 88 - Training Loss: 0.014323906041681767\n",
      "Epoch 89 - Training Loss: 0.014937091618776321\n",
      "Epoch 90 - Training Loss: 0.013634872622787952\n",
      "Epoch 91 - Training Loss: 0.012776224873960018\n",
      "Epoch 92 - Training Loss: 0.01464096363633871\n",
      "Epoch 93 - Training Loss: 0.013052701018750668\n",
      "Epoch 94 - Training Loss: 0.013372993096709251\n",
      "Epoch 95 - Training Loss: 0.013392230495810509\n",
      "Epoch 96 - Training Loss: 0.013914918527007103\n",
      "Epoch 97 - Training Loss: 0.014843020588159561\n",
      "Epoch 98 - Training Loss: 0.014407537877559662\n",
      "Epoch 99 - Training Loss: 0.01436978206038475\n",
      "Epoch 100 - Training Loss: 0.013918104581534863\n",
      "Epoch 1 - Training Loss: 0.012993482872843742\n",
      "Epoch 2 - Training Loss: 0.015025967732071877\n",
      "Epoch 3 - Training Loss: 0.014943249523639679\n",
      "Epoch 4 - Training Loss: 0.013801699504256248\n",
      "Epoch 5 - Training Loss: 0.014453917741775513\n",
      "Epoch 6 - Training Loss: 0.012869874946773052\n",
      "Epoch 7 - Training Loss: 0.012763340026140213\n",
      "Epoch 8 - Training Loss: 0.015549960546195507\n",
      "Epoch 9 - Training Loss: 0.014525237493216991\n",
      "Epoch 10 - Training Loss: 0.015128804370760918\n",
      "Epoch 11 - Training Loss: 0.01445472426712513\n",
      "Epoch 12 - Training Loss: 0.015080348588526249\n",
      "Epoch 13 - Training Loss: 0.0131958844140172\n",
      "Epoch 14 - Training Loss: 0.013814329169690609\n",
      "Epoch 15 - Training Loss: 0.015124284662306309\n",
      "Epoch 16 - Training Loss: 0.012811791151762009\n",
      "Epoch 17 - Training Loss: 0.013363705016672611\n",
      "Epoch 18 - Training Loss: 0.013974051922559738\n",
      "Epoch 19 - Training Loss: 0.013819778338074684\n",
      "Epoch 20 - Training Loss: 0.013775674626231194\n",
      "Epoch 21 - Training Loss: 0.012732483446598053\n",
      "Epoch 22 - Training Loss: 0.014090802520513535\n",
      "Epoch 23 - Training Loss: 0.014145070686936378\n",
      "Epoch 24 - Training Loss: 0.01317264698445797\n",
      "Epoch 25 - Training Loss: 0.01377697754651308\n",
      "Epoch 26 - Training Loss: 0.013414928689599037\n",
      "Epoch 27 - Training Loss: 0.01333271898329258\n",
      "Epoch 28 - Training Loss: 0.013955873437225819\n",
      "Epoch 29 - Training Loss: 0.013562401756644249\n",
      "Epoch 30 - Training Loss: 0.01482914574444294\n",
      "Epoch 31 - Training Loss: 0.013539230450987816\n",
      "early stopping on epoch: 32\n",
      "Epoch 1 - Training Loss: 0.013682730495929718\n",
      "Epoch 2 - Training Loss: 0.014606501907110214\n",
      "Epoch 3 - Training Loss: 0.012981221079826355\n",
      "Epoch 4 - Training Loss: 0.015203094109892845\n",
      "Epoch 5 - Training Loss: 0.014944516122341156\n",
      "Epoch 6 - Training Loss: 0.013840248808264732\n",
      "Epoch 7 - Training Loss: 0.014545490965247154\n",
      "Epoch 8 - Training Loss: 0.014242652803659439\n",
      "Epoch 9 - Training Loss: 0.013285360299050808\n",
      "Epoch 10 - Training Loss: 0.01403703261166811\n",
      "Epoch 11 - Training Loss: 0.013843318447470665\n",
      "Epoch 12 - Training Loss: 0.014112248085439205\n",
      "Epoch 13 - Training Loss: 0.01411555614322424\n",
      "Epoch 14 - Training Loss: 0.014109679497778416\n",
      "Epoch 15 - Training Loss: 0.014684478752315044\n",
      "early stopping on epoch: 16\n",
      "Epoch 1 - Training Loss: 0.013372252695262432\n",
      "Epoch 2 - Training Loss: 0.013649593107402325\n",
      "Epoch 3 - Training Loss: 0.014492734335362911\n",
      "Epoch 4 - Training Loss: 0.014376597478985786\n",
      "Epoch 5 - Training Loss: 0.014355987310409546\n",
      "Epoch 6 - Training Loss: 0.013304464519023895\n",
      "Epoch 7 - Training Loss: 0.014213035814464092\n",
      "Epoch 8 - Training Loss: 0.01310215424746275\n",
      "Epoch 9 - Training Loss: 0.013376076705753803\n",
      "Epoch 10 - Training Loss: 0.013975209556519985\n",
      "Epoch 11 - Training Loss: 0.014191639609634876\n",
      "Epoch 12 - Training Loss: 0.014330347999930382\n",
      "Epoch 13 - Training Loss: 0.01368244830518961\n",
      "Epoch 14 - Training Loss: 0.013951043598353863\n",
      "Epoch 15 - Training Loss: 0.01374808605760336\n",
      "Epoch 16 - Training Loss: 0.01506316103041172\n",
      "Epoch 17 - Training Loss: 0.013787376694381237\n",
      "Epoch 18 - Training Loss: 0.014437557198107243\n",
      "Epoch 19 - Training Loss: 0.014522215351462364\n",
      "Epoch 20 - Training Loss: 0.013913316652178764\n",
      "Epoch 21 - Training Loss: 0.014585296623408794\n",
      "early stopping on epoch: 22\n",
      "Epoch 1 - Training Loss: 0.013254685327410698\n",
      "Epoch 2 - Training Loss: 0.012824822217226028\n",
      "Epoch 3 - Training Loss: 0.01359478384256363\n",
      "Epoch 4 - Training Loss: 0.013183253817260265\n",
      "Epoch 5 - Training Loss: 0.013576289638876915\n",
      "Epoch 6 - Training Loss: 0.014731764793395996\n",
      "Epoch 7 - Training Loss: 0.014712736941874027\n",
      "Epoch 8 - Training Loss: 0.01380255725234747\n",
      "Epoch 9 - Training Loss: 0.0131082097068429\n",
      "Epoch 10 - Training Loss: 0.013466248288750648\n",
      "Epoch 11 - Training Loss: 0.013325434178113937\n",
      "Epoch 12 - Training Loss: 0.013995064422488213\n",
      "Epoch 13 - Training Loss: 0.01468109805136919\n",
      "Epoch 14 - Training Loss: 0.013501496985554695\n",
      "Epoch 15 - Training Loss: 0.014073118567466736\n",
      "Epoch 16 - Training Loss: 0.013968855142593384\n",
      "Epoch 17 - Training Loss: 0.013589911162853241\n",
      "Epoch 18 - Training Loss: 0.01261062640696764\n",
      "Epoch 19 - Training Loss: 0.01475360058248043\n",
      "Epoch 20 - Training Loss: 0.01326048094779253\n",
      "Epoch 21 - Training Loss: 0.0137895243242383\n",
      "Epoch 22 - Training Loss: 0.01358906552195549\n",
      "Epoch 23 - Training Loss: 0.015270155854523182\n",
      "Epoch 24 - Training Loss: 0.013562311418354511\n",
      "Epoch 25 - Training Loss: 0.013731432147324085\n",
      "Epoch 26 - Training Loss: 0.01483489666134119\n",
      "Epoch 27 - Training Loss: 0.014164814725518227\n",
      "Epoch 28 - Training Loss: 0.014180810190737247\n",
      "Epoch 29 - Training Loss: 0.014588408172130585\n",
      "Epoch 30 - Training Loss: 0.01473468542098999\n",
      "Epoch 31 - Training Loss: 0.0140542546287179\n",
      "Epoch 32 - Training Loss: 0.014249864965677261\n",
      "Epoch 33 - Training Loss: 0.012910925783216953\n",
      "Epoch 34 - Training Loss: 0.01349152997136116\n",
      "Epoch 35 - Training Loss: 0.013715746812522411\n",
      "Epoch 36 - Training Loss: 0.013445141725242138\n",
      "Epoch 37 - Training Loss: 0.014266731217503548\n",
      "Epoch 38 - Training Loss: 0.014358717016875744\n",
      "Epoch 39 - Training Loss: 0.01484350673854351\n",
      "Epoch 40 - Training Loss: 0.01333208754658699\n",
      "Epoch 41 - Training Loss: 0.013705642893910408\n",
      "Epoch 42 - Training Loss: 0.013982410542666912\n",
      "Epoch 43 - Training Loss: 0.014331801794469357\n",
      "Epoch 44 - Training Loss: 0.0131673039868474\n",
      "Epoch 45 - Training Loss: 0.01413332112133503\n",
      "Epoch 46 - Training Loss: 0.014268005266785622\n",
      "Epoch 47 - Training Loss: 0.01352772582322359\n",
      "Epoch 48 - Training Loss: 0.013991442508995533\n",
      "Epoch 49 - Training Loss: 0.013911725021898746\n",
      "Epoch 50 - Training Loss: 0.013855024240911007\n",
      "Epoch 51 - Training Loss: 0.013233141973614693\n",
      "Epoch 52 - Training Loss: 0.013408131897449493\n",
      "Epoch 53 - Training Loss: 0.014865315519273281\n",
      "Epoch 54 - Training Loss: 0.013547973707318306\n",
      "Epoch 55 - Training Loss: 0.013422946445643902\n",
      "Epoch 56 - Training Loss: 0.013115989044308662\n",
      "Epoch 57 - Training Loss: 0.013117743656039238\n",
      "Epoch 58 - Training Loss: 0.01434860285371542\n",
      "Epoch 59 - Training Loss: 0.014319886453449726\n",
      "Epoch 60 - Training Loss: 0.01357595156878233\n",
      "Epoch 61 - Training Loss: 0.012658149003982544\n",
      "Epoch 62 - Training Loss: 0.015163207426667213\n",
      "Epoch 63 - Training Loss: 0.015443229116499424\n",
      "Epoch 64 - Training Loss: 0.013227050192654133\n",
      "Epoch 65 - Training Loss: 0.013890733942389488\n",
      "Epoch 66 - Training Loss: 0.012723373249173164\n",
      "Epoch 67 - Training Loss: 0.014418127946555614\n",
      "Epoch 68 - Training Loss: 0.01436636596918106\n",
      "Epoch 69 - Training Loss: 0.013023605570197105\n",
      "Epoch 70 - Training Loss: 0.014317939057946205\n",
      "Epoch 71 - Training Loss: 0.014217020012438297\n",
      "Epoch 72 - Training Loss: 0.01433867309242487\n",
      "Epoch 73 - Training Loss: 0.014975858852267265\n",
      "Epoch 74 - Training Loss: 0.013740568421781063\n",
      "Epoch 75 - Training Loss: 0.014005187898874283\n",
      "Epoch 76 - Training Loss: 0.013809900730848312\n",
      "Epoch 77 - Training Loss: 0.014351525343954563\n",
      "Epoch 78 - Training Loss: 0.013300169259309769\n",
      "Epoch 79 - Training Loss: 0.013931883499026299\n",
      "Epoch 80 - Training Loss: 0.0134531669318676\n",
      "Epoch 81 - Training Loss: 0.013631470501422882\n",
      "Epoch 82 - Training Loss: 0.013349315151572227\n",
      "Epoch 83 - Training Loss: 0.013423506170511246\n",
      "Epoch 84 - Training Loss: 0.0155237577855587\n",
      "Epoch 85 - Training Loss: 0.014547321945428848\n",
      "Epoch 86 - Training Loss: 0.013090427033603191\n",
      "Epoch 87 - Training Loss: 0.015510649420320988\n",
      "Epoch 88 - Training Loss: 0.014476769603788853\n",
      "Epoch 89 - Training Loss: 0.013751563616096973\n",
      "Epoch 90 - Training Loss: 0.01381270494312048\n",
      "Epoch 91 - Training Loss: 0.015676090493798256\n",
      "Epoch 92 - Training Loss: 0.014200006611645222\n",
      "Epoch 93 - Training Loss: 0.014270485378801823\n",
      "Epoch 94 - Training Loss: 0.013439707458019257\n",
      "Epoch 95 - Training Loss: 0.013963629491627216\n",
      "Epoch 96 - Training Loss: 0.013740243390202522\n",
      "Epoch 97 - Training Loss: 0.0154652064666152\n",
      "Epoch 98 - Training Loss: 0.014803626574575901\n",
      "Epoch 99 - Training Loss: 0.014052674174308777\n",
      "Epoch 100 - Training Loss: 0.013846111483871937\n",
      "Epoch 1 - Training Loss: 0.014747606590390205\n",
      "Epoch 2 - Training Loss: 0.012433373369276524\n",
      "Epoch 3 - Training Loss: 0.01327546127140522\n",
      "Epoch 4 - Training Loss: 0.015529626980423927\n",
      "Epoch 5 - Training Loss: 0.013154653832316399\n",
      "Epoch 6 - Training Loss: 0.014846480451524258\n",
      "Epoch 7 - Training Loss: 0.014453188516199589\n",
      "Epoch 8 - Training Loss: 0.0138587336987257\n",
      "Epoch 9 - Training Loss: 0.012815146706998348\n",
      "Epoch 10 - Training Loss: 0.013101998716592789\n",
      "Epoch 11 - Training Loss: 0.01507181953638792\n",
      "Epoch 12 - Training Loss: 0.01359194703400135\n",
      "Epoch 13 - Training Loss: 0.015217754058539867\n",
      "Epoch 14 - Training Loss: 0.014077234081923962\n",
      "Epoch 15 - Training Loss: 0.014385532587766647\n",
      "Epoch 16 - Training Loss: 0.014230894856154919\n",
      "Epoch 17 - Training Loss: 0.013593807816505432\n",
      "Epoch 18 - Training Loss: 0.012734031304717064\n",
      "Epoch 19 - Training Loss: 0.015150442719459534\n",
      "Epoch 20 - Training Loss: 0.014459483325481415\n",
      "Epoch 21 - Training Loss: 0.012706155888736248\n",
      "Epoch 22 - Training Loss: 0.014274691231548786\n",
      "Epoch 23 - Training Loss: 0.014358929358422756\n",
      "Epoch 24 - Training Loss: 0.013127515092492104\n",
      "Epoch 25 - Training Loss: 0.013790939003229141\n",
      "Epoch 26 - Training Loss: 0.014502054080367088\n",
      "Epoch 27 - Training Loss: 0.013880372978746891\n",
      "Epoch 28 - Training Loss: 0.014281968586146832\n",
      "Epoch 29 - Training Loss: 0.01353241316974163\n",
      "Epoch 30 - Training Loss: 0.013575070537626743\n",
      "Epoch 31 - Training Loss: 0.01335065346211195\n",
      "Epoch 32 - Training Loss: 0.014881350100040436\n",
      "Epoch 33 - Training Loss: 0.015474342741072178\n",
      "Epoch 34 - Training Loss: 0.015317466109991074\n",
      "Epoch 35 - Training Loss: 0.014099476858973503\n",
      "Epoch 36 - Training Loss: 0.01428687758743763\n",
      "Epoch 37 - Training Loss: 0.013922059908509254\n",
      "Epoch 38 - Training Loss: 0.014378685504198074\n",
      "Epoch 39 - Training Loss: 0.015334872528910637\n",
      "Epoch 40 - Training Loss: 0.013621247373521328\n",
      "Epoch 41 - Training Loss: 0.014554150402545929\n",
      "Epoch 42 - Training Loss: 0.013786496594548225\n",
      "Epoch 43 - Training Loss: 0.014223959296941757\n",
      "Epoch 44 - Training Loss: 0.014189404435455799\n",
      "Epoch 45 - Training Loss: 0.014494076371192932\n",
      "Epoch 46 - Training Loss: 0.013982773758471012\n",
      "Epoch 47 - Training Loss: 0.014305278658866882\n",
      "Epoch 48 - Training Loss: 0.01354908850044012\n",
      "Epoch 49 - Training Loss: 0.013892979361116886\n",
      "early stopping on epoch: 50\n",
      "Epoch 1 - Training Loss: 0.013265338726341724\n",
      "Epoch 2 - Training Loss: 0.012997745536267757\n",
      "Epoch 3 - Training Loss: 0.01365235261619091\n",
      "Epoch 4 - Training Loss: 0.015482875518500805\n",
      "Epoch 5 - Training Loss: 0.014239034615457058\n",
      "Epoch 6 - Training Loss: 0.013816103339195251\n",
      "Epoch 7 - Training Loss: 0.01478928979486227\n",
      "Epoch 8 - Training Loss: 0.013054697774350643\n",
      "Epoch 9 - Training Loss: 0.0131348492577672\n",
      "Epoch 10 - Training Loss: 0.013734063133597374\n",
      "Epoch 11 - Training Loss: 0.01401247177273035\n",
      "Epoch 12 - Training Loss: 0.015333736315369606\n",
      "Epoch 13 - Training Loss: 0.01480036973953247\n",
      "Epoch 14 - Training Loss: 0.014452258124947548\n",
      "Epoch 15 - Training Loss: 0.01374743226915598\n",
      "Epoch 16 - Training Loss: 0.015469571575522423\n",
      "Epoch 17 - Training Loss: 0.013425109907984734\n",
      "Epoch 18 - Training Loss: 0.014517034403979778\n",
      "Epoch 19 - Training Loss: 0.014578459784388542\n",
      "Epoch 20 - Training Loss: 0.012970059178769588\n",
      "Epoch 21 - Training Loss: 0.014453621581196785\n",
      "Epoch 22 - Training Loss: 0.01395345851778984\n",
      "Epoch 23 - Training Loss: 0.013383672572672367\n",
      "Epoch 24 - Training Loss: 0.013601353392004967\n",
      "Epoch 25 - Training Loss: 0.01407083310186863\n",
      "Epoch 26 - Training Loss: 0.013772285543382168\n",
      "Epoch 27 - Training Loss: 0.014117407612502575\n",
      "Epoch 28 - Training Loss: 0.013702314347028732\n",
      "Epoch 29 - Training Loss: 0.014858596958220005\n",
      "Epoch 30 - Training Loss: 0.0139019088819623\n",
      "Epoch 31 - Training Loss: 0.013815504498779774\n",
      "Epoch 32 - Training Loss: 0.015601921826601028\n",
      "Epoch 33 - Training Loss: 0.014675403013825417\n",
      "Epoch 34 - Training Loss: 0.014266913756728172\n",
      "Epoch 35 - Training Loss: 0.014030158519744873\n",
      "Epoch 36 - Training Loss: 0.01277733501046896\n",
      "Epoch 37 - Training Loss: 0.013934480026364326\n",
      "Epoch 38 - Training Loss: 0.014885746873915195\n",
      "Epoch 39 - Training Loss: 0.014920022338628769\n",
      "Epoch 40 - Training Loss: 0.013135264627635479\n",
      "Epoch 41 - Training Loss: 0.013766683638095856\n",
      "Epoch 42 - Training Loss: 0.013761727139353752\n",
      "Epoch 43 - Training Loss: 0.013300537131726742\n",
      "Epoch 44 - Training Loss: 0.014080160297453403\n",
      "Epoch 45 - Training Loss: 0.013682393357157707\n",
      "Epoch 46 - Training Loss: 0.015767721459269524\n",
      "Epoch 47 - Training Loss: 0.014988923445343971\n",
      "Epoch 48 - Training Loss: 0.01293167844414711\n",
      "Epoch 49 - Training Loss: 0.013874158263206482\n",
      "Epoch 50 - Training Loss: 0.012745080515742302\n",
      "Epoch 51 - Training Loss: 0.01343825925141573\n",
      "Epoch 52 - Training Loss: 0.013269614428281784\n",
      "Epoch 53 - Training Loss: 0.013761047273874283\n",
      "Epoch 54 - Training Loss: 0.013286772184073925\n",
      "Epoch 55 - Training Loss: 0.013855216093361378\n",
      "Epoch 56 - Training Loss: 0.013671280816197395\n",
      "Epoch 57 - Training Loss: 0.015070591121912003\n",
      "Epoch 58 - Training Loss: 0.012777633965015411\n",
      "Epoch 59 - Training Loss: 0.013662686571478844\n",
      "Epoch 60 - Training Loss: 0.013617066666483879\n",
      "Epoch 61 - Training Loss: 0.014109313488006592\n",
      "Epoch 62 - Training Loss: 0.014843745157122612\n",
      "Epoch 63 - Training Loss: 0.012842318043112755\n",
      "Epoch 64 - Training Loss: 0.013561883941292763\n",
      "Epoch 65 - Training Loss: 0.013034769333899021\n",
      "Epoch 66 - Training Loss: 0.014115783385932446\n",
      "Epoch 67 - Training Loss: 0.013659482821822166\n",
      "Epoch 68 - Training Loss: 0.013856940902769566\n",
      "Epoch 69 - Training Loss: 0.01387239433825016\n",
      "Epoch 70 - Training Loss: 0.014619327150285244\n",
      "Epoch 71 - Training Loss: 0.014311272650957108\n",
      "Epoch 72 - Training Loss: 0.014264600351452827\n",
      "Epoch 73 - Training Loss: 0.013212325982749462\n",
      "Epoch 74 - Training Loss: 0.015171151608228683\n",
      "Epoch 75 - Training Loss: 0.013472752645611763\n",
      "Epoch 76 - Training Loss: 0.01471138559281826\n",
      "Epoch 77 - Training Loss: 0.014047841541469097\n",
      "Epoch 78 - Training Loss: 0.01396961510181427\n",
      "Epoch 79 - Training Loss: 0.013966855593025684\n",
      "Epoch 80 - Training Loss: 0.01427949033677578\n",
      "Epoch 81 - Training Loss: 0.013556067831814289\n",
      "Epoch 82 - Training Loss: 0.015229721553623676\n",
      "Epoch 83 - Training Loss: 0.012871123850345612\n",
      "Epoch 84 - Training Loss: 0.014674335718154907\n",
      "Epoch 85 - Training Loss: 0.013997222296893597\n",
      "Epoch 86 - Training Loss: 0.013886562548577785\n",
      "Epoch 87 - Training Loss: 0.012657674960792065\n",
      "Epoch 88 - Training Loss: 0.014448791742324829\n",
      "Epoch 89 - Training Loss: 0.013681508600711823\n",
      "Epoch 90 - Training Loss: 0.014864587225019932\n",
      "Epoch 91 - Training Loss: 0.014551077038049698\n",
      "Epoch 92 - Training Loss: 0.014745492488145828\n",
      "Epoch 93 - Training Loss: 0.014922693371772766\n",
      "Epoch 94 - Training Loss: 0.01469334401190281\n",
      "Epoch 95 - Training Loss: 0.014006064273416996\n",
      "Epoch 96 - Training Loss: 0.01387012843042612\n",
      "Epoch 97 - Training Loss: 0.01323921512812376\n",
      "Epoch 98 - Training Loss: 0.01342445332556963\n",
      "Epoch 99 - Training Loss: 0.014706417918205261\n",
      "Epoch 100 - Training Loss: 0.013276959769427776\n",
      "Epoch 1 - Training Loss: 0.014442402869462967\n",
      "Epoch 2 - Training Loss: 0.013489668257534504\n",
      "Epoch 3 - Training Loss: 0.01410036999732256\n",
      "Epoch 4 - Training Loss: 0.0136311249807477\n",
      "Epoch 5 - Training Loss: 0.014189127832651138\n",
      "Epoch 6 - Training Loss: 0.013742918148636818\n",
      "Epoch 7 - Training Loss: 0.013224427588284016\n",
      "Epoch 8 - Training Loss: 0.014534670859575272\n",
      "Epoch 9 - Training Loss: 0.013803588226437569\n",
      "Epoch 10 - Training Loss: 0.01400747336447239\n",
      "Epoch 11 - Training Loss: 0.014341918751597404\n",
      "Epoch 12 - Training Loss: 0.01409964170306921\n",
      "Epoch 13 - Training Loss: 0.013434396125376225\n",
      "Epoch 14 - Training Loss: 0.013915767893195152\n",
      "Epoch 15 - Training Loss: 0.014985466375946999\n",
      "Epoch 16 - Training Loss: 0.01412751991301775\n",
      "Epoch 17 - Training Loss: 0.0134157445281744\n",
      "Epoch 18 - Training Loss: 0.013345940038561821\n",
      "Epoch 19 - Training Loss: 0.013725855387747288\n",
      "Epoch 20 - Training Loss: 0.012984716333448887\n",
      "Epoch 21 - Training Loss: 0.014191757887601852\n",
      "Epoch 22 - Training Loss: 0.015783993527293205\n",
      "Epoch 23 - Training Loss: 0.01372662652283907\n",
      "Epoch 24 - Training Loss: 0.01479962095618248\n",
      "Epoch 25 - Training Loss: 0.013891567476093769\n",
      "Epoch 26 - Training Loss: 0.01329538132995367\n",
      "Epoch 27 - Training Loss: 0.014185448177158833\n",
      "Epoch 28 - Training Loss: 0.013252082280814648\n",
      "Epoch 29 - Training Loss: 0.015068966895341873\n",
      "Epoch 30 - Training Loss: 0.013325857929885387\n",
      "Epoch 31 - Training Loss: 0.013690938241779804\n",
      "Epoch 32 - Training Loss: 0.012721262872219086\n",
      "Epoch 33 - Training Loss: 0.014406953938305378\n",
      "Epoch 34 - Training Loss: 0.014099417254328728\n",
      "Epoch 35 - Training Loss: 0.01501358300447464\n",
      "Epoch 36 - Training Loss: 0.013989067636430264\n",
      "Epoch 37 - Training Loss: 0.014338521286845207\n",
      "Epoch 38 - Training Loss: 0.0151552464812994\n",
      "Epoch 39 - Training Loss: 0.013140044175088406\n",
      "Epoch 40 - Training Loss: 0.012538095004856586\n",
      "Epoch 41 - Training Loss: 0.01593715511262417\n",
      "Epoch 42 - Training Loss: 0.014428081922233105\n",
      "Epoch 43 - Training Loss: 0.014606625773012638\n",
      "Epoch 44 - Training Loss: 0.014618877321481705\n",
      "Epoch 45 - Training Loss: 0.013810339383780956\n",
      "Epoch 46 - Training Loss: 0.014204795472323895\n",
      "Epoch 47 - Training Loss: 0.013934608548879623\n",
      "Epoch 48 - Training Loss: 0.014333226718008518\n",
      "Epoch 49 - Training Loss: 0.014359766617417336\n",
      "Epoch 50 - Training Loss: 0.01506679505109787\n",
      "Epoch 51 - Training Loss: 0.014993448741734028\n",
      "early stopping on epoch: 52\n",
      "Epoch 1 - Training Loss: 0.012591635808348656\n",
      "Epoch 2 - Training Loss: 0.014496914111077785\n",
      "Epoch 3 - Training Loss: 0.014746556989848614\n",
      "Epoch 4 - Training Loss: 0.015073337592184544\n",
      "Epoch 5 - Training Loss: 0.014097950421273708\n",
      "Epoch 6 - Training Loss: 0.013561934232711792\n",
      "Epoch 7 - Training Loss: 0.015335962176322937\n",
      "Epoch 8 - Training Loss: 0.015635553747415543\n",
      "Epoch 9 - Training Loss: 0.014945310540497303\n",
      "Epoch 10 - Training Loss: 0.01414692122489214\n",
      "Epoch 11 - Training Loss: 0.012820687144994736\n",
      "Epoch 12 - Training Loss: 0.014984773471951485\n",
      "Epoch 13 - Training Loss: 0.014018526300787926\n",
      "Epoch 14 - Training Loss: 0.014470160938799381\n",
      "Epoch 15 - Training Loss: 0.014056744985282421\n",
      "Epoch 16 - Training Loss: 0.013216144405305386\n",
      "Epoch 17 - Training Loss: 0.013007118366658688\n",
      "Epoch 18 - Training Loss: 0.013383283279836178\n",
      "Epoch 19 - Training Loss: 0.014054222032427788\n",
      "Epoch 20 - Training Loss: 0.014458631165325642\n",
      "Epoch 21 - Training Loss: 0.01375491637736559\n",
      "Epoch 22 - Training Loss: 0.014306140132248402\n",
      "Epoch 23 - Training Loss: 0.013697221875190735\n",
      "Epoch 24 - Training Loss: 0.014603553339838982\n",
      "Epoch 25 - Training Loss: 0.013804114423692226\n",
      "Epoch 26 - Training Loss: 0.014498353004455566\n",
      "Epoch 27 - Training Loss: 0.013945859856903553\n",
      "Epoch 28 - Training Loss: 0.013726995326578617\n",
      "Epoch 29 - Training Loss: 0.01245763711631298\n",
      "Epoch 30 - Training Loss: 0.014657474122941494\n",
      "Epoch 31 - Training Loss: 0.01401685830205679\n",
      "Epoch 32 - Training Loss: 0.014802438206970692\n",
      "Epoch 33 - Training Loss: 0.013292196206748486\n",
      "Epoch 34 - Training Loss: 0.01459726132452488\n",
      "Epoch 35 - Training Loss: 0.01315731555223465\n",
      "Epoch 36 - Training Loss: 0.013317052274942398\n",
      "Epoch 37 - Training Loss: 0.01441757008433342\n",
      "Epoch 38 - Training Loss: 0.01330077275633812\n",
      "Epoch 39 - Training Loss: 0.013057184405624866\n",
      "Epoch 40 - Training Loss: 0.0135506521910429\n",
      "Epoch 41 - Training Loss: 0.013574179261922836\n",
      "Epoch 42 - Training Loss: 0.013569319620728493\n",
      "Epoch 43 - Training Loss: 0.01447480358183384\n",
      "Epoch 44 - Training Loss: 0.0130477799102664\n",
      "Epoch 45 - Training Loss: 0.013704168610274792\n",
      "Epoch 46 - Training Loss: 0.013897334225475788\n",
      "Epoch 47 - Training Loss: 0.01454917248338461\n",
      "Epoch 48 - Training Loss: 0.013338635675609112\n",
      "Epoch 49 - Training Loss: 0.013764692470431328\n",
      "Epoch 50 - Training Loss: 0.015107447281479836\n",
      "Epoch 51 - Training Loss: 0.013513533398509026\n",
      "Epoch 52 - Training Loss: 0.013718368485569954\n",
      "Epoch 53 - Training Loss: 0.013792195357382298\n",
      "Epoch 54 - Training Loss: 0.014163138344883919\n",
      "Epoch 55 - Training Loss: 0.014085830189287663\n",
      "Epoch 56 - Training Loss: 0.013401199132204056\n",
      "Epoch 57 - Training Loss: 0.014390748925507069\n",
      "Epoch 58 - Training Loss: 0.013986065052449703\n",
      "Epoch 59 - Training Loss: 0.012838529422879219\n",
      "Epoch 60 - Training Loss: 0.015374471433460712\n",
      "Epoch 61 - Training Loss: 0.01270277425646782\n",
      "Epoch 62 - Training Loss: 0.0136170769110322\n",
      "Epoch 63 - Training Loss: 0.014409724622964859\n",
      "Epoch 64 - Training Loss: 0.012934565544128418\n",
      "Epoch 65 - Training Loss: 0.014306033961474895\n",
      "Epoch 66 - Training Loss: 0.014222054742276669\n",
      "Epoch 67 - Training Loss: 0.014209010638296604\n",
      "Epoch 68 - Training Loss: 0.013707771897315979\n",
      "Epoch 69 - Training Loss: 0.013631016947329044\n",
      "Epoch 70 - Training Loss: 0.013058600947260857\n",
      "Epoch 71 - Training Loss: 0.014521770179271698\n",
      "Epoch 72 - Training Loss: 0.014290510676801205\n",
      "Epoch 73 - Training Loss: 0.013947850093245506\n",
      "Epoch 74 - Training Loss: 0.01380681898444891\n",
      "Epoch 75 - Training Loss: 0.013075929135084152\n",
      "Epoch 76 - Training Loss: 0.012940825894474983\n",
      "Epoch 77 - Training Loss: 0.014944406226277351\n",
      "Epoch 78 - Training Loss: 0.012810099869966507\n",
      "Epoch 79 - Training Loss: 0.014177178964018822\n",
      "Epoch 80 - Training Loss: 0.014229544438421726\n",
      "Epoch 81 - Training Loss: 0.01387826632708311\n",
      "Epoch 82 - Training Loss: 0.013360312208533287\n",
      "Epoch 83 - Training Loss: 0.015339603647589684\n",
      "Epoch 84 - Training Loss: 0.01345378439873457\n",
      "Epoch 85 - Training Loss: 0.014384725131094456\n",
      "Epoch 86 - Training Loss: 0.01420559361577034\n",
      "Epoch 87 - Training Loss: 0.014015811495482922\n",
      "Epoch 88 - Training Loss: 0.014120702631771564\n",
      "Epoch 89 - Training Loss: 0.015183902345597744\n",
      "Epoch 90 - Training Loss: 0.013184036128222942\n",
      "Epoch 91 - Training Loss: 0.01327109057456255\n",
      "Epoch 92 - Training Loss: 0.013171947561204433\n",
      "Epoch 93 - Training Loss: 0.014261688105762005\n",
      "Epoch 94 - Training Loss: 0.013143538497388363\n",
      "Epoch 95 - Training Loss: 0.012926679104566574\n",
      "Epoch 96 - Training Loss: 0.013179785571992397\n",
      "Epoch 97 - Training Loss: 0.01336519606411457\n",
      "Epoch 98 - Training Loss: 0.01383212674409151\n",
      "Epoch 99 - Training Loss: 0.014367333613336086\n",
      "Epoch 100 - Training Loss: 0.01373288594186306\n",
      "Epoch 1 - Training Loss: 0.013528173789381981\n",
      "Epoch 2 - Training Loss: 0.013369720429182053\n",
      "Epoch 3 - Training Loss: 0.01519610546529293\n",
      "Epoch 4 - Training Loss: 0.012913821265101433\n",
      "Epoch 5 - Training Loss: 0.013074335642158985\n",
      "Epoch 6 - Training Loss: 0.016026129946112633\n",
      "Epoch 7 - Training Loss: 0.013439485803246498\n",
      "Epoch 8 - Training Loss: 0.01368514634668827\n",
      "Epoch 9 - Training Loss: 0.012700329534709454\n",
      "Epoch 10 - Training Loss: 0.015043065883219242\n",
      "Epoch 11 - Training Loss: 0.014361672103404999\n",
      "Epoch 12 - Training Loss: 0.013929656706750393\n",
      "Epoch 13 - Training Loss: 0.013997226022183895\n",
      "Epoch 14 - Training Loss: 0.014832580462098122\n",
      "Epoch 15 - Training Loss: 0.014005121774971485\n",
      "Epoch 16 - Training Loss: 0.01335214078426361\n",
      "Epoch 17 - Training Loss: 0.014382192865014076\n",
      "Epoch 18 - Training Loss: 0.01365741342306137\n",
      "Epoch 19 - Training Loss: 0.012903986498713493\n",
      "Epoch 20 - Training Loss: 0.01389822643250227\n",
      "Epoch 21 - Training Loss: 0.014917664229869843\n",
      "Epoch 22 - Training Loss: 0.013835105113685131\n",
      "Epoch 23 - Training Loss: 0.014025036245584488\n",
      "Epoch 24 - Training Loss: 0.013991334475576878\n",
      "Epoch 25 - Training Loss: 0.013503462076187134\n",
      "Epoch 26 - Training Loss: 0.01432679034769535\n",
      "Epoch 27 - Training Loss: 0.014669331721961498\n",
      "Epoch 28 - Training Loss: 0.013767256401479244\n",
      "Epoch 29 - Training Loss: 0.01351588312536478\n",
      "Epoch 30 - Training Loss: 0.014198417775332928\n",
      "Epoch 31 - Training Loss: 0.014030984602868557\n",
      "early stopping on epoch: 32\n",
      "Epoch 1 - Training Loss: 0.014557190239429474\n",
      "Epoch 2 - Training Loss: 0.01422933954745531\n",
      "Epoch 3 - Training Loss: 0.012883607298135757\n",
      "Epoch 4 - Training Loss: 0.013448089361190796\n",
      "Epoch 5 - Training Loss: 0.015483375638723373\n",
      "Epoch 6 - Training Loss: 0.013864410109817982\n",
      "Epoch 7 - Training Loss: 0.013936308212578297\n",
      "Epoch 8 - Training Loss: 0.013813096098601818\n",
      "Epoch 9 - Training Loss: 0.01340867206454277\n",
      "Epoch 10 - Training Loss: 0.01519376877695322\n",
      "Epoch 11 - Training Loss: 0.013653024099767208\n",
      "Epoch 12 - Training Loss: 0.013603740371763706\n",
      "Epoch 13 - Training Loss: 0.013631712645292282\n",
      "Epoch 14 - Training Loss: 0.014153317548334599\n",
      "Epoch 15 - Training Loss: 0.014644188806414604\n",
      "Epoch 16 - Training Loss: 0.014237675815820694\n",
      "Epoch 17 - Training Loss: 0.01394361536949873\n",
      "Epoch 18 - Training Loss: 0.014423917047679424\n",
      "Epoch 19 - Training Loss: 0.01386999897658825\n",
      "Epoch 20 - Training Loss: 0.014003888703882694\n",
      "early stopping on epoch: 21\n",
      "Epoch 1 - Training Loss: 0.014511354267597198\n",
      "Epoch 2 - Training Loss: 0.013632044196128845\n",
      "Epoch 3 - Training Loss: 0.014081141911447048\n",
      "Epoch 4 - Training Loss: 0.014148421585559845\n",
      "Epoch 5 - Training Loss: 0.013283606618642807\n",
      "Epoch 6 - Training Loss: 0.014635223895311356\n",
      "Epoch 7 - Training Loss: 0.014551437459886074\n",
      "Epoch 8 - Training Loss: 0.013304302468895912\n",
      "Epoch 9 - Training Loss: 0.013653256930410862\n",
      "Epoch 10 - Training Loss: 0.01381225511431694\n",
      "Epoch 11 - Training Loss: 0.014246365055441856\n",
      "Epoch 12 - Training Loss: 0.012870220467448235\n",
      "Epoch 13 - Training Loss: 0.014194654300808907\n",
      "Epoch 14 - Training Loss: 0.012811356224119663\n",
      "Epoch 15 - Training Loss: 0.013741630129516125\n",
      "Epoch 16 - Training Loss: 0.013322131708264351\n",
      "Epoch 17 - Training Loss: 0.014599081128835678\n",
      "Epoch 18 - Training Loss: 0.01235280092805624\n",
      "Epoch 19 - Training Loss: 0.014572705142199993\n",
      "Epoch 20 - Training Loss: 0.014352410100400448\n",
      "Epoch 21 - Training Loss: 0.013907966203987598\n",
      "Epoch 22 - Training Loss: 0.013718984089791775\n",
      "Epoch 23 - Training Loss: 0.013463645242154598\n",
      "Epoch 24 - Training Loss: 0.015864046290516853\n",
      "Epoch 25 - Training Loss: 0.013809147290885448\n",
      "Epoch 26 - Training Loss: 0.01458583865314722\n",
      "Epoch 27 - Training Loss: 0.01327919214963913\n",
      "Epoch 28 - Training Loss: 0.013250996358692646\n",
      "Epoch 29 - Training Loss: 0.014442301355302334\n",
      "Epoch 30 - Training Loss: 0.013824558816850185\n",
      "Epoch 31 - Training Loss: 0.014161105267703533\n",
      "Epoch 32 - Training Loss: 0.012967550195753574\n",
      "Epoch 33 - Training Loss: 0.01484263688325882\n",
      "Epoch 34 - Training Loss: 0.014520430006086826\n",
      "Epoch 35 - Training Loss: 0.014225013554096222\n",
      "Epoch 36 - Training Loss: 0.01339088473469019\n",
      "Epoch 37 - Training Loss: 0.01459299586713314\n",
      "Epoch 38 - Training Loss: 0.014761709608137608\n",
      "Epoch 39 - Training Loss: 0.012960205785930157\n",
      "Epoch 40 - Training Loss: 0.014767421409487724\n",
      "Epoch 41 - Training Loss: 0.015490700490772724\n",
      "Epoch 42 - Training Loss: 0.013352815061807632\n",
      "Epoch 43 - Training Loss: 0.014742878265678883\n",
      "Epoch 44 - Training Loss: 0.015071568079292774\n",
      "Epoch 45 - Training Loss: 0.013608652167022228\n",
      "Epoch 46 - Training Loss: 0.013778272084891796\n",
      "Epoch 47 - Training Loss: 0.013065243139863014\n",
      "Epoch 48 - Training Loss: 0.014045953750610352\n",
      "Epoch 49 - Training Loss: 0.012912759557366371\n",
      "Epoch 50 - Training Loss: 0.012872097082436085\n",
      "Epoch 51 - Training Loss: 0.013770954683423042\n",
      "Epoch 52 - Training Loss: 0.013578320853412151\n",
      "Epoch 53 - Training Loss: 0.01387654710561037\n",
      "Epoch 54 - Training Loss: 0.015240859240293503\n",
      "Epoch 55 - Training Loss: 0.013913242146372795\n",
      "Epoch 56 - Training Loss: 0.01548133883625269\n",
      "Epoch 57 - Training Loss: 0.015661081299185753\n",
      "Epoch 58 - Training Loss: 0.014587609097361565\n",
      "Epoch 59 - Training Loss: 0.013785523362457752\n",
      "Epoch 60 - Training Loss: 0.014011267572641373\n",
      "Epoch 61 - Training Loss: 0.01376285869628191\n",
      "Epoch 62 - Training Loss: 0.013367093168199062\n",
      "Epoch 63 - Training Loss: 0.013473037630319595\n",
      "Epoch 64 - Training Loss: 0.012512213550508022\n",
      "Epoch 65 - Training Loss: 0.014209091663360596\n",
      "Epoch 66 - Training Loss: 0.014756591059267521\n",
      "Epoch 67 - Training Loss: 0.014016355387866497\n",
      "Epoch 68 - Training Loss: 0.01431270968168974\n",
      "Epoch 69 - Training Loss: 0.014908994548022747\n",
      "Epoch 70 - Training Loss: 0.013840674422681332\n",
      "Epoch 71 - Training Loss: 0.014371542260050774\n",
      "Epoch 72 - Training Loss: 0.014637083746492863\n",
      "Epoch 73 - Training Loss: 0.013971925713121891\n",
      "Epoch 74 - Training Loss: 0.014422977343201637\n",
      "early stopping on epoch: 75\n",
      "Epoch 1 - Training Loss: 0.014368759468197823\n",
      "Epoch 2 - Training Loss: 0.013795245438814163\n",
      "Epoch 3 - Training Loss: 0.013739706948399544\n",
      "Epoch 4 - Training Loss: 0.01425881590694189\n",
      "Epoch 5 - Training Loss: 0.01447173859924078\n",
      "Epoch 6 - Training Loss: 0.014587544836103916\n",
      "Epoch 7 - Training Loss: 0.0137075399979949\n",
      "Epoch 8 - Training Loss: 0.013965207152068615\n",
      "Epoch 9 - Training Loss: 0.014915197156369686\n",
      "Epoch 10 - Training Loss: 0.014216206967830658\n",
      "early stopping on epoch: 11\n",
      "Epoch 1 - Training Loss: 0.013467013835906982\n",
      "Epoch 2 - Training Loss: 0.014430593699216843\n",
      "Epoch 3 - Training Loss: 0.013183395378291607\n",
      "Epoch 4 - Training Loss: 0.013917578384280205\n",
      "Epoch 5 - Training Loss: 0.014498142525553703\n",
      "Epoch 6 - Training Loss: 0.014669510535895824\n",
      "Epoch 7 - Training Loss: 0.014821925200521946\n",
      "Epoch 8 - Training Loss: 0.013384494930505753\n",
      "Epoch 9 - Training Loss: 0.013365846127271652\n",
      "Epoch 10 - Training Loss: 0.014342518523335457\n",
      "Epoch 11 - Training Loss: 0.015240402892231941\n",
      "Epoch 12 - Training Loss: 0.013942974619567394\n",
      "Epoch 13 - Training Loss: 0.014370372518897057\n",
      "Epoch 14 - Training Loss: 0.013638047501444817\n",
      "Epoch 15 - Training Loss: 0.012651005759835243\n",
      "Epoch 16 - Training Loss: 0.014714315533638\n",
      "Epoch 17 - Training Loss: 0.014120643027126789\n",
      "Epoch 18 - Training Loss: 0.01373395323753357\n",
      "Epoch 19 - Training Loss: 0.01376167219132185\n",
      "Epoch 20 - Training Loss: 0.013312390074133873\n",
      "Epoch 21 - Training Loss: 0.014554481953382492\n",
      "Epoch 22 - Training Loss: 0.014707651920616627\n",
      "Epoch 23 - Training Loss: 0.013268759474158287\n",
      "Epoch 24 - Training Loss: 0.013182753697037697\n",
      "Epoch 25 - Training Loss: 0.013654448091983795\n",
      "Epoch 26 - Training Loss: 0.015165301039814949\n",
      "Epoch 27 - Training Loss: 0.013624725863337517\n",
      "Epoch 28 - Training Loss: 0.014195949770510197\n",
      "Epoch 29 - Training Loss: 0.014768240973353386\n",
      "Epoch 30 - Training Loss: 0.013537830673158169\n",
      "Epoch 31 - Training Loss: 0.013597606681287289\n",
      "Epoch 32 - Training Loss: 0.013972706161439419\n",
      "Epoch 33 - Training Loss: 0.013294236734509468\n",
      "Epoch 34 - Training Loss: 0.015000225976109505\n",
      "Epoch 35 - Training Loss: 0.01522090844810009\n",
      "Epoch 36 - Training Loss: 0.014219224452972412\n",
      "Epoch 37 - Training Loss: 0.01265987753868103\n",
      "Epoch 38 - Training Loss: 0.01401565596461296\n",
      "Epoch 39 - Training Loss: 0.013695049099624157\n",
      "Epoch 40 - Training Loss: 0.014104820787906647\n",
      "Epoch 41 - Training Loss: 0.013425598852336407\n",
      "Epoch 42 - Training Loss: 0.01345105655491352\n",
      "Epoch 43 - Training Loss: 0.013287322595715523\n",
      "Epoch 44 - Training Loss: 0.013301115483045578\n",
      "Epoch 45 - Training Loss: 0.015253841876983643\n",
      "Epoch 46 - Training Loss: 0.0132439024746418\n",
      "Epoch 47 - Training Loss: 0.015435810200870037\n",
      "Epoch 48 - Training Loss: 0.01362752914428711\n",
      "Epoch 49 - Training Loss: 0.013548416085541248\n",
      "Epoch 50 - Training Loss: 0.014384607784450054\n",
      "Epoch 51 - Training Loss: 0.013604758307337761\n",
      "Epoch 52 - Training Loss: 0.014649806544184685\n",
      "Epoch 53 - Training Loss: 0.013750859536230564\n",
      "Epoch 54 - Training Loss: 0.013349121436476707\n",
      "Epoch 55 - Training Loss: 0.014153729192912579\n",
      "Epoch 56 - Training Loss: 0.01381121389567852\n",
      "Epoch 57 - Training Loss: 0.015471501275897026\n",
      "Epoch 58 - Training Loss: 0.013935273513197899\n",
      "Epoch 59 - Training Loss: 0.01332634687423706\n",
      "Epoch 60 - Training Loss: 0.0134895583614707\n",
      "Epoch 61 - Training Loss: 0.013607691042125225\n",
      "Epoch 62 - Training Loss: 0.013193458318710327\n",
      "Epoch 63 - Training Loss: 0.014668782241642475\n",
      "Epoch 64 - Training Loss: 0.014300179667770863\n",
      "Epoch 65 - Training Loss: 0.014543845318257809\n",
      "Epoch 66 - Training Loss: 0.01403994020074606\n",
      "Epoch 67 - Training Loss: 0.012157238088548183\n",
      "Epoch 68 - Training Loss: 0.013315989635884762\n",
      "Epoch 69 - Training Loss: 0.014183387160301208\n",
      "Epoch 70 - Training Loss: 0.013398256152868271\n",
      "Epoch 71 - Training Loss: 0.014311231672763824\n",
      "Epoch 72 - Training Loss: 0.013933846727013588\n",
      "Epoch 73 - Training Loss: 0.014723635278642178\n",
      "Epoch 74 - Training Loss: 0.01298634335398674\n",
      "Epoch 75 - Training Loss: 0.013141036964952946\n",
      "Epoch 76 - Training Loss: 0.013580458238720894\n",
      "Epoch 77 - Training Loss: 0.01421377807855606\n",
      "Epoch 78 - Training Loss: 0.01356773916631937\n",
      "Epoch 79 - Training Loss: 0.013461379334330559\n",
      "Epoch 80 - Training Loss: 0.013244831934571266\n",
      "Epoch 81 - Training Loss: 0.0145680271089077\n",
      "Epoch 82 - Training Loss: 0.014185783453285694\n",
      "Epoch 83 - Training Loss: 0.013477867469191551\n",
      "Epoch 84 - Training Loss: 0.013096164911985397\n",
      "Epoch 85 - Training Loss: 0.014090357348322868\n",
      "Epoch 86 - Training Loss: 0.013823609799146652\n",
      "Epoch 87 - Training Loss: 0.013926281593739986\n",
      "Epoch 88 - Training Loss: 0.014363748952746391\n",
      "Epoch 89 - Training Loss: 0.01446992252022028\n",
      "Epoch 90 - Training Loss: 0.01476097758859396\n",
      "Epoch 91 - Training Loss: 0.013982154428958893\n",
      "Epoch 92 - Training Loss: 0.013172526843845844\n",
      "Epoch 93 - Training Loss: 0.014939788728952408\n",
      "Epoch 94 - Training Loss: 0.013388622552156448\n",
      "Epoch 95 - Training Loss: 0.014280639588832855\n",
      "Epoch 96 - Training Loss: 0.014912602491676807\n",
      "Epoch 97 - Training Loss: 0.014201309531927109\n",
      "Epoch 98 - Training Loss: 0.013546104542911053\n",
      "Epoch 99 - Training Loss: 0.012705625966191292\n",
      "Epoch 100 - Training Loss: 0.013374553993344307\n",
      "Epoch 1 - Training Loss: 0.014892371371388435\n",
      "Epoch 2 - Training Loss: 0.014363210648298264\n",
      "Epoch 3 - Training Loss: 0.013432258740067482\n",
      "Epoch 4 - Training Loss: 0.015519773587584496\n",
      "Epoch 5 - Training Loss: 0.01353867631405592\n",
      "Epoch 6 - Training Loss: 0.015359235927462578\n",
      "Epoch 7 - Training Loss: 0.013807927258312702\n",
      "Epoch 8 - Training Loss: 0.014655956998467445\n",
      "Epoch 9 - Training Loss: 0.013663962483406067\n",
      "Epoch 10 - Training Loss: 0.014715570956468582\n",
      "Epoch 11 - Training Loss: 0.014320746064186096\n",
      "Epoch 12 - Training Loss: 0.0128867756575346\n",
      "Epoch 13 - Training Loss: 0.015122286975383759\n",
      "Epoch 14 - Training Loss: 0.013910099864006042\n",
      "Epoch 15 - Training Loss: 0.012752603739500046\n",
      "Epoch 16 - Training Loss: 0.013864330016076565\n",
      "Epoch 17 - Training Loss: 0.014961320906877518\n",
      "Epoch 18 - Training Loss: 0.013172612525522709\n",
      "Epoch 19 - Training Loss: 0.013778463006019592\n",
      "Epoch 20 - Training Loss: 0.014553632587194443\n",
      "Epoch 21 - Training Loss: 0.013193710707128048\n",
      "Epoch 22 - Training Loss: 0.014077506959438324\n",
      "Epoch 23 - Training Loss: 0.0138690872117877\n",
      "Epoch 24 - Training Loss: 0.01410206500440836\n",
      "Epoch 25 - Training Loss: 0.01513159554451704\n",
      "Epoch 26 - Training Loss: 0.014294954016804695\n",
      "Epoch 27 - Training Loss: 0.013869239017367363\n",
      "Epoch 28 - Training Loss: 0.01436528842896223\n",
      "Epoch 29 - Training Loss: 0.01397426426410675\n",
      "Epoch 30 - Training Loss: 0.013569296337664127\n",
      "Epoch 31 - Training Loss: 0.0135453836992383\n",
      "Epoch 32 - Training Loss: 0.01430199109017849\n",
      "Epoch 33 - Training Loss: 0.014759787358343601\n",
      "Epoch 34 - Training Loss: 0.013822466135025024\n",
      "Epoch 35 - Training Loss: 0.01308735553175211\n",
      "Epoch 36 - Training Loss: 0.015656817704439163\n",
      "Epoch 37 - Training Loss: 0.013254452496767044\n",
      "Epoch 38 - Training Loss: 0.013981944881379604\n",
      "Epoch 39 - Training Loss: 0.012782363221049309\n",
      "Epoch 40 - Training Loss: 0.014851241372525692\n",
      "Epoch 41 - Training Loss: 0.014430089853703976\n",
      "Epoch 42 - Training Loss: 0.014681435190141201\n",
      "Epoch 43 - Training Loss: 0.013431468978524208\n",
      "Epoch 44 - Training Loss: 0.014003638178110123\n",
      "Epoch 45 - Training Loss: 0.013214942067861557\n",
      "Epoch 46 - Training Loss: 0.013990188017487526\n",
      "Epoch 47 - Training Loss: 0.013120423071086407\n",
      "Epoch 48 - Training Loss: 0.014500506222248077\n",
      "Epoch 49 - Training Loss: 0.01408756710588932\n",
      "Epoch 50 - Training Loss: 0.013655145652592182\n",
      "Epoch 51 - Training Loss: 0.014546730555593967\n",
      "Epoch 52 - Training Loss: 0.014898589812219143\n",
      "Epoch 53 - Training Loss: 0.014490156434476376\n",
      "Epoch 54 - Training Loss: 0.014027156867086887\n",
      "Epoch 55 - Training Loss: 0.014511801302433014\n",
      "Epoch 56 - Training Loss: 0.014024906791746616\n",
      "Epoch 57 - Training Loss: 0.013181625865399837\n",
      "Epoch 58 - Training Loss: 0.014490149915218353\n",
      "Epoch 59 - Training Loss: 0.013238952495157719\n",
      "Epoch 60 - Training Loss: 0.014764474704861641\n",
      "Epoch 61 - Training Loss: 0.014193771407008171\n",
      "Epoch 62 - Training Loss: 0.013370269909501076\n",
      "Epoch 63 - Training Loss: 0.014192570000886917\n",
      "Epoch 64 - Training Loss: 0.012999133206903934\n",
      "Epoch 65 - Training Loss: 0.014789958484470844\n",
      "Epoch 66 - Training Loss: 0.013863950036466122\n",
      "Epoch 67 - Training Loss: 0.01367052923887968\n",
      "Epoch 68 - Training Loss: 0.01471454557031393\n",
      "Epoch 69 - Training Loss: 0.013205491937696934\n",
      "Epoch 70 - Training Loss: 0.013896656222641468\n",
      "Epoch 71 - Training Loss: 0.01478813961148262\n",
      "Epoch 72 - Training Loss: 0.014209895394742489\n",
      "Epoch 73 - Training Loss: 0.015015033073723316\n",
      "Epoch 74 - Training Loss: 0.01380420196801424\n",
      "Epoch 75 - Training Loss: 0.01389481220394373\n",
      "Epoch 76 - Training Loss: 0.013339792378246784\n",
      "Epoch 77 - Training Loss: 0.013987828977406025\n",
      "Epoch 78 - Training Loss: 0.013172435574233532\n",
      "Epoch 79 - Training Loss: 0.013100801035761833\n",
      "Epoch 80 - Training Loss: 0.01348298043012619\n",
      "Epoch 81 - Training Loss: 0.013585341162979603\n",
      "Epoch 82 - Training Loss: 0.013716832734644413\n",
      "Epoch 83 - Training Loss: 0.014511022716760635\n",
      "Epoch 84 - Training Loss: 0.014608551748096943\n",
      "Epoch 85 - Training Loss: 0.014188271947205067\n",
      "Epoch 86 - Training Loss: 0.014865901321172714\n",
      "Epoch 87 - Training Loss: 0.013441719114780426\n",
      "Epoch 88 - Training Loss: 0.013146668672561646\n",
      "Epoch 89 - Training Loss: 0.014395136386156082\n",
      "Epoch 90 - Training Loss: 0.013722935691475868\n",
      "Epoch 91 - Training Loss: 0.014339038170874119\n",
      "Epoch 92 - Training Loss: 0.013217885978519917\n",
      "Epoch 93 - Training Loss: 0.013542713597416878\n",
      "Epoch 94 - Training Loss: 0.013473022729158401\n",
      "Epoch 95 - Training Loss: 0.014995105564594269\n",
      "Epoch 96 - Training Loss: 0.01418917067348957\n",
      "Epoch 97 - Training Loss: 0.013908974826335907\n",
      "Epoch 98 - Training Loss: 0.015905052423477173\n",
      "Epoch 99 - Training Loss: 0.0144268199801445\n",
      "Epoch 100 - Training Loss: 0.014379641972482204\n",
      "Epoch 1 - Training Loss: 0.013046115636825562\n",
      "Epoch 2 - Training Loss: 0.01471581868827343\n",
      "Epoch 3 - Training Loss: 0.013339816592633724\n",
      "Epoch 4 - Training Loss: 0.014150692149996758\n",
      "Epoch 5 - Training Loss: 0.015250662341713905\n",
      "Epoch 6 - Training Loss: 0.014700892381370068\n",
      "Epoch 7 - Training Loss: 0.013742288574576378\n",
      "Epoch 8 - Training Loss: 0.013419555500149727\n",
      "Epoch 9 - Training Loss: 0.013677910901606083\n",
      "Epoch 10 - Training Loss: 0.013728788122534752\n",
      "Epoch 11 - Training Loss: 0.013853839598596096\n",
      "Epoch 12 - Training Loss: 0.013303002342581749\n",
      "Epoch 13 - Training Loss: 0.013316587544977665\n",
      "Epoch 14 - Training Loss: 0.013910803012549877\n",
      "Epoch 15 - Training Loss: 0.01523901242762804\n",
      "Epoch 16 - Training Loss: 0.015092713758349419\n",
      "Epoch 17 - Training Loss: 0.013278675265610218\n",
      "Epoch 18 - Training Loss: 0.013248012401163578\n",
      "Epoch 19 - Training Loss: 0.013074610382318497\n",
      "Epoch 20 - Training Loss: 0.014818561263382435\n",
      "Epoch 21 - Training Loss: 0.013648745603859425\n",
      "Epoch 22 - Training Loss: 0.013055971823632717\n",
      "Epoch 23 - Training Loss: 0.012817946262657642\n",
      "Epoch 24 - Training Loss: 0.013103661127388477\n",
      "Epoch 25 - Training Loss: 0.013126451522111893\n",
      "Epoch 26 - Training Loss: 0.013289892114698887\n",
      "Epoch 27 - Training Loss: 0.013697312213480473\n",
      "Epoch 28 - Training Loss: 0.014773750677704811\n",
      "Epoch 29 - Training Loss: 0.01269123051315546\n",
      "Epoch 30 - Training Loss: 0.013571002520620823\n",
      "Epoch 31 - Training Loss: 0.013858458958566189\n",
      "Epoch 32 - Training Loss: 0.01486145704984665\n",
      "Epoch 33 - Training Loss: 0.014517239294946194\n",
      "Epoch 34 - Training Loss: 0.013931747525930405\n",
      "Epoch 35 - Training Loss: 0.012882879003882408\n",
      "Epoch 36 - Training Loss: 0.013777270913124084\n",
      "Epoch 37 - Training Loss: 0.014524639584124088\n",
      "Epoch 38 - Training Loss: 0.01311278436332941\n",
      "Epoch 39 - Training Loss: 0.013769016601145267\n",
      "Epoch 40 - Training Loss: 0.014151633717119694\n",
      "Epoch 41 - Training Loss: 0.013944189064204693\n",
      "Epoch 42 - Training Loss: 0.013252142816781998\n",
      "Epoch 43 - Training Loss: 0.01398280169814825\n",
      "Epoch 44 - Training Loss: 0.015313268639147282\n",
      "Epoch 45 - Training Loss: 0.014966549351811409\n",
      "Epoch 46 - Training Loss: 0.013535532169044018\n",
      "Epoch 47 - Training Loss: 0.014448393136262894\n",
      "Epoch 48 - Training Loss: 0.014195389114320278\n",
      "Epoch 49 - Training Loss: 0.015368030406534672\n",
      "Epoch 50 - Training Loss: 0.012778298929333687\n",
      "Epoch 51 - Training Loss: 0.014466047286987305\n",
      "Epoch 52 - Training Loss: 0.014626882039010525\n",
      "Epoch 53 - Training Loss: 0.013983868062496185\n",
      "Epoch 54 - Training Loss: 0.01402083970606327\n",
      "Epoch 55 - Training Loss: 0.013471407815814018\n",
      "Epoch 56 - Training Loss: 0.013940583914518356\n",
      "Epoch 57 - Training Loss: 0.015134316869080067\n",
      "Epoch 58 - Training Loss: 0.013507038354873657\n",
      "Epoch 59 - Training Loss: 0.01476603839546442\n",
      "Epoch 60 - Training Loss: 0.013666522689163685\n",
      "early stopping on epoch: 61\n",
      "Epoch 1 - Training Loss: 0.014295549131929874\n",
      "Epoch 2 - Training Loss: 0.013385849073529243\n",
      "Epoch 3 - Training Loss: 0.013743248768150806\n",
      "Epoch 4 - Training Loss: 0.013822989538311958\n",
      "Epoch 5 - Training Loss: 0.014094279147684574\n",
      "Epoch 6 - Training Loss: 0.014794725924730301\n",
      "Epoch 7 - Training Loss: 0.013286619447171688\n",
      "Epoch 8 - Training Loss: 0.013859250582754612\n",
      "Epoch 9 - Training Loss: 0.014371383935213089\n",
      "Epoch 10 - Training Loss: 0.014303257688879967\n",
      "Epoch 11 - Training Loss: 0.014304532669484615\n",
      "Epoch 12 - Training Loss: 0.013701708987355232\n",
      "Epoch 13 - Training Loss: 0.01353603508323431\n",
      "Epoch 14 - Training Loss: 0.013773579150438309\n",
      "Epoch 15 - Training Loss: 0.014269606210291386\n",
      "Epoch 16 - Training Loss: 0.01429130882024765\n",
      "Epoch 17 - Training Loss: 0.013190614990890026\n",
      "Epoch 18 - Training Loss: 0.013985979370772839\n",
      "Epoch 19 - Training Loss: 0.014632047154009342\n",
      "Epoch 20 - Training Loss: 0.015229113399982452\n",
      "Epoch 21 - Training Loss: 0.014218767173588276\n",
      "Epoch 22 - Training Loss: 0.012144798412919044\n",
      "Epoch 23 - Training Loss: 0.014024876989424229\n",
      "Epoch 24 - Training Loss: 0.014161758124828339\n",
      "Epoch 25 - Training Loss: 0.012870176695287228\n",
      "Epoch 26 - Training Loss: 0.015652259811758995\n",
      "Epoch 27 - Training Loss: 0.0139659084379673\n",
      "Epoch 28 - Training Loss: 0.014181714504957199\n",
      "Epoch 29 - Training Loss: 0.013568543829023838\n",
      "Epoch 30 - Training Loss: 0.015121959149837494\n",
      "Epoch 31 - Training Loss: 0.012953604571521282\n",
      "Epoch 32 - Training Loss: 0.013361111283302307\n",
      "Epoch 33 - Training Loss: 0.014857827685773373\n",
      "Epoch 34 - Training Loss: 0.013537646271288395\n",
      "Epoch 35 - Training Loss: 0.012597433291375637\n",
      "Epoch 36 - Training Loss: 0.01356030348688364\n",
      "Epoch 37 - Training Loss: 0.013592667877674103\n",
      "Epoch 38 - Training Loss: 0.013729986734688282\n",
      "Epoch 39 - Training Loss: 0.013419908471405506\n",
      "Epoch 40 - Training Loss: 0.013542469590902328\n",
      "Epoch 41 - Training Loss: 0.01495288498699665\n",
      "Epoch 42 - Training Loss: 0.014316355809569359\n",
      "Epoch 43 - Training Loss: 0.013895872049033642\n",
      "Epoch 44 - Training Loss: 0.01344924047589302\n",
      "Epoch 45 - Training Loss: 0.01418218482285738\n",
      "Epoch 46 - Training Loss: 0.013597437180578709\n",
      "Epoch 47 - Training Loss: 0.014149565249681473\n",
      "Epoch 48 - Training Loss: 0.014039935544133186\n",
      "Epoch 49 - Training Loss: 0.01400855090469122\n",
      "Epoch 50 - Training Loss: 0.013261893764138222\n",
      "Epoch 51 - Training Loss: 0.012869732454419136\n",
      "Epoch 52 - Training Loss: 0.013634850271046162\n",
      "Epoch 53 - Training Loss: 0.015141665004193783\n",
      "Epoch 54 - Training Loss: 0.014714473858475685\n",
      "Epoch 55 - Training Loss: 0.014340011402964592\n",
      "Epoch 56 - Training Loss: 0.013851871713995934\n",
      "Epoch 57 - Training Loss: 0.014164138585329056\n",
      "Epoch 58 - Training Loss: 0.01374734565615654\n",
      "Epoch 59 - Training Loss: 0.013872546143829823\n",
      "Epoch 60 - Training Loss: 0.012999708764255047\n",
      "Epoch 61 - Training Loss: 0.013783338479697704\n",
      "Epoch 62 - Training Loss: 0.013895212672650814\n",
      "Epoch 63 - Training Loss: 0.013900530524551868\n",
      "Epoch 64 - Training Loss: 0.012660926207900047\n",
      "Epoch 65 - Training Loss: 0.014843233861029148\n",
      "Epoch 66 - Training Loss: 0.012724017724394798\n",
      "Epoch 67 - Training Loss: 0.015086617320775986\n",
      "Epoch 68 - Training Loss: 0.014525937847793102\n",
      "Epoch 69 - Training Loss: 0.013757742941379547\n",
      "Epoch 70 - Training Loss: 0.01585039682686329\n",
      "Epoch 71 - Training Loss: 0.01436604093760252\n",
      "Epoch 72 - Training Loss: 0.014373875223100185\n",
      "Epoch 73 - Training Loss: 0.013806103728711605\n",
      "Epoch 74 - Training Loss: 0.013887262903153896\n",
      "Epoch 75 - Training Loss: 0.014834891073405743\n",
      "Epoch 76 - Training Loss: 0.013948335312306881\n",
      "Epoch 77 - Training Loss: 0.013788376934826374\n",
      "Epoch 78 - Training Loss: 0.014728288166224957\n",
      "Epoch 79 - Training Loss: 0.013868425972759724\n",
      "Epoch 80 - Training Loss: 0.01325011346489191\n",
      "Epoch 81 - Training Loss: 0.01373822521418333\n",
      "Epoch 82 - Training Loss: 0.015047842636704445\n",
      "Epoch 83 - Training Loss: 0.01381975319236517\n",
      "Epoch 84 - Training Loss: 0.013392684049904346\n",
      "Epoch 85 - Training Loss: 0.014066237024962902\n",
      "Epoch 86 - Training Loss: 0.014682044275105\n",
      "Epoch 87 - Training Loss: 0.013565048575401306\n",
      "Epoch 88 - Training Loss: 0.01427778322249651\n",
      "Epoch 89 - Training Loss: 0.0143427150323987\n",
      "Epoch 90 - Training Loss: 0.01362766046077013\n",
      "Epoch 91 - Training Loss: 0.014086398296058178\n",
      "Epoch 92 - Training Loss: 0.015358014032244682\n",
      "Epoch 93 - Training Loss: 0.014217752031981945\n",
      "Epoch 94 - Training Loss: 0.014162297360599041\n",
      "Epoch 95 - Training Loss: 0.01319601945579052\n",
      "Epoch 96 - Training Loss: 0.01470458135008812\n",
      "Epoch 97 - Training Loss: 0.014392496086657047\n",
      "Epoch 98 - Training Loss: 0.013786399737000465\n",
      "Epoch 99 - Training Loss: 0.013515160419046879\n",
      "Epoch 100 - Training Loss: 0.01416418980807066\n",
      "Epoch 1 - Training Loss: 0.013809122145175934\n",
      "Epoch 2 - Training Loss: 0.013842197135090828\n",
      "Epoch 3 - Training Loss: 0.01345771923661232\n",
      "Epoch 4 - Training Loss: 0.015505553223192692\n",
      "Epoch 5 - Training Loss: 0.015005037188529968\n",
      "Epoch 6 - Training Loss: 0.015588437207043171\n",
      "Epoch 7 - Training Loss: 0.013809761963784695\n",
      "Epoch 8 - Training Loss: 0.014091194607317448\n",
      "Epoch 9 - Training Loss: 0.01397384237498045\n",
      "Epoch 10 - Training Loss: 0.013346419669687748\n",
      "Epoch 11 - Training Loss: 0.013170833699405193\n",
      "Epoch 12 - Training Loss: 0.013707621954381466\n",
      "Epoch 13 - Training Loss: 0.015098013915121555\n",
      "Epoch 14 - Training Loss: 0.014671890065073967\n",
      "Epoch 15 - Training Loss: 0.013789094984531403\n",
      "Epoch 16 - Training Loss: 0.01290171593427658\n",
      "Epoch 17 - Training Loss: 0.014070478267967701\n",
      "Epoch 18 - Training Loss: 0.013613051734864712\n",
      "Epoch 19 - Training Loss: 0.013493506237864494\n",
      "Epoch 20 - Training Loss: 0.014339729212224483\n",
      "Epoch 21 - Training Loss: 0.014982197433710098\n",
      "Epoch 22 - Training Loss: 0.015049937181174755\n",
      "Epoch 23 - Training Loss: 0.012825697660446167\n",
      "Epoch 24 - Training Loss: 0.013818725012242794\n",
      "Epoch 25 - Training Loss: 0.013475172221660614\n",
      "Epoch 26 - Training Loss: 0.015397160314023495\n",
      "Epoch 27 - Training Loss: 0.015029546804726124\n",
      "Epoch 28 - Training Loss: 0.01310372818261385\n",
      "Epoch 29 - Training Loss: 0.013879254460334778\n",
      "Epoch 30 - Training Loss: 0.01357338111847639\n",
      "Epoch 31 - Training Loss: 0.013523095287382603\n",
      "Epoch 32 - Training Loss: 0.013349434360861778\n",
      "Epoch 33 - Training Loss: 0.0133502297103405\n",
      "Epoch 34 - Training Loss: 0.013346548192203045\n",
      "Epoch 35 - Training Loss: 0.01355416513979435\n",
      "Epoch 36 - Training Loss: 0.015201091766357422\n",
      "Epoch 37 - Training Loss: 0.014156834222376347\n",
      "Epoch 38 - Training Loss: 0.015455213375389576\n",
      "Epoch 39 - Training Loss: 0.014666981995105743\n",
      "Epoch 40 - Training Loss: 0.013684924691915512\n",
      "Epoch 41 - Training Loss: 0.013708235695958138\n",
      "Epoch 42 - Training Loss: 0.014368170872330666\n",
      "Epoch 43 - Training Loss: 0.013328361324965954\n",
      "Epoch 44 - Training Loss: 0.013215107843279839\n",
      "Epoch 45 - Training Loss: 0.013719117268919945\n",
      "Epoch 46 - Training Loss: 0.014322607778012753\n",
      "Epoch 47 - Training Loss: 0.015135309658944607\n",
      "Epoch 48 - Training Loss: 0.014675825834274292\n",
      "Epoch 49 - Training Loss: 0.013400832191109657\n",
      "Epoch 50 - Training Loss: 0.015842629596590996\n",
      "Epoch 51 - Training Loss: 0.013611101545393467\n",
      "Epoch 52 - Training Loss: 0.014384845271706581\n",
      "Epoch 53 - Training Loss: 0.014800703153014183\n",
      "Epoch 54 - Training Loss: 0.014041494578123093\n",
      "Epoch 55 - Training Loss: 0.013037396594882011\n",
      "Epoch 56 - Training Loss: 0.012990807183086872\n",
      "Epoch 57 - Training Loss: 0.014415532350540161\n",
      "Epoch 58 - Training Loss: 0.014465573243796825\n",
      "Epoch 59 - Training Loss: 0.015515209175646305\n",
      "Epoch 60 - Training Loss: 0.013802539557218552\n",
      "Epoch 61 - Training Loss: 0.014224794693291187\n",
      "Epoch 62 - Training Loss: 0.013568680733442307\n",
      "Epoch 63 - Training Loss: 0.013994990848004818\n",
      "Epoch 64 - Training Loss: 0.014254788868129253\n",
      "Epoch 65 - Training Loss: 0.014203760772943497\n",
      "Epoch 66 - Training Loss: 0.013086722232401371\n",
      "Epoch 67 - Training Loss: 0.01345926895737648\n",
      "Epoch 68 - Training Loss: 0.014439250342547894\n",
      "Epoch 69 - Training Loss: 0.014114952646195889\n",
      "early stopping on epoch: 70\n",
      "Epoch 1 - Training Loss: 0.013711929321289062\n",
      "Epoch 2 - Training Loss: 0.013721823692321777\n",
      "Epoch 3 - Training Loss: 0.012921085581183434\n",
      "Epoch 4 - Training Loss: 0.013503873720765114\n",
      "Epoch 5 - Training Loss: 0.01375486422330141\n",
      "Epoch 6 - Training Loss: 0.013884186744689941\n",
      "Epoch 7 - Training Loss: 0.013614115305244923\n",
      "Epoch 8 - Training Loss: 0.014726630412042141\n",
      "Epoch 9 - Training Loss: 0.014676517806947231\n",
      "Epoch 10 - Training Loss: 0.013743518851697445\n",
      "Epoch 11 - Training Loss: 0.014168587513267994\n",
      "Epoch 12 - Training Loss: 0.014089454896748066\n",
      "Epoch 13 - Training Loss: 0.012796709313988686\n",
      "Epoch 14 - Training Loss: 0.01452855858951807\n",
      "Epoch 15 - Training Loss: 0.013596822507679462\n",
      "Epoch 16 - Training Loss: 0.014619942754507065\n",
      "Epoch 17 - Training Loss: 0.013468940742313862\n",
      "Epoch 18 - Training Loss: 0.013737371191382408\n",
      "Epoch 19 - Training Loss: 0.01383887603878975\n",
      "Epoch 20 - Training Loss: 0.016207775101065636\n",
      "Epoch 21 - Training Loss: 0.014034093357622623\n",
      "Epoch 22 - Training Loss: 0.013772528618574142\n",
      "Epoch 23 - Training Loss: 0.014298347756266594\n",
      "Epoch 24 - Training Loss: 0.013787653297185898\n",
      "Epoch 25 - Training Loss: 0.013499277643859386\n",
      "Epoch 26 - Training Loss: 0.014857983216643333\n",
      "Epoch 27 - Training Loss: 0.014833826571702957\n",
      "Epoch 28 - Training Loss: 0.013857183046638966\n",
      "Epoch 29 - Training Loss: 0.012978404760360718\n",
      "Epoch 30 - Training Loss: 0.012725763954222202\n",
      "Epoch 31 - Training Loss: 0.01404658704996109\n",
      "Epoch 32 - Training Loss: 0.013263802044093609\n",
      "Epoch 33 - Training Loss: 0.013151061721146107\n",
      "Epoch 34 - Training Loss: 0.014417968690395355\n",
      "Epoch 35 - Training Loss: 0.014209344051778316\n",
      "Epoch 36 - Training Loss: 0.01338056568056345\n",
      "Epoch 37 - Training Loss: 0.013749976642429829\n",
      "Epoch 38 - Training Loss: 0.013814544305205345\n",
      "Epoch 39 - Training Loss: 0.014190913178026676\n",
      "Epoch 40 - Training Loss: 0.012557079084217548\n",
      "Epoch 41 - Training Loss: 0.013587252236902714\n",
      "Epoch 42 - Training Loss: 0.01483743917196989\n",
      "Epoch 43 - Training Loss: 0.013920417055487633\n",
      "Epoch 44 - Training Loss: 0.015103151090443134\n",
      "Epoch 45 - Training Loss: 0.015161299146711826\n",
      "Epoch 46 - Training Loss: 0.01384280901402235\n",
      "Epoch 47 - Training Loss: 0.015022681094706059\n",
      "Epoch 48 - Training Loss: 0.012874012812972069\n",
      "Epoch 49 - Training Loss: 0.015117732807993889\n",
      "Epoch 50 - Training Loss: 0.013327033258974552\n",
      "Epoch 51 - Training Loss: 0.014530070126056671\n",
      "Epoch 52 - Training Loss: 0.013332705944776535\n",
      "Epoch 53 - Training Loss: 0.01375765074044466\n",
      "Epoch 54 - Training Loss: 0.013700183480978012\n",
      "Epoch 55 - Training Loss: 0.01313113421201706\n",
      "Epoch 56 - Training Loss: 0.01408956665545702\n",
      "Epoch 57 - Training Loss: 0.013716968707740307\n",
      "Epoch 58 - Training Loss: 0.014675220474600792\n",
      "Epoch 59 - Training Loss: 0.014050127938389778\n",
      "Epoch 60 - Training Loss: 0.014541581273078918\n",
      "Epoch 61 - Training Loss: 0.014752976596355438\n",
      "Epoch 62 - Training Loss: 0.014072045683860779\n",
      "Epoch 63 - Training Loss: 0.014152816496789455\n",
      "Epoch 64 - Training Loss: 0.014017926529049873\n",
      "Epoch 65 - Training Loss: 0.01408313773572445\n",
      "Epoch 66 - Training Loss: 0.013988886028528214\n",
      "Epoch 67 - Training Loss: 0.01308423187583685\n",
      "Epoch 68 - Training Loss: 0.014237962663173676\n",
      "Epoch 69 - Training Loss: 0.013271036557853222\n",
      "Epoch 70 - Training Loss: 0.014200368896126747\n",
      "Epoch 71 - Training Loss: 0.01342811156064272\n",
      "Epoch 72 - Training Loss: 0.013675936497747898\n",
      "Epoch 73 - Training Loss: 0.014874827116727829\n",
      "Epoch 74 - Training Loss: 0.013378839008510113\n",
      "Epoch 75 - Training Loss: 0.013538282364606857\n",
      "Epoch 76 - Training Loss: 0.01425650343298912\n",
      "Epoch 77 - Training Loss: 0.014099448919296265\n",
      "early stopping on epoch: 78\n",
      "Epoch 1 - Training Loss: 0.014110453426837921\n",
      "Epoch 2 - Training Loss: 0.014479022473096848\n",
      "Epoch 3 - Training Loss: 0.014465529471635818\n",
      "Epoch 4 - Training Loss: 0.014291220344603062\n",
      "Epoch 5 - Training Loss: 0.014787490479648113\n",
      "Epoch 6 - Training Loss: 0.013363742269575596\n",
      "Epoch 7 - Training Loss: 0.014227868057787418\n",
      "Epoch 8 - Training Loss: 0.013411607593297958\n",
      "Epoch 9 - Training Loss: 0.01334947720170021\n",
      "Epoch 10 - Training Loss: 0.015215449035167694\n",
      "Epoch 11 - Training Loss: 0.014007198624312878\n",
      "Epoch 12 - Training Loss: 0.014467056840658188\n",
      "Epoch 13 - Training Loss: 0.014344594441354275\n",
      "Epoch 14 - Training Loss: 0.013976042158901691\n",
      "Epoch 15 - Training Loss: 0.01322099193930626\n",
      "Epoch 16 - Training Loss: 0.014163999818265438\n",
      "Epoch 17 - Training Loss: 0.0141146807000041\n",
      "Epoch 18 - Training Loss: 0.014740921556949615\n",
      "Epoch 19 - Training Loss: 0.013802211731672287\n",
      "Epoch 20 - Training Loss: 0.014825151301920414\n",
      "early stopping on epoch: 21\n",
      "Epoch 1 - Training Loss: 0.014117845334112644\n",
      "Epoch 2 - Training Loss: 0.014426183886826038\n",
      "Epoch 3 - Training Loss: 0.013623407110571861\n",
      "Epoch 4 - Training Loss: 0.01449616625905037\n",
      "Epoch 5 - Training Loss: 0.012875264510512352\n",
      "Epoch 6 - Training Loss: 0.013736440800130367\n",
      "Epoch 7 - Training Loss: 0.014480985701084137\n",
      "Epoch 8 - Training Loss: 0.013704014010727406\n",
      "Epoch 9 - Training Loss: 0.014469707384705544\n",
      "Epoch 10 - Training Loss: 0.015826515853405\n",
      "Epoch 11 - Training Loss: 0.013776158913969994\n",
      "Epoch 12 - Training Loss: 0.014328854158520699\n",
      "Epoch 13 - Training Loss: 0.015029377304017544\n",
      "Epoch 14 - Training Loss: 0.014150746166706085\n",
      "Epoch 15 - Training Loss: 0.013697515241801739\n",
      "Epoch 16 - Training Loss: 0.013653729110956192\n",
      "Epoch 17 - Training Loss: 0.01434236764907837\n",
      "Epoch 18 - Training Loss: 0.013567970134317875\n",
      "Epoch 19 - Training Loss: 0.01440016645938158\n",
      "Epoch 20 - Training Loss: 0.01394905336201191\n",
      "Epoch 21 - Training Loss: 0.014206639491021633\n",
      "Epoch 22 - Training Loss: 0.014064297080039978\n",
      "Epoch 23 - Training Loss: 0.014331919141113758\n",
      "Epoch 24 - Training Loss: 0.0145603958517313\n",
      "early stopping on epoch: 25\n",
      "Epoch 1 - Training Loss: 0.01433014776557684\n",
      "Epoch 2 - Training Loss: 0.013386331498622894\n",
      "Epoch 3 - Training Loss: 0.015003945678472519\n",
      "Epoch 4 - Training Loss: 0.014077072031795979\n",
      "Epoch 5 - Training Loss: 0.014830272644758224\n",
      "Epoch 6 - Training Loss: 0.014986654743552208\n",
      "Epoch 7 - Training Loss: 0.014298120513558388\n",
      "Epoch 8 - Training Loss: 0.014899847097694874\n",
      "Epoch 9 - Training Loss: 0.014599047601222992\n",
      "Epoch 10 - Training Loss: 0.0157100111246109\n",
      "Epoch 11 - Training Loss: 0.015013135969638824\n",
      "Epoch 12 - Training Loss: 0.013804979622364044\n",
      "Epoch 13 - Training Loss: 0.014763941988348961\n",
      "Epoch 14 - Training Loss: 0.01477082073688507\n",
      "Epoch 15 - Training Loss: 0.014016631059348583\n",
      "Epoch 16 - Training Loss: 0.014956126920878887\n",
      "Epoch 17 - Training Loss: 0.014091637916862965\n",
      "Epoch 18 - Training Loss: 0.013353469781577587\n",
      "Epoch 19 - Training Loss: 0.014051206409931183\n",
      "Epoch 20 - Training Loss: 0.014013313688337803\n",
      "Epoch 21 - Training Loss: 0.015175046399235725\n",
      "Epoch 22 - Training Loss: 0.013871517032384872\n",
      "Epoch 23 - Training Loss: 0.014580558985471725\n",
      "Epoch 24 - Training Loss: 0.01596282422542572\n",
      "Epoch 25 - Training Loss: 0.014171358197927475\n",
      "Epoch 26 - Training Loss: 0.015277289785444736\n",
      "Epoch 27 - Training Loss: 0.01590890623629093\n",
      "Epoch 28 - Training Loss: 0.014216363430023193\n",
      "Epoch 29 - Training Loss: 0.015294295735657215\n",
      "Epoch 30 - Training Loss: 0.01421303953975439\n",
      "Epoch 31 - Training Loss: 0.01325241755694151\n",
      "Epoch 32 - Training Loss: 0.015301129780709743\n",
      "Epoch 33 - Training Loss: 0.014106886461377144\n",
      "Epoch 34 - Training Loss: 0.013922990299761295\n",
      "Epoch 35 - Training Loss: 0.014751044102013111\n",
      "Epoch 36 - Training Loss: 0.014279459603130817\n",
      "Epoch 37 - Training Loss: 0.015293712727725506\n",
      "Epoch 38 - Training Loss: 0.015201066620647907\n",
      "Epoch 39 - Training Loss: 0.016023432835936546\n",
      "Epoch 40 - Training Loss: 0.014066672883927822\n",
      "Epoch 41 - Training Loss: 0.015091628767549992\n",
      "Epoch 42 - Training Loss: 0.014387600123882294\n",
      "Epoch 43 - Training Loss: 0.014807666651904583\n",
      "Epoch 44 - Training Loss: 0.01362137496471405\n",
      "Epoch 45 - Training Loss: 0.014439905062317848\n",
      "Epoch 46 - Training Loss: 0.014941602945327759\n",
      "Epoch 47 - Training Loss: 0.01511787623167038\n",
      "Epoch 48 - Training Loss: 0.014497973956167698\n",
      "Epoch 49 - Training Loss: 0.013302505016326904\n",
      "Epoch 50 - Training Loss: 0.01510878186672926\n",
      "Epoch 51 - Training Loss: 0.014107725583016872\n",
      "Epoch 52 - Training Loss: 0.013481536880135536\n",
      "Epoch 53 - Training Loss: 0.01382538489997387\n",
      "Epoch 54 - Training Loss: 0.014956606552004814\n",
      "Epoch 55 - Training Loss: 0.012932068668305874\n",
      "Epoch 56 - Training Loss: 0.015094197355210781\n",
      "Epoch 57 - Training Loss: 0.01577812060713768\n",
      "Epoch 58 - Training Loss: 0.014173964969813824\n",
      "Epoch 59 - Training Loss: 0.014665006659924984\n",
      "Epoch 60 - Training Loss: 0.013707747682929039\n",
      "Epoch 61 - Training Loss: 0.014966297894716263\n",
      "Epoch 62 - Training Loss: 0.013893361203372478\n",
      "Epoch 63 - Training Loss: 0.014204949140548706\n",
      "Epoch 64 - Training Loss: 0.01474553532898426\n",
      "Epoch 65 - Training Loss: 0.014522881247103214\n",
      "Epoch 66 - Training Loss: 0.015226799063384533\n",
      "Epoch 67 - Training Loss: 0.014436611905694008\n",
      "Epoch 68 - Training Loss: 0.014057251624763012\n",
      "Epoch 69 - Training Loss: 0.014050102792680264\n",
      "Epoch 70 - Training Loss: 0.015319488011300564\n",
      "Epoch 71 - Training Loss: 0.014835835434496403\n",
      "Epoch 72 - Training Loss: 0.014214593917131424\n",
      "Epoch 73 - Training Loss: 0.013722360134124756\n",
      "Epoch 74 - Training Loss: 0.013609474524855614\n",
      "Epoch 75 - Training Loss: 0.015828561037778854\n",
      "Epoch 76 - Training Loss: 0.013989778235554695\n",
      "Epoch 77 - Training Loss: 0.01396955456584692\n",
      "Epoch 78 - Training Loss: 0.014666675589978695\n",
      "Epoch 79 - Training Loss: 0.015364503487944603\n",
      "Epoch 80 - Training Loss: 0.014569330960512161\n",
      "Epoch 81 - Training Loss: 0.014331675134599209\n",
      "Epoch 82 - Training Loss: 0.015300663188099861\n",
      "Epoch 83 - Training Loss: 0.013695526868104935\n",
      "Epoch 84 - Training Loss: 0.013936390168964863\n",
      "Epoch 85 - Training Loss: 0.014349118806421757\n",
      "Epoch 86 - Training Loss: 0.01400105468928814\n",
      "Epoch 87 - Training Loss: 0.015998542308807373\n",
      "Epoch 88 - Training Loss: 0.015244457870721817\n",
      "Epoch 89 - Training Loss: 0.014565947465598583\n",
      "Epoch 90 - Training Loss: 0.013803638517856598\n",
      "Epoch 91 - Training Loss: 0.014410469681024551\n",
      "Epoch 92 - Training Loss: 0.014083544723689556\n",
      "Epoch 93 - Training Loss: 0.01584765501320362\n",
      "Epoch 94 - Training Loss: 0.015206686221063137\n",
      "Epoch 95 - Training Loss: 0.012905081734061241\n",
      "Epoch 96 - Training Loss: 0.014597726985812187\n",
      "Epoch 97 - Training Loss: 0.013488800264894962\n",
      "Epoch 98 - Training Loss: 0.013364151120185852\n",
      "Epoch 99 - Training Loss: 0.014134123921394348\n",
      "Epoch 100 - Training Loss: 0.014346659183502197\n",
      "Epoch 1 - Training Loss: 0.01322798803448677\n",
      "Epoch 2 - Training Loss: 0.014756922610104084\n",
      "Epoch 3 - Training Loss: 0.014900892972946167\n",
      "Epoch 4 - Training Loss: 0.014727387577295303\n",
      "Epoch 5 - Training Loss: 0.015145177021622658\n",
      "Epoch 6 - Training Loss: 0.015519175678491592\n",
      "Epoch 7 - Training Loss: 0.014802437275648117\n",
      "Epoch 8 - Training Loss: 0.014146782457828522\n",
      "Epoch 9 - Training Loss: 0.01543317548930645\n",
      "Epoch 10 - Training Loss: 0.014230645261704922\n",
      "Epoch 11 - Training Loss: 0.014277529902756214\n",
      "early stopping on epoch: 12\n",
      "Epoch 1 - Training Loss: 0.01432046853005886\n",
      "Epoch 2 - Training Loss: 0.015078897587954998\n",
      "Epoch 3 - Training Loss: 0.013824611902236938\n",
      "Epoch 4 - Training Loss: 0.015179060399532318\n",
      "Epoch 5 - Training Loss: 0.014176426455378532\n",
      "Epoch 6 - Training Loss: 0.013697735965251923\n",
      "Epoch 7 - Training Loss: 0.01523016020655632\n",
      "Epoch 8 - Training Loss: 0.01641974039375782\n",
      "Epoch 9 - Training Loss: 0.015397446230053902\n",
      "Epoch 10 - Training Loss: 0.014272158965468407\n",
      "Epoch 11 - Training Loss: 0.015574581921100616\n",
      "Epoch 12 - Training Loss: 0.015535684302449226\n",
      "Epoch 13 - Training Loss: 0.014665699563920498\n",
      "Epoch 14 - Training Loss: 0.01583143323659897\n",
      "Epoch 15 - Training Loss: 0.013885456137359142\n",
      "Epoch 16 - Training Loss: 0.013494239188730717\n",
      "Epoch 17 - Training Loss: 0.01408933475613594\n",
      "Epoch 18 - Training Loss: 0.016069753095507622\n",
      "Epoch 19 - Training Loss: 0.015344439074397087\n",
      "Epoch 20 - Training Loss: 0.015089238993823528\n",
      "Epoch 21 - Training Loss: 0.01651880517601967\n",
      "Epoch 22 - Training Loss: 0.015859659761190414\n",
      "Epoch 23 - Training Loss: 0.015210635960102081\n",
      "Epoch 24 - Training Loss: 0.015010778792202473\n",
      "Epoch 25 - Training Loss: 0.01431993581354618\n",
      "Epoch 26 - Training Loss: 0.01564982533454895\n",
      "Epoch 27 - Training Loss: 0.015500678680837154\n",
      "Epoch 28 - Training Loss: 0.01433428656309843\n",
      "Epoch 29 - Training Loss: 0.01555097009986639\n",
      "Epoch 30 - Training Loss: 0.014248973689973354\n",
      "Epoch 31 - Training Loss: 0.01512601412832737\n",
      "Epoch 32 - Training Loss: 0.016325566917657852\n",
      "Epoch 33 - Training Loss: 0.015066592954099178\n",
      "Epoch 34 - Training Loss: 0.014189304783940315\n",
      "Epoch 35 - Training Loss: 0.015200975351035595\n",
      "Epoch 36 - Training Loss: 0.014955908060073853\n",
      "Epoch 37 - Training Loss: 0.015278988517820835\n",
      "Epoch 38 - Training Loss: 0.014348265714943409\n",
      "Epoch 39 - Training Loss: 0.01595706306397915\n",
      "Epoch 40 - Training Loss: 0.016548769548535347\n",
      "Epoch 41 - Training Loss: 0.015141875483095646\n",
      "Epoch 42 - Training Loss: 0.015088844113051891\n",
      "Epoch 43 - Training Loss: 0.015475373715162277\n",
      "Epoch 44 - Training Loss: 0.015381205826997757\n",
      "Epoch 45 - Training Loss: 0.015398947522044182\n",
      "Epoch 46 - Training Loss: 0.016020754352211952\n",
      "Epoch 47 - Training Loss: 0.015439016744494438\n",
      "Epoch 48 - Training Loss: 0.015067609027028084\n",
      "Epoch 49 - Training Loss: 0.014747128821909428\n",
      "Epoch 50 - Training Loss: 0.01574808731675148\n",
      "Epoch 51 - Training Loss: 0.013879979960620403\n",
      "Epoch 52 - Training Loss: 0.014864805154502392\n",
      "Epoch 53 - Training Loss: 0.015046212822198868\n",
      "Epoch 54 - Training Loss: 0.013820062391459942\n",
      "Epoch 55 - Training Loss: 0.015121528878808022\n",
      "Epoch 56 - Training Loss: 0.014563747681677341\n",
      "Epoch 57 - Training Loss: 0.016338491812348366\n",
      "Epoch 58 - Training Loss: 0.014665358699858189\n",
      "Epoch 59 - Training Loss: 0.014741793274879456\n",
      "Epoch 60 - Training Loss: 0.014859925955533981\n",
      "Epoch 61 - Training Loss: 0.014738914556801319\n",
      "Epoch 62 - Training Loss: 0.014833434484899044\n",
      "Epoch 63 - Training Loss: 0.015445469878613949\n",
      "Epoch 64 - Training Loss: 0.013948210515081882\n",
      "Epoch 65 - Training Loss: 0.013605891726911068\n",
      "Epoch 66 - Training Loss: 0.015954514965415\n",
      "Epoch 67 - Training Loss: 0.015246773138642311\n",
      "Epoch 68 - Training Loss: 0.01548709161579609\n",
      "Epoch 69 - Training Loss: 0.014499150216579437\n",
      "Epoch 70 - Training Loss: 0.015039573423564434\n",
      "Epoch 71 - Training Loss: 0.014954344369471073\n",
      "Epoch 72 - Training Loss: 0.016189558431506157\n",
      "Epoch 73 - Training Loss: 0.01335174310952425\n",
      "Epoch 74 - Training Loss: 0.016412213444709778\n",
      "Epoch 75 - Training Loss: 0.01511981338262558\n",
      "Epoch 76 - Training Loss: 0.015292195603251457\n",
      "Epoch 77 - Training Loss: 0.015025189146399498\n",
      "Epoch 78 - Training Loss: 0.014545912854373455\n",
      "Epoch 79 - Training Loss: 0.013953580521047115\n",
      "Epoch 80 - Training Loss: 0.014741094782948494\n",
      "Epoch 81 - Training Loss: 0.01450867298990488\n",
      "Epoch 82 - Training Loss: 0.015312082134187222\n",
      "Epoch 83 - Training Loss: 0.01554802991449833\n",
      "Epoch 84 - Training Loss: 0.015678342431783676\n",
      "Epoch 85 - Training Loss: 0.013533784076571465\n",
      "Epoch 86 - Training Loss: 0.01453515887260437\n",
      "Epoch 87 - Training Loss: 0.01430733036249876\n",
      "Epoch 88 - Training Loss: 0.015270190313458443\n",
      "Epoch 89 - Training Loss: 0.01510388869792223\n",
      "Epoch 90 - Training Loss: 0.015888124704360962\n",
      "Epoch 91 - Training Loss: 0.014543525874614716\n",
      "Epoch 92 - Training Loss: 0.01570156216621399\n",
      "Epoch 93 - Training Loss: 0.015610930509865284\n",
      "Epoch 94 - Training Loss: 0.014074902050197124\n",
      "Epoch 95 - Training Loss: 0.013840725645422935\n",
      "Epoch 96 - Training Loss: 0.015193966217339039\n",
      "Epoch 97 - Training Loss: 0.014615882188081741\n",
      "Epoch 98 - Training Loss: 0.015308680012822151\n",
      "Epoch 99 - Training Loss: 0.01492837443947792\n",
      "Epoch 100 - Training Loss: 0.015099111013114452\n",
      "Epoch 1 - Training Loss: 0.015935003757476807\n",
      "Epoch 2 - Training Loss: 0.014369956217706203\n",
      "Epoch 3 - Training Loss: 0.015515783801674843\n",
      "Epoch 4 - Training Loss: 0.014182246290147305\n",
      "Epoch 5 - Training Loss: 0.015270868316292763\n",
      "Epoch 6 - Training Loss: 0.014600444585084915\n",
      "Epoch 7 - Training Loss: 0.01415200624614954\n",
      "Epoch 8 - Training Loss: 0.013027120381593704\n",
      "Epoch 9 - Training Loss: 0.014311816543340683\n",
      "Epoch 10 - Training Loss: 0.014756965450942516\n",
      "Epoch 11 - Training Loss: 0.015481957234442234\n",
      "Epoch 12 - Training Loss: 0.014528878033161163\n",
      "Epoch 13 - Training Loss: 0.014320801012217999\n",
      "Epoch 14 - Training Loss: 0.014652651734650135\n",
      "Epoch 15 - Training Loss: 0.01579173654317856\n",
      "Epoch 16 - Training Loss: 0.013923176564276218\n",
      "Epoch 17 - Training Loss: 0.01429422851651907\n",
      "Epoch 18 - Training Loss: 0.016509804874658585\n",
      "Epoch 19 - Training Loss: 0.013927672989666462\n",
      "Epoch 20 - Training Loss: 0.014861778356134892\n",
      "Epoch 21 - Training Loss: 0.013849231414496899\n",
      "Epoch 22 - Training Loss: 0.016222409904003143\n",
      "Epoch 23 - Training Loss: 0.014087068848311901\n",
      "Epoch 24 - Training Loss: 0.0161269661039114\n",
      "Epoch 25 - Training Loss: 0.01596425659954548\n",
      "Epoch 26 - Training Loss: 0.016067970544099808\n",
      "Epoch 27 - Training Loss: 0.015446052886545658\n",
      "Epoch 28 - Training Loss: 0.014306108467280865\n",
      "Epoch 29 - Training Loss: 0.014435826800763607\n",
      "Epoch 30 - Training Loss: 0.01638062857091427\n",
      "Epoch 31 - Training Loss: 0.01496969535946846\n",
      "Epoch 32 - Training Loss: 0.014873574487864971\n",
      "Epoch 33 - Training Loss: 0.015051259659230709\n",
      "Epoch 34 - Training Loss: 0.016168514266610146\n",
      "Epoch 35 - Training Loss: 0.015536477789282799\n",
      "Epoch 36 - Training Loss: 0.01368336658924818\n",
      "Epoch 37 - Training Loss: 0.015393213368952274\n",
      "Epoch 38 - Training Loss: 0.015603228472173214\n",
      "Epoch 39 - Training Loss: 0.015267949551343918\n",
      "Epoch 40 - Training Loss: 0.015576706267893314\n",
      "Epoch 41 - Training Loss: 0.014985374175012112\n",
      "Epoch 42 - Training Loss: 0.014545676298439503\n",
      "Epoch 43 - Training Loss: 0.0147517379373312\n",
      "Epoch 44 - Training Loss: 0.015241428278386593\n",
      "Epoch 45 - Training Loss: 0.016222799196839333\n",
      "Epoch 46 - Training Loss: 0.0143955172970891\n",
      "early stopping on epoch: 47\n",
      "Epoch 1 - Training Loss: 0.015642786398530006\n",
      "Epoch 2 - Training Loss: 0.014736724086105824\n",
      "Epoch 3 - Training Loss: 0.014696131460368633\n",
      "Epoch 4 - Training Loss: 0.016622338443994522\n",
      "Epoch 5 - Training Loss: 0.01549409981817007\n",
      "Epoch 6 - Training Loss: 0.017068911343812943\n",
      "Epoch 7 - Training Loss: 0.014309634454548359\n",
      "Epoch 8 - Training Loss: 0.015423314645886421\n",
      "Epoch 9 - Training Loss: 0.01477165799587965\n",
      "Epoch 10 - Training Loss: 0.015621762722730637\n",
      "Epoch 11 - Training Loss: 0.014869075268507004\n",
      "Epoch 12 - Training Loss: 0.014606534503400326\n",
      "Epoch 13 - Training Loss: 0.01452626846730709\n",
      "Epoch 14 - Training Loss: 0.01622747629880905\n",
      "Epoch 15 - Training Loss: 0.0177090335637331\n",
      "Epoch 16 - Training Loss: 0.014856139197945595\n",
      "Epoch 17 - Training Loss: 0.0169002003967762\n",
      "Epoch 18 - Training Loss: 0.01619587279856205\n",
      "Epoch 19 - Training Loss: 0.015084812417626381\n",
      "Epoch 20 - Training Loss: 0.014882599003612995\n",
      "Epoch 21 - Training Loss: 0.014706275425851345\n",
      "Epoch 22 - Training Loss: 0.015521337278187275\n",
      "Epoch 23 - Training Loss: 0.016027143225073814\n",
      "Epoch 24 - Training Loss: 0.015120675787329674\n",
      "Epoch 25 - Training Loss: 0.01380037423223257\n",
      "Epoch 26 - Training Loss: 0.01527494192123413\n",
      "Epoch 27 - Training Loss: 0.014337620697915554\n",
      "Epoch 28 - Training Loss: 0.015669306740164757\n",
      "Epoch 29 - Training Loss: 0.015712911263108253\n",
      "Epoch 30 - Training Loss: 0.015858270227909088\n",
      "Epoch 31 - Training Loss: 0.014222824014723301\n",
      "Epoch 32 - Training Loss: 0.01563708670437336\n",
      "Epoch 33 - Training Loss: 0.014016046188771725\n",
      "Epoch 34 - Training Loss: 0.018368512392044067\n",
      "Epoch 35 - Training Loss: 0.015150985680520535\n",
      "Epoch 36 - Training Loss: 0.014183294959366322\n",
      "Epoch 37 - Training Loss: 0.015009318478405476\n",
      "Epoch 38 - Training Loss: 0.015458590351045132\n",
      "Epoch 39 - Training Loss: 0.01512604858726263\n",
      "Epoch 40 - Training Loss: 0.015501824207603931\n",
      "Epoch 41 - Training Loss: 0.016849735751748085\n",
      "Epoch 42 - Training Loss: 0.016033273190259933\n",
      "Epoch 43 - Training Loss: 0.014353655278682709\n",
      "Epoch 44 - Training Loss: 0.016394944861531258\n",
      "Epoch 45 - Training Loss: 0.01495984848588705\n",
      "Epoch 46 - Training Loss: 0.014185955747961998\n",
      "Epoch 47 - Training Loss: 0.015426822938024998\n",
      "Epoch 48 - Training Loss: 0.016770759597420692\n",
      "Epoch 49 - Training Loss: 0.01684616133570671\n",
      "Epoch 50 - Training Loss: 0.015197284519672394\n",
      "Epoch 51 - Training Loss: 0.014847583137452602\n",
      "Epoch 52 - Training Loss: 0.01538923941552639\n",
      "Epoch 53 - Training Loss: 0.016074517741799355\n",
      "Epoch 54 - Training Loss: 0.015717677772045135\n",
      "Epoch 55 - Training Loss: 0.015239550732076168\n",
      "Epoch 56 - Training Loss: 0.015554401092231274\n",
      "Epoch 57 - Training Loss: 0.014822923578321934\n",
      "Epoch 58 - Training Loss: 0.014743915759027004\n",
      "Epoch 59 - Training Loss: 0.015346070751547813\n",
      "early stopping on epoch: 60\n",
      "Epoch 1 - Training Loss: 0.015446186065673828\n",
      "Epoch 2 - Training Loss: 0.015599182806909084\n",
      "Epoch 3 - Training Loss: 0.0153659014031291\n",
      "Epoch 4 - Training Loss: 0.016550786793231964\n",
      "Epoch 5 - Training Loss: 0.015012383460998535\n",
      "Epoch 6 - Training Loss: 0.015216505154967308\n",
      "Epoch 7 - Training Loss: 0.015439578332006931\n",
      "Epoch 8 - Training Loss: 0.014034956693649292\n",
      "Epoch 9 - Training Loss: 0.015555296093225479\n",
      "Epoch 10 - Training Loss: 0.015188951045274734\n",
      "Epoch 11 - Training Loss: 0.015233705751597881\n",
      "Epoch 12 - Training Loss: 0.014982964843511581\n",
      "Epoch 13 - Training Loss: 0.01529301144182682\n",
      "Epoch 14 - Training Loss: 0.014715881086885929\n",
      "early stopping on epoch: 15\n",
      "Epoch 1 - Training Loss: 0.015727726742625237\n",
      "Epoch 2 - Training Loss: 0.01610034704208374\n",
      "Epoch 3 - Training Loss: 0.014775188639760017\n",
      "Epoch 4 - Training Loss: 0.013784385286271572\n",
      "Epoch 5 - Training Loss: 0.017632093280553818\n",
      "Epoch 6 - Training Loss: 0.01680438220500946\n",
      "Epoch 7 - Training Loss: 0.014867431484162807\n",
      "Epoch 8 - Training Loss: 0.01624971814453602\n",
      "Epoch 9 - Training Loss: 0.017374617978930473\n",
      "Epoch 10 - Training Loss: 0.016456132754683495\n",
      "Epoch 11 - Training Loss: 0.017114654183387756\n",
      "Epoch 12 - Training Loss: 0.014732757583260536\n",
      "Epoch 13 - Training Loss: 0.015037130564451218\n",
      "Epoch 14 - Training Loss: 0.014201832935214043\n",
      "Epoch 15 - Training Loss: 0.013785245828330517\n",
      "Epoch 16 - Training Loss: 0.016194133087992668\n",
      "Epoch 17 - Training Loss: 0.01704392209649086\n",
      "Epoch 18 - Training Loss: 0.015664614737033844\n",
      "Epoch 19 - Training Loss: 0.015230410732328892\n",
      "Epoch 20 - Training Loss: 0.015572463162243366\n",
      "Epoch 21 - Training Loss: 0.013875055126845837\n",
      "Epoch 22 - Training Loss: 0.015271887183189392\n",
      "Epoch 23 - Training Loss: 0.015784969553351402\n",
      "Epoch 24 - Training Loss: 0.0151521610096097\n",
      "Epoch 25 - Training Loss: 0.014619615860283375\n",
      "Epoch 26 - Training Loss: 0.015267770737409592\n",
      "Epoch 27 - Training Loss: 0.015333704650402069\n",
      "Epoch 28 - Training Loss: 0.014772304333746433\n",
      "Epoch 29 - Training Loss: 0.015751386061310768\n",
      "Epoch 30 - Training Loss: 0.01634049601852894\n",
      "Epoch 31 - Training Loss: 0.014319991692900658\n",
      "Epoch 32 - Training Loss: 0.016645075753331184\n",
      "Epoch 33 - Training Loss: 0.015670858323574066\n",
      "Epoch 34 - Training Loss: 0.015093778260052204\n",
      "Epoch 35 - Training Loss: 0.014852364547550678\n",
      "Epoch 36 - Training Loss: 0.014645827934145927\n",
      "Epoch 37 - Training Loss: 0.014680934138596058\n",
      "Epoch 38 - Training Loss: 0.01713954657316208\n",
      "Epoch 39 - Training Loss: 0.016490444540977478\n",
      "Epoch 40 - Training Loss: 0.01653442345559597\n",
      "Epoch 41 - Training Loss: 0.014643813483417034\n",
      "Epoch 42 - Training Loss: 0.01579335890710354\n",
      "Epoch 43 - Training Loss: 0.015285969711840153\n",
      "Epoch 44 - Training Loss: 0.015891799703240395\n",
      "Epoch 45 - Training Loss: 0.015269228257238865\n",
      "Epoch 46 - Training Loss: 0.014576839283108711\n",
      "Epoch 47 - Training Loss: 0.014304212294518948\n",
      "Epoch 48 - Training Loss: 0.014996063895523548\n",
      "Epoch 49 - Training Loss: 0.015750518068671227\n",
      "Epoch 50 - Training Loss: 0.01636500097811222\n",
      "Epoch 51 - Training Loss: 0.015224219299852848\n",
      "Epoch 52 - Training Loss: 0.015081392601132393\n",
      "Epoch 53 - Training Loss: 0.016399094834923744\n",
      "Epoch 54 - Training Loss: 0.01493875589221716\n",
      "Epoch 55 - Training Loss: 0.014858114533126354\n",
      "Epoch 56 - Training Loss: 0.016132738441228867\n",
      "Epoch 57 - Training Loss: 0.014561975374817848\n",
      "Epoch 58 - Training Loss: 0.01591799221932888\n",
      "Epoch 59 - Training Loss: 0.015710271894931793\n",
      "Epoch 60 - Training Loss: 0.014776972122490406\n",
      "Epoch 61 - Training Loss: 0.015572763048112392\n",
      "Epoch 62 - Training Loss: 0.01647344045341015\n",
      "Epoch 63 - Training Loss: 0.01614389568567276\n",
      "Epoch 64 - Training Loss: 0.016064710915088654\n",
      "Epoch 65 - Training Loss: 0.014627925120294094\n",
      "Epoch 66 - Training Loss: 0.015831101685762405\n",
      "Epoch 67 - Training Loss: 0.016227271407842636\n",
      "Epoch 68 - Training Loss: 0.01607593521475792\n",
      "Epoch 69 - Training Loss: 0.014643804170191288\n",
      "Epoch 70 - Training Loss: 0.014357335865497589\n",
      "Epoch 71 - Training Loss: 0.01481675822287798\n",
      "Epoch 72 - Training Loss: 0.01528354361653328\n",
      "Epoch 73 - Training Loss: 0.0158720463514328\n",
      "Epoch 74 - Training Loss: 0.015233312733471394\n",
      "Epoch 75 - Training Loss: 0.014434775337576866\n",
      "Epoch 76 - Training Loss: 0.014543280005455017\n",
      "Epoch 77 - Training Loss: 0.01590355858206749\n",
      "Epoch 78 - Training Loss: 0.01543373242020607\n",
      "Epoch 79 - Training Loss: 0.017221393063664436\n",
      "Epoch 80 - Training Loss: 0.015640806406736374\n",
      "Epoch 81 - Training Loss: 0.016255149617791176\n",
      "Epoch 82 - Training Loss: 0.015163175761699677\n",
      "Epoch 83 - Training Loss: 0.0141909783706069\n",
      "Epoch 84 - Training Loss: 0.015923261642456055\n",
      "Epoch 85 - Training Loss: 0.015363015234470367\n",
      "Epoch 86 - Training Loss: 0.01476894598454237\n",
      "Epoch 87 - Training Loss: 0.014053015038371086\n",
      "Epoch 88 - Training Loss: 0.015310735441744328\n",
      "Epoch 89 - Training Loss: 0.015055838041007519\n",
      "Epoch 90 - Training Loss: 0.01733691804111004\n",
      "Epoch 91 - Training Loss: 0.014651167206466198\n",
      "Epoch 92 - Training Loss: 0.015516993589699268\n",
      "Epoch 93 - Training Loss: 0.014959259890019894\n",
      "Epoch 94 - Training Loss: 0.016038427129387856\n",
      "Epoch 95 - Training Loss: 0.015306730754673481\n",
      "Epoch 96 - Training Loss: 0.014853893779218197\n",
      "Epoch 97 - Training Loss: 0.014131089672446251\n",
      "Epoch 98 - Training Loss: 0.0146425049751997\n",
      "Epoch 99 - Training Loss: 0.014996778219938278\n",
      "Epoch 100 - Training Loss: 0.014654036611318588\n",
      "Epoch 1 - Training Loss: 0.015897147357463837\n",
      "Epoch 2 - Training Loss: 0.015389153733849525\n",
      "Epoch 3 - Training Loss: 0.014376897364854813\n",
      "Epoch 4 - Training Loss: 0.01640373282134533\n",
      "Epoch 5 - Training Loss: 0.014350533485412598\n",
      "Epoch 6 - Training Loss: 0.014424563385546207\n",
      "Epoch 7 - Training Loss: 0.01626739092171192\n",
      "Epoch 8 - Training Loss: 0.015505763702094555\n",
      "Epoch 9 - Training Loss: 0.014942320995032787\n",
      "Epoch 10 - Training Loss: 0.01572738215327263\n",
      "Epoch 11 - Training Loss: 0.015274308621883392\n",
      "Epoch 12 - Training Loss: 0.014831742271780968\n",
      "Epoch 13 - Training Loss: 0.014908895827829838\n",
      "Epoch 14 - Training Loss: 0.016963066533207893\n",
      "Epoch 15 - Training Loss: 0.016399266198277473\n",
      "Epoch 16 - Training Loss: 0.01444841455668211\n",
      "Epoch 17 - Training Loss: 0.01533722784370184\n",
      "Epoch 18 - Training Loss: 0.016606705263257027\n",
      "Epoch 19 - Training Loss: 0.014639482833445072\n",
      "Epoch 20 - Training Loss: 0.015783770009875298\n",
      "Epoch 21 - Training Loss: 0.015156874433159828\n",
      "Epoch 22 - Training Loss: 0.014589546248316765\n",
      "Epoch 23 - Training Loss: 0.017310267314314842\n",
      "Epoch 24 - Training Loss: 0.0166485458612442\n",
      "Epoch 25 - Training Loss: 0.014711367897689342\n",
      "Epoch 26 - Training Loss: 0.014734323136508465\n",
      "Epoch 27 - Training Loss: 0.016594622284173965\n",
      "Epoch 28 - Training Loss: 0.01502318400889635\n",
      "Epoch 29 - Training Loss: 0.01634550467133522\n",
      "Epoch 30 - Training Loss: 0.014439466409385204\n",
      "Epoch 31 - Training Loss: 0.015043231658637524\n",
      "Epoch 32 - Training Loss: 0.016023805364966393\n",
      "Epoch 33 - Training Loss: 0.014402789063751698\n",
      "Epoch 34 - Training Loss: 0.014907525852322578\n",
      "Epoch 35 - Training Loss: 0.014360977336764336\n",
      "Epoch 36 - Training Loss: 0.015568828210234642\n",
      "Epoch 37 - Training Loss: 0.014022980816662312\n",
      "Epoch 38 - Training Loss: 0.01586105301976204\n",
      "Epoch 39 - Training Loss: 0.01516002044081688\n",
      "Epoch 40 - Training Loss: 0.015605570748448372\n",
      "Epoch 41 - Training Loss: 0.016298789530992508\n",
      "Epoch 42 - Training Loss: 0.015192285180091858\n",
      "Epoch 43 - Training Loss: 0.015348294749855995\n",
      "Epoch 44 - Training Loss: 0.016555877402424812\n",
      "Epoch 45 - Training Loss: 0.014857769012451172\n",
      "Epoch 46 - Training Loss: 0.013956519775092602\n",
      "Epoch 47 - Training Loss: 0.0140384491533041\n",
      "Epoch 48 - Training Loss: 0.01749773882329464\n",
      "Epoch 49 - Training Loss: 0.017023300752043724\n",
      "Epoch 50 - Training Loss: 0.01543011050671339\n",
      "Epoch 51 - Training Loss: 0.013830864802002907\n",
      "Epoch 52 - Training Loss: 0.01404545083642006\n",
      "Epoch 53 - Training Loss: 0.014979799278080463\n",
      "Epoch 54 - Training Loss: 0.015501193702220917\n",
      "Epoch 55 - Training Loss: 0.015106906183063984\n",
      "Epoch 56 - Training Loss: 0.01426630187779665\n",
      "Epoch 57 - Training Loss: 0.01536872610449791\n",
      "Epoch 58 - Training Loss: 0.014910796657204628\n",
      "Epoch 59 - Training Loss: 0.01552517618983984\n",
      "Epoch 60 - Training Loss: 0.014922233298420906\n",
      "Epoch 61 - Training Loss: 0.01532620657235384\n",
      "Epoch 62 - Training Loss: 0.01646367274224758\n",
      "Epoch 63 - Training Loss: 0.014596390537917614\n",
      "Epoch 64 - Training Loss: 0.015161877498030663\n",
      "Epoch 65 - Training Loss: 0.015969501808285713\n",
      "Epoch 66 - Training Loss: 0.015230286866426468\n",
      "Epoch 67 - Training Loss: 0.01511209923774004\n",
      "Epoch 68 - Training Loss: 0.01597338542342186\n",
      "Epoch 69 - Training Loss: 0.014967118389904499\n",
      "Epoch 70 - Training Loss: 0.015150819905102253\n",
      "Epoch 71 - Training Loss: 0.015012255869805813\n",
      "Epoch 72 - Training Loss: 0.01625608280301094\n",
      "Epoch 73 - Training Loss: 0.016663480550050735\n",
      "Epoch 74 - Training Loss: 0.015547666698694229\n",
      "Epoch 75 - Training Loss: 0.015566769056022167\n",
      "Epoch 76 - Training Loss: 0.014594954438507557\n",
      "Epoch 77 - Training Loss: 0.014790639281272888\n",
      "Epoch 78 - Training Loss: 0.014491801150143147\n",
      "Epoch 79 - Training Loss: 0.015761448070406914\n",
      "Epoch 80 - Training Loss: 0.015886694192886353\n",
      "Epoch 81 - Training Loss: 0.01623021624982357\n",
      "Epoch 82 - Training Loss: 0.01627199538052082\n",
      "Epoch 83 - Training Loss: 0.015255220234394073\n",
      "Epoch 84 - Training Loss: 0.013605793938040733\n",
      "Epoch 85 - Training Loss: 0.01739257015287876\n",
      "Epoch 86 - Training Loss: 0.015660181641578674\n",
      "Epoch 87 - Training Loss: 0.01761816069483757\n",
      "Epoch 88 - Training Loss: 0.015000020153820515\n",
      "Epoch 89 - Training Loss: 0.01476309821009636\n",
      "Epoch 90 - Training Loss: 0.015606899745762348\n",
      "Epoch 91 - Training Loss: 0.016183461993932724\n",
      "Epoch 92 - Training Loss: 0.014710363000631332\n",
      "Epoch 93 - Training Loss: 0.014166622422635555\n",
      "Epoch 94 - Training Loss: 0.016369003802537918\n",
      "Epoch 95 - Training Loss: 0.017023997381329536\n",
      "Epoch 96 - Training Loss: 0.015894923359155655\n",
      "Epoch 97 - Training Loss: 0.015472491271793842\n",
      "Epoch 98 - Training Loss: 0.014929317869246006\n",
      "Epoch 99 - Training Loss: 0.014413338154554367\n",
      "Epoch 100 - Training Loss: 0.015070314519107342\n",
      "Epoch 1 - Training Loss: 0.014808627776801586\n",
      "Epoch 2 - Training Loss: 0.015470569021999836\n",
      "Epoch 3 - Training Loss: 0.015866443514823914\n",
      "Epoch 4 - Training Loss: 0.015936369076371193\n",
      "Epoch 5 - Training Loss: 0.015033436007797718\n",
      "Epoch 6 - Training Loss: 0.013383128680288792\n",
      "Epoch 7 - Training Loss: 0.0164145790040493\n",
      "Epoch 8 - Training Loss: 0.01681005395948887\n",
      "Epoch 9 - Training Loss: 0.015343288891017437\n",
      "Epoch 10 - Training Loss: 0.015207860618829727\n",
      "Epoch 11 - Training Loss: 0.015806471928954124\n",
      "Epoch 12 - Training Loss: 0.015422415919601917\n",
      "Epoch 13 - Training Loss: 0.014858001843094826\n",
      "Epoch 14 - Training Loss: 0.01544327661395073\n",
      "Epoch 15 - Training Loss: 0.015997178852558136\n",
      "Epoch 16 - Training Loss: 0.015210350044071674\n",
      "Epoch 17 - Training Loss: 0.01757163181900978\n",
      "Epoch 18 - Training Loss: 0.014366650953888893\n",
      "Epoch 19 - Training Loss: 0.015358961187303066\n",
      "Epoch 20 - Training Loss: 0.015302525833249092\n",
      "Epoch 21 - Training Loss: 0.013625666499137878\n",
      "Epoch 22 - Training Loss: 0.01572604291141033\n",
      "Epoch 23 - Training Loss: 0.015403671190142632\n",
      "Epoch 24 - Training Loss: 0.014933211728930473\n",
      "Epoch 25 - Training Loss: 0.01532791554927826\n",
      "Epoch 26 - Training Loss: 0.014622481539845467\n",
      "Epoch 27 - Training Loss: 0.015480736270546913\n",
      "Epoch 28 - Training Loss: 0.016034254804253578\n",
      "Epoch 29 - Training Loss: 0.01680256798863411\n",
      "Epoch 30 - Training Loss: 0.015054851770401001\n",
      "Epoch 31 - Training Loss: 0.014329059049487114\n",
      "Epoch 32 - Training Loss: 0.015821337699890137\n",
      "Epoch 33 - Training Loss: 0.01542691607028246\n",
      "Epoch 34 - Training Loss: 0.015732629224658012\n",
      "Epoch 35 - Training Loss: 0.015421357937157154\n",
      "Epoch 36 - Training Loss: 0.015388483181595802\n",
      "Epoch 37 - Training Loss: 0.016219722107052803\n",
      "Epoch 38 - Training Loss: 0.014818556606769562\n",
      "Epoch 39 - Training Loss: 0.014438549056649208\n",
      "Epoch 40 - Training Loss: 0.015497080981731415\n",
      "Epoch 41 - Training Loss: 0.01398427877575159\n",
      "Epoch 42 - Training Loss: 0.01682146266102791\n",
      "Epoch 43 - Training Loss: 0.014820978976786137\n",
      "Epoch 44 - Training Loss: 0.015519550070166588\n",
      "Epoch 45 - Training Loss: 0.01794157736003399\n",
      "Epoch 46 - Training Loss: 0.014406267553567886\n",
      "Epoch 47 - Training Loss: 0.01488454733043909\n",
      "Epoch 48 - Training Loss: 0.015813017264008522\n",
      "Epoch 49 - Training Loss: 0.015713486820459366\n",
      "Epoch 50 - Training Loss: 0.015885384753346443\n",
      "Epoch 51 - Training Loss: 0.015455210581421852\n",
      "Epoch 52 - Training Loss: 0.014498626813292503\n",
      "Epoch 53 - Training Loss: 0.014889633283019066\n",
      "Epoch 54 - Training Loss: 0.016875261440873146\n",
      "Epoch 55 - Training Loss: 0.01454990729689598\n",
      "Epoch 56 - Training Loss: 0.017202621325850487\n",
      "Epoch 57 - Training Loss: 0.01440342701971531\n",
      "Epoch 58 - Training Loss: 0.016316397115588188\n",
      "Epoch 59 - Training Loss: 0.014745177701115608\n",
      "Epoch 60 - Training Loss: 0.015327797271311283\n",
      "Epoch 61 - Training Loss: 0.017473706975579262\n",
      "Epoch 62 - Training Loss: 0.016443077474832535\n",
      "Epoch 63 - Training Loss: 0.015136093832552433\n",
      "Epoch 64 - Training Loss: 0.015600685961544514\n",
      "Epoch 65 - Training Loss: 0.014461441896855831\n",
      "Epoch 66 - Training Loss: 0.0152093805372715\n",
      "Epoch 67 - Training Loss: 0.016576405614614487\n",
      "Epoch 68 - Training Loss: 0.015074249356985092\n",
      "Epoch 69 - Training Loss: 0.015524928458034992\n",
      "Epoch 70 - Training Loss: 0.01608537882566452\n",
      "Epoch 71 - Training Loss: 0.014942662790417671\n",
      "Epoch 72 - Training Loss: 0.014814660884439945\n",
      "Epoch 73 - Training Loss: 0.015750613063573837\n",
      "Epoch 74 - Training Loss: 0.016080735251307487\n",
      "Epoch 75 - Training Loss: 0.014113563112914562\n",
      "Epoch 76 - Training Loss: 0.01555486861616373\n",
      "Epoch 77 - Training Loss: 0.01592191867530346\n",
      "Epoch 78 - Training Loss: 0.014914089813828468\n",
      "Epoch 79 - Training Loss: 0.014637374319136143\n",
      "Epoch 80 - Training Loss: 0.016462275758385658\n",
      "Epoch 81 - Training Loss: 0.015135448426008224\n",
      "Epoch 82 - Training Loss: 0.016372360289096832\n",
      "Epoch 83 - Training Loss: 0.014442885294556618\n",
      "Epoch 84 - Training Loss: 0.01500231958925724\n",
      "Epoch 85 - Training Loss: 0.015379007905721664\n",
      "Epoch 86 - Training Loss: 0.015169714577496052\n",
      "Epoch 87 - Training Loss: 0.016626130789518356\n",
      "Epoch 88 - Training Loss: 0.014251370914280415\n",
      "Epoch 89 - Training Loss: 0.01582840085029602\n",
      "Epoch 90 - Training Loss: 0.014522702433168888\n",
      "Epoch 91 - Training Loss: 0.015723848715424538\n",
      "Epoch 92 - Training Loss: 0.01660190150141716\n",
      "Epoch 93 - Training Loss: 0.015487284399569035\n",
      "Epoch 94 - Training Loss: 0.015325845219194889\n",
      "Epoch 95 - Training Loss: 0.01570047251880169\n",
      "Epoch 96 - Training Loss: 0.01445589680224657\n",
      "Epoch 97 - Training Loss: 0.01592320390045643\n",
      "Epoch 98 - Training Loss: 0.015163898468017578\n",
      "Epoch 99 - Training Loss: 0.014439290389418602\n",
      "Epoch 100 - Training Loss: 0.01583424024283886\n",
      "Epoch 1 - Training Loss: 0.015971524640917778\n",
      "Epoch 2 - Training Loss: 0.014600408263504505\n",
      "Epoch 3 - Training Loss: 0.014796542003750801\n",
      "Epoch 4 - Training Loss: 0.01647086627781391\n",
      "Epoch 5 - Training Loss: 0.016456972807645798\n",
      "Epoch 6 - Training Loss: 0.014716078527271748\n",
      "Epoch 7 - Training Loss: 0.01613806188106537\n",
      "Epoch 8 - Training Loss: 0.016233162954449654\n",
      "Epoch 9 - Training Loss: 0.015445583499968052\n",
      "Epoch 10 - Training Loss: 0.01591329649090767\n",
      "Epoch 11 - Training Loss: 0.014794856309890747\n",
      "Epoch 12 - Training Loss: 0.014950467273592949\n",
      "Epoch 13 - Training Loss: 0.015035644173622131\n",
      "Epoch 14 - Training Loss: 0.0156923308968544\n",
      "Epoch 15 - Training Loss: 0.016831334680318832\n",
      "Epoch 16 - Training Loss: 0.015276912599802017\n",
      "Epoch 17 - Training Loss: 0.014705055393278599\n",
      "Epoch 18 - Training Loss: 0.014730087481439114\n",
      "Epoch 19 - Training Loss: 0.014938422478735447\n",
      "Epoch 20 - Training Loss: 0.015064636245369911\n",
      "Epoch 21 - Training Loss: 0.01603151485323906\n",
      "Epoch 22 - Training Loss: 0.01679939031600952\n",
      "Epoch 23 - Training Loss: 0.014486411586403847\n",
      "Epoch 24 - Training Loss: 0.016149958595633507\n",
      "Epoch 25 - Training Loss: 0.015330157242715359\n",
      "Epoch 26 - Training Loss: 0.01756543479859829\n",
      "Epoch 27 - Training Loss: 0.015027717687189579\n",
      "Epoch 28 - Training Loss: 0.014480371959507465\n",
      "Epoch 29 - Training Loss: 0.014740806072950363\n",
      "Epoch 30 - Training Loss: 0.014365856535732746\n",
      "Epoch 31 - Training Loss: 0.014000640250742435\n",
      "Epoch 32 - Training Loss: 0.013953001238405704\n",
      "Epoch 33 - Training Loss: 0.015417158603668213\n",
      "Epoch 34 - Training Loss: 0.013791847042739391\n",
      "Epoch 35 - Training Loss: 0.015779325738549232\n",
      "Epoch 36 - Training Loss: 0.013971875421702862\n",
      "Epoch 37 - Training Loss: 0.015721801668405533\n",
      "Epoch 38 - Training Loss: 0.01616084761917591\n",
      "Epoch 39 - Training Loss: 0.01698789931833744\n",
      "Epoch 40 - Training Loss: 0.015921764075756073\n",
      "Epoch 41 - Training Loss: 0.015309386886656284\n",
      "Epoch 42 - Training Loss: 0.01542968675494194\n",
      "Epoch 43 - Training Loss: 0.01631644368171692\n",
      "Epoch 44 - Training Loss: 0.0150682982057333\n",
      "Epoch 45 - Training Loss: 0.014360768720507622\n",
      "Epoch 46 - Training Loss: 0.01545521430671215\n",
      "Epoch 47 - Training Loss: 0.015561528503894806\n",
      "Epoch 48 - Training Loss: 0.015354163944721222\n",
      "Epoch 49 - Training Loss: 0.01549974363297224\n",
      "Epoch 50 - Training Loss: 0.015789231285452843\n",
      "Epoch 51 - Training Loss: 0.01599232107400894\n",
      "Epoch 52 - Training Loss: 0.014972995966672897\n",
      "Epoch 53 - Training Loss: 0.014905743300914764\n",
      "Epoch 54 - Training Loss: 0.016744345426559448\n",
      "Epoch 55 - Training Loss: 0.014185832813382149\n",
      "Epoch 56 - Training Loss: 0.015078849159181118\n",
      "Epoch 57 - Training Loss: 0.015139107592403889\n",
      "Epoch 58 - Training Loss: 0.015772148966789246\n",
      "Epoch 59 - Training Loss: 0.016599996015429497\n",
      "Epoch 60 - Training Loss: 0.014687779359519482\n",
      "Epoch 61 - Training Loss: 0.014965190552175045\n",
      "Epoch 62 - Training Loss: 0.014100751839578152\n",
      "Epoch 63 - Training Loss: 0.014965211041271687\n",
      "Epoch 64 - Training Loss: 0.015077659860253334\n",
      "Epoch 65 - Training Loss: 0.01489215437322855\n",
      "Epoch 66 - Training Loss: 0.014681840315461159\n",
      "Epoch 67 - Training Loss: 0.015142714604735374\n",
      "Epoch 68 - Training Loss: 0.014962431974709034\n",
      "Epoch 69 - Training Loss: 0.014534669928252697\n",
      "early stopping on epoch: 70\n",
      "Epoch 1 - Training Loss: 0.016117818653583527\n",
      "Epoch 2 - Training Loss: 0.015342176891863346\n",
      "Epoch 3 - Training Loss: 0.01474781148135662\n",
      "Epoch 4 - Training Loss: 0.014246915467083454\n",
      "Epoch 5 - Training Loss: 0.01454539131373167\n",
      "Epoch 6 - Training Loss: 0.015018750913441181\n",
      "Epoch 7 - Training Loss: 0.016137516126036644\n",
      "Epoch 8 - Training Loss: 0.016243180260062218\n",
      "Epoch 9 - Training Loss: 0.015637699514627457\n",
      "Epoch 10 - Training Loss: 0.015538396313786507\n",
      "Epoch 11 - Training Loss: 0.014145012013614178\n",
      "Epoch 12 - Training Loss: 0.01841951534152031\n",
      "Epoch 13 - Training Loss: 0.01652594842016697\n",
      "Epoch 14 - Training Loss: 0.015535326674580574\n",
      "Epoch 15 - Training Loss: 0.015700722113251686\n",
      "Epoch 16 - Training Loss: 0.016163375228643417\n",
      "Epoch 17 - Training Loss: 0.01616586558520794\n",
      "Epoch 18 - Training Loss: 0.01624888926744461\n",
      "Epoch 19 - Training Loss: 0.01625867746770382\n",
      "Epoch 20 - Training Loss: 0.01469339057803154\n",
      "Epoch 21 - Training Loss: 0.014640972018241882\n",
      "Epoch 22 - Training Loss: 0.01658073253929615\n",
      "Epoch 23 - Training Loss: 0.015638645738363266\n",
      "Epoch 24 - Training Loss: 0.01523033156991005\n",
      "Epoch 25 - Training Loss: 0.016034768894314766\n",
      "Epoch 26 - Training Loss: 0.015670349821448326\n",
      "Epoch 27 - Training Loss: 0.014779175631701946\n",
      "Epoch 28 - Training Loss: 0.016651231795549393\n",
      "Epoch 29 - Training Loss: 0.016645068302750587\n",
      "Epoch 30 - Training Loss: 0.014801009558141232\n",
      "Epoch 31 - Training Loss: 0.01687123253941536\n",
      "Epoch 32 - Training Loss: 0.01626741886138916\n",
      "Epoch 33 - Training Loss: 0.015430455096065998\n",
      "Epoch 34 - Training Loss: 0.015260799787938595\n",
      "Epoch 35 - Training Loss: 0.01597619242966175\n",
      "Epoch 36 - Training Loss: 0.016451265662908554\n",
      "Epoch 37 - Training Loss: 0.01699499972164631\n",
      "Epoch 38 - Training Loss: 0.015174533240497112\n",
      "Epoch 39 - Training Loss: 0.01584017276763916\n",
      "Epoch 40 - Training Loss: 0.015661517158150673\n",
      "Epoch 41 - Training Loss: 0.01700410060584545\n",
      "Epoch 42 - Training Loss: 0.015606297180056572\n",
      "Epoch 43 - Training Loss: 0.016002686694264412\n",
      "Epoch 44 - Training Loss: 0.015521476976573467\n",
      "Epoch 45 - Training Loss: 0.01564696803689003\n",
      "Epoch 46 - Training Loss: 0.015562377870082855\n",
      "Epoch 47 - Training Loss: 0.016519520431756973\n",
      "Epoch 48 - Training Loss: 0.014831415377557278\n",
      "Epoch 49 - Training Loss: 0.015359858982264996\n",
      "Epoch 50 - Training Loss: 0.014697030186653137\n",
      "Epoch 51 - Training Loss: 0.016161516308784485\n",
      "early stopping on epoch: 52\n",
      "Epoch 1 - Training Loss: 0.01526760496199131\n",
      "Epoch 2 - Training Loss: 0.01587086357176304\n",
      "Epoch 3 - Training Loss: 0.014977807179093361\n",
      "Epoch 4 - Training Loss: 0.015866165980696678\n",
      "Epoch 5 - Training Loss: 0.016356514766812325\n",
      "Epoch 6 - Training Loss: 0.017078250646591187\n",
      "Epoch 7 - Training Loss: 0.016841571778059006\n",
      "Epoch 8 - Training Loss: 0.015848353505134583\n",
      "Epoch 9 - Training Loss: 0.016139641404151917\n",
      "Epoch 10 - Training Loss: 0.016254421323537827\n",
      "Epoch 11 - Training Loss: 0.016056736931204796\n",
      "Epoch 12 - Training Loss: 0.015304062515497208\n",
      "Epoch 13 - Training Loss: 0.015434538945555687\n",
      "Epoch 14 - Training Loss: 0.015724189579486847\n",
      "Epoch 15 - Training Loss: 0.01555757224559784\n",
      "Epoch 16 - Training Loss: 0.015831684693694115\n",
      "Epoch 17 - Training Loss: 0.01716987043619156\n",
      "Epoch 18 - Training Loss: 0.015658967196941376\n",
      "Epoch 19 - Training Loss: 0.01573943719267845\n",
      "Epoch 20 - Training Loss: 0.016041453927755356\n",
      "Epoch 21 - Training Loss: 0.016190098598599434\n",
      "Epoch 22 - Training Loss: 0.014319393783807755\n",
      "Epoch 23 - Training Loss: 0.016200801357626915\n",
      "Epoch 24 - Training Loss: 0.014642035588622093\n",
      "Epoch 25 - Training Loss: 0.014328292571008205\n",
      "Epoch 26 - Training Loss: 0.015355472452938557\n",
      "Epoch 27 - Training Loss: 0.016137845814228058\n",
      "Epoch 28 - Training Loss: 0.01677006296813488\n",
      "Epoch 29 - Training Loss: 0.015697799623012543\n",
      "Epoch 30 - Training Loss: 0.01633373647928238\n",
      "Epoch 31 - Training Loss: 0.015123005956411362\n",
      "Epoch 32 - Training Loss: 0.015412388369441032\n",
      "Epoch 33 - Training Loss: 0.016985511407256126\n",
      "Epoch 34 - Training Loss: 0.015545742586255074\n",
      "Epoch 35 - Training Loss: 0.016018450260162354\n",
      "Epoch 36 - Training Loss: 0.015874596312642097\n",
      "Epoch 37 - Training Loss: 0.015264788642525673\n",
      "Epoch 38 - Training Loss: 0.015223168767988682\n",
      "Epoch 39 - Training Loss: 0.015779320150613785\n",
      "Epoch 40 - Training Loss: 0.016489636152982712\n",
      "Epoch 41 - Training Loss: 0.015290102921426296\n",
      "Epoch 42 - Training Loss: 0.015411966480314732\n",
      "Epoch 43 - Training Loss: 0.016078634187579155\n",
      "early stopping on epoch: 44\n",
      "Epoch 1 - Training Loss: 0.01436548214405775\n",
      "Epoch 2 - Training Loss: 0.015444747172296047\n",
      "Epoch 3 - Training Loss: 0.014609231613576412\n",
      "Epoch 4 - Training Loss: 0.015598339959979057\n",
      "Epoch 5 - Training Loss: 0.016611898317933083\n",
      "Epoch 6 - Training Loss: 0.014705189503729343\n",
      "Epoch 7 - Training Loss: 0.015573833137750626\n",
      "Epoch 8 - Training Loss: 0.015528261661529541\n",
      "Epoch 9 - Training Loss: 0.01589175872504711\n",
      "Epoch 10 - Training Loss: 0.017074866220355034\n",
      "Epoch 11 - Training Loss: 0.01765104942023754\n",
      "Epoch 12 - Training Loss: 0.014493056572973728\n",
      "Epoch 13 - Training Loss: 0.015147609636187553\n",
      "Epoch 14 - Training Loss: 0.017082756385207176\n",
      "Epoch 15 - Training Loss: 0.01477542519569397\n",
      "Epoch 16 - Training Loss: 0.014727568253874779\n",
      "Epoch 17 - Training Loss: 0.015888644382357597\n",
      "Epoch 18 - Training Loss: 0.015162048861384392\n",
      "Epoch 19 - Training Loss: 0.015592611394822598\n",
      "Epoch 20 - Training Loss: 0.01508577261120081\n",
      "Epoch 21 - Training Loss: 0.01565270684659481\n",
      "Epoch 22 - Training Loss: 0.014628620818257332\n",
      "Epoch 23 - Training Loss: 0.01380447018891573\n",
      "Epoch 24 - Training Loss: 0.015949038788676262\n",
      "Epoch 25 - Training Loss: 0.014988593757152557\n",
      "Epoch 26 - Training Loss: 0.014982574619352818\n",
      "Epoch 27 - Training Loss: 0.015436711721122265\n",
      "Epoch 28 - Training Loss: 0.015940958634018898\n",
      "Epoch 29 - Training Loss: 0.014445174485445023\n",
      "Epoch 30 - Training Loss: 0.01539963111281395\n",
      "Epoch 31 - Training Loss: 0.014930464327335358\n",
      "Epoch 32 - Training Loss: 0.01636826992034912\n",
      "Epoch 33 - Training Loss: 0.015331922098994255\n",
      "Epoch 34 - Training Loss: 0.014964636415243149\n",
      "Epoch 35 - Training Loss: 0.014981908723711967\n",
      "Epoch 36 - Training Loss: 0.014960011467337608\n",
      "Epoch 37 - Training Loss: 0.01549120619893074\n",
      "Epoch 38 - Training Loss: 0.01508963294327259\n",
      "Epoch 39 - Training Loss: 0.01706196367740631\n",
      "Epoch 40 - Training Loss: 0.015560939908027649\n",
      "Epoch 41 - Training Loss: 0.015196419321000576\n",
      "Epoch 42 - Training Loss: 0.01599404588341713\n",
      "Epoch 43 - Training Loss: 0.01586208865046501\n",
      "Epoch 44 - Training Loss: 0.016058627516031265\n",
      "Epoch 45 - Training Loss: 0.015400262549519539\n",
      "Epoch 46 - Training Loss: 0.014346620067954063\n",
      "Epoch 47 - Training Loss: 0.015504938550293446\n",
      "Epoch 48 - Training Loss: 0.015144377015531063\n",
      "Epoch 49 - Training Loss: 0.01712125912308693\n",
      "Epoch 50 - Training Loss: 0.014603476040065289\n",
      "Epoch 51 - Training Loss: 0.01624300330877304\n",
      "Epoch 52 - Training Loss: 0.016637055203318596\n",
      "Epoch 53 - Training Loss: 0.01643798127770424\n",
      "Epoch 54 - Training Loss: 0.015606924891471863\n",
      "Epoch 55 - Training Loss: 0.01510306354612112\n",
      "Epoch 56 - Training Loss: 0.015130729414522648\n",
      "Epoch 57 - Training Loss: 0.01720977947115898\n",
      "Epoch 58 - Training Loss: 0.015970870852470398\n",
      "Epoch 59 - Training Loss: 0.015415209345519543\n",
      "Epoch 60 - Training Loss: 0.014278735034167767\n",
      "Epoch 61 - Training Loss: 0.0159100703895092\n",
      "Epoch 62 - Training Loss: 0.01610754244029522\n",
      "Epoch 63 - Training Loss: 0.016153182834386826\n",
      "Epoch 64 - Training Loss: 0.014306758530437946\n",
      "Epoch 65 - Training Loss: 0.014694204553961754\n",
      "Epoch 66 - Training Loss: 0.014684347435832024\n",
      "Epoch 67 - Training Loss: 0.0164800975471735\n",
      "Epoch 68 - Training Loss: 0.014441239647567272\n",
      "Epoch 69 - Training Loss: 0.01545823272317648\n",
      "Epoch 70 - Training Loss: 0.015879878774285316\n",
      "Epoch 71 - Training Loss: 0.016007324680685997\n",
      "Epoch 72 - Training Loss: 0.017232757061719894\n",
      "Epoch 73 - Training Loss: 0.014571801759302616\n",
      "Epoch 74 - Training Loss: 0.014732083305716515\n",
      "Epoch 75 - Training Loss: 0.01643424853682518\n",
      "Epoch 76 - Training Loss: 0.015440949238836765\n",
      "Epoch 77 - Training Loss: 0.01601112075150013\n",
      "Epoch 78 - Training Loss: 0.015092005021870136\n",
      "Epoch 79 - Training Loss: 0.014829969964921474\n",
      "Epoch 80 - Training Loss: 0.01658383384346962\n",
      "Epoch 81 - Training Loss: 0.014527897350490093\n",
      "Epoch 82 - Training Loss: 0.014631065540015697\n",
      "Epoch 83 - Training Loss: 0.014638332650065422\n",
      "Epoch 84 - Training Loss: 0.01603936031460762\n",
      "Epoch 85 - Training Loss: 0.015027365647256374\n",
      "Epoch 86 - Training Loss: 0.014984769746661186\n",
      "Epoch 87 - Training Loss: 0.01410367526113987\n",
      "Epoch 88 - Training Loss: 0.015047361142933369\n",
      "Epoch 89 - Training Loss: 0.015321604907512665\n",
      "Epoch 90 - Training Loss: 0.017328737303614616\n",
      "Epoch 91 - Training Loss: 0.016382206231355667\n",
      "Epoch 92 - Training Loss: 0.014967390336096287\n",
      "Epoch 93 - Training Loss: 0.015096175484359264\n",
      "Epoch 94 - Training Loss: 0.015151416882872581\n",
      "Epoch 95 - Training Loss: 0.014586315490305424\n",
      "Epoch 96 - Training Loss: 0.015757771208882332\n",
      "Epoch 97 - Training Loss: 0.016740217804908752\n",
      "Epoch 98 - Training Loss: 0.01741824485361576\n",
      "Epoch 99 - Training Loss: 0.015168128535151482\n",
      "Epoch 100 - Training Loss: 0.015059324912726879\n",
      "Epoch 1 - Training Loss: 0.015245158225297928\n",
      "Epoch 2 - Training Loss: 0.016398675739765167\n",
      "Epoch 3 - Training Loss: 0.016695963218808174\n",
      "Epoch 4 - Training Loss: 0.014993439428508282\n",
      "Epoch 5 - Training Loss: 0.017248202115297318\n",
      "Epoch 6 - Training Loss: 0.015900935977697372\n",
      "Epoch 7 - Training Loss: 0.015608489513397217\n",
      "Epoch 8 - Training Loss: 0.015718618407845497\n",
      "Epoch 9 - Training Loss: 0.016052696853876114\n",
      "Epoch 10 - Training Loss: 0.014537314884364605\n",
      "Epoch 11 - Training Loss: 0.015754742547869682\n",
      "Epoch 12 - Training Loss: 0.01443411037325859\n",
      "Epoch 13 - Training Loss: 0.01671840250492096\n",
      "Epoch 14 - Training Loss: 0.016363678500056267\n",
      "Epoch 15 - Training Loss: 0.014881128445267677\n",
      "Epoch 16 - Training Loss: 0.014366312883794308\n",
      "Epoch 17 - Training Loss: 0.016704142093658447\n",
      "Epoch 18 - Training Loss: 0.015571228228509426\n",
      "Epoch 19 - Training Loss: 0.01691414602100849\n",
      "Epoch 20 - Training Loss: 0.015270528383553028\n",
      "Epoch 21 - Training Loss: 0.0156832505017519\n",
      "Epoch 22 - Training Loss: 0.01626673713326454\n",
      "Epoch 23 - Training Loss: 0.015125586651265621\n",
      "Epoch 24 - Training Loss: 0.015151094645261765\n",
      "Epoch 25 - Training Loss: 0.014984781853854656\n",
      "Epoch 26 - Training Loss: 0.015492524951696396\n",
      "Epoch 27 - Training Loss: 0.014785759150981903\n",
      "Epoch 28 - Training Loss: 0.016326498240232468\n",
      "Epoch 29 - Training Loss: 0.015414031222462654\n",
      "Epoch 30 - Training Loss: 0.016419915482401848\n",
      "Epoch 31 - Training Loss: 0.014853273518383503\n",
      "Epoch 32 - Training Loss: 0.01586756855249405\n",
      "Epoch 33 - Training Loss: 0.018053267151117325\n",
      "Epoch 34 - Training Loss: 0.015732256695628166\n",
      "Epoch 35 - Training Loss: 0.015006301924586296\n",
      "Epoch 36 - Training Loss: 0.015033772215247154\n",
      "Epoch 37 - Training Loss: 0.01597091183066368\n",
      "Epoch 38 - Training Loss: 0.016283433884382248\n",
      "Epoch 39 - Training Loss: 0.014427741058170795\n",
      "Epoch 40 - Training Loss: 0.014818933792412281\n",
      "Epoch 41 - Training Loss: 0.01466570608317852\n",
      "Epoch 42 - Training Loss: 0.017133699730038643\n",
      "Epoch 43 - Training Loss: 0.016009412705898285\n",
      "Epoch 44 - Training Loss: 0.015493080019950867\n",
      "Epoch 45 - Training Loss: 0.014907228760421276\n",
      "Epoch 46 - Training Loss: 0.015883246436715126\n",
      "Epoch 47 - Training Loss: 0.0159465242177248\n",
      "Epoch 48 - Training Loss: 0.014643141068518162\n",
      "Epoch 49 - Training Loss: 0.015758400782942772\n",
      "Epoch 50 - Training Loss: 0.01571902446448803\n",
      "Epoch 51 - Training Loss: 0.01731257699429989\n",
      "Epoch 52 - Training Loss: 0.016483241692185402\n",
      "Epoch 53 - Training Loss: 0.016987355425953865\n",
      "Epoch 54 - Training Loss: 0.015246273949742317\n",
      "Epoch 55 - Training Loss: 0.015891877934336662\n",
      "Epoch 56 - Training Loss: 0.01654156856238842\n",
      "Epoch 57 - Training Loss: 0.014675482176244259\n",
      "Epoch 58 - Training Loss: 0.014543450437486172\n",
      "Epoch 59 - Training Loss: 0.014131168834865093\n",
      "Epoch 60 - Training Loss: 0.014831320382654667\n",
      "Epoch 61 - Training Loss: 0.017132140696048737\n",
      "Epoch 62 - Training Loss: 0.015742039307951927\n",
      "Epoch 63 - Training Loss: 0.015527982264757156\n",
      "Epoch 64 - Training Loss: 0.015993719920516014\n",
      "Epoch 65 - Training Loss: 0.015624115243554115\n",
      "Epoch 66 - Training Loss: 0.015820162370800972\n",
      "Epoch 67 - Training Loss: 0.014790667220950127\n",
      "Epoch 68 - Training Loss: 0.01770004816353321\n",
      "Epoch 69 - Training Loss: 0.015780281275510788\n",
      "Epoch 70 - Training Loss: 0.014933777041733265\n",
      "Epoch 71 - Training Loss: 0.015091036446392536\n",
      "Epoch 72 - Training Loss: 0.015353587456047535\n",
      "Epoch 73 - Training Loss: 0.014143094420433044\n",
      "Epoch 74 - Training Loss: 0.01515982300043106\n",
      "Epoch 75 - Training Loss: 0.015998095273971558\n",
      "Epoch 76 - Training Loss: 0.016065722331404686\n",
      "Epoch 77 - Training Loss: 0.016540726646780968\n",
      "Epoch 78 - Training Loss: 0.01589694805443287\n",
      "Epoch 79 - Training Loss: 0.016091840341687202\n",
      "Epoch 80 - Training Loss: 0.015830181539058685\n",
      "Epoch 81 - Training Loss: 0.01587357558310032\n",
      "Epoch 82 - Training Loss: 0.015262944623827934\n",
      "Epoch 83 - Training Loss: 0.015804944559931755\n",
      "Epoch 84 - Training Loss: 0.01635775901377201\n",
      "Epoch 85 - Training Loss: 0.014943363144993782\n",
      "Epoch 86 - Training Loss: 0.01719285175204277\n",
      "Epoch 87 - Training Loss: 0.014899942092597485\n",
      "Epoch 88 - Training Loss: 0.016389600932598114\n",
      "Epoch 89 - Training Loss: 0.015459929592907429\n",
      "Epoch 90 - Training Loss: 0.01649186573922634\n",
      "Epoch 91 - Training Loss: 0.015782088041305542\n",
      "Epoch 92 - Training Loss: 0.014798753894865513\n",
      "Epoch 93 - Training Loss: 0.016037695109844208\n",
      "Epoch 94 - Training Loss: 0.015527323819696903\n",
      "Epoch 95 - Training Loss: 0.015608314424753189\n",
      "Epoch 96 - Training Loss: 0.01688789576292038\n",
      "Epoch 97 - Training Loss: 0.015912380069494247\n",
      "Epoch 98 - Training Loss: 0.01642327569425106\n",
      "Epoch 99 - Training Loss: 0.01611766777932644\n",
      "Epoch 100 - Training Loss: 0.015330541878938675\n",
      "Epoch 1 - Training Loss: 0.01673445850610733\n",
      "Epoch 2 - Training Loss: 0.015961002558469772\n",
      "Epoch 3 - Training Loss: 0.01519805658608675\n",
      "Epoch 4 - Training Loss: 0.015456029213964939\n",
      "Epoch 5 - Training Loss: 0.016667446121573448\n",
      "Epoch 6 - Training Loss: 0.01551098469644785\n",
      "Epoch 7 - Training Loss: 0.016353702172636986\n",
      "Epoch 8 - Training Loss: 0.015484335832297802\n",
      "Epoch 9 - Training Loss: 0.017218319699168205\n",
      "Epoch 10 - Training Loss: 0.015605437569320202\n",
      "Epoch 11 - Training Loss: 0.014703918248414993\n",
      "Epoch 12 - Training Loss: 0.016388051211833954\n",
      "Epoch 13 - Training Loss: 0.015008186921477318\n",
      "Epoch 14 - Training Loss: 0.01510317251086235\n",
      "Epoch 15 - Training Loss: 0.014750892296433449\n",
      "Epoch 16 - Training Loss: 0.0157876368612051\n",
      "Epoch 17 - Training Loss: 0.016253523528575897\n",
      "Epoch 18 - Training Loss: 0.015456083230674267\n",
      "Epoch 19 - Training Loss: 0.015110987238585949\n",
      "early stopping on epoch: 20\n",
      "\n",
      "The RMSE is: 6.393791675567627\n",
      "\n",
      "The MAPE is: 8.81013348698616\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mape'])\n",
    "\n",
    "# Empty list for predictions\n",
    "y_pred = []\n",
    "\n",
    "# Iterate until we go through entire test set\n",
    "for i in range(len(WFX_test)):\n",
    "    # Train\n",
    "    model, _ = train_model(model = model, X_train = WFX_train, y_train = WFy_train)\n",
    "    # Predict step-ahead\n",
    "    pred = model.predict(WFX_test[i:i+1], verbose=0, batch_size=batch_size)\n",
    "    # Append prediction to list\n",
    "    y_pred.append(pred[0][0])\n",
    "    # Add input from test set to train\n",
    "    WFX_train = np.concatenate((WFX_train, WFX_test[i:i+1]), axis=0)\n",
    "    WFy_train = np.concatenate((WFy_train, WFy_test[i:i+1]), axis=0)\n",
    "\n",
    "# Unscale predictions\n",
    "y_pred_unsc = scaler.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "y_test_unsc = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Compute metrics\n",
    "rmse_value = rmse(y_test_unsc, y_pred_unsc)\n",
    "mape_value = mape(y_test_unsc, y_pred_unsc)\n",
    "\n",
    "# Print metrics\n",
    "print(f'\\nThe RMSE is: {rmse_value}')\n",
    "print(f'\\nThe MAPE is: {mape_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "225942a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "test_dates = dates[-len(y_test):]\n",
    "df = pd.DataFrame({'y_pred': np.array(y_pred_unsc).flatten(), 'y_test': y_test_unsc.flatten()})\n",
    "df.set_index(test_dates, inplace = True)\n",
    "df.plot()\n",
    "plt.title('WFTUNEDL1B10 Predictions')\n",
    "plt.savefig(path+'WFTUNEDL1B10_Forecast.png', transparent = True, dpi = 300)\n",
    "plt.ylabel('EUR') \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d8382d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'WFTUNEDL1B10_Results.pkl', 'wb') as f: # Rename\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
